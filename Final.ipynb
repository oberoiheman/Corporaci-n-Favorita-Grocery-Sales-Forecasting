{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r9eNHKOkKWRh"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59f375a2b8b04678a15274ea8533fa93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1a6b61ffe08144188a9d7af4dd944559",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8dedbfc3d5b34ffabc22cae9ef998930",
              "IPY_MODEL_b889abfccba64c39af9ff1765bc65ddd"
            ]
          }
        },
        "1a6b61ffe08144188a9d7af4dd944559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8dedbfc3d5b34ffabc22cae9ef998930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_02655e7f0375403a8c79e77ab4fff9ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bab852b3801c40eda7039353b5aef6ce"
          }
        },
        "b889abfccba64c39af9ff1765bc65ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ac22252566c4bd58e659b0bf6aa6cbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/? [06:43&lt;00:00, 25.19s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e969869e917c427f93de02da0f36f289"
          }
        },
        "02655e7f0375403a8c79e77ab4fff9ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bab852b3801c40eda7039353b5aef6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ac22252566c4bd58e659b0bf6aa6cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e969869e917c427f93de02da0f36f289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c2a26edc1644bfead378282a980d487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4b744174a06a41b196b9098a398f2e05",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68b13a87cb374a7aa1218af453b5ceae",
              "IPY_MODEL_8992519e628e48e79c5b9dc484f735cc"
            ]
          }
        },
        "4b744174a06a41b196b9098a398f2e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68b13a87cb374a7aa1218af453b5ceae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5b54196bb3b54c79bcc3dde2f99831b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_890122267f4e41bab23b1e9e80e67df2"
          }
        },
        "8992519e628e48e79c5b9dc484f735cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e645fc343f084ce792c967fb0dfc5fa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/? [04:29&lt;00:00, 16.83s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3bebe896ab6e4afd9f2ead54292d89a2"
          }
        },
        "5b54196bb3b54c79bcc3dde2f99831b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "890122267f4e41bab23b1e9e80e67df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e645fc343f084ce792c967fb0dfc5fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3bebe896ab6e4afd9f2ead54292d89a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A97XENA4YNw5",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-c6ApHMHi99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "6cd8a1b7-7ff9-47c5-d3c1-44ebcd73815a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyrVZB-GHolC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from datetime import date, timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "import os\n",
        "import sys\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Gzw6rydKNXq",
        "colab_type": "text"
      },
      "source": [
        "## Downloading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr_945RdHqRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d76e590f-3e5a-40b6-a272-c706fd048238"
      },
      "source": [
        "!wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/7391/44328/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1595846545&Signature=fOmnQiBAwPnPPle4jgShB4NFMjbmoiOoOlFQRYjPKCX7GKNFuTWdK0TLICd6qEaosYMvkam3gkTLL1DzSO1fI94bUqpM%2FnI%2FLZq8HWDJYHjeiP06zCajKO4BA3UIytFW3dy1IKbQWfTvY%2Bme7rtMOTJOAr3HpSkXiELNXNepz8G22cVCaZY1P6t2KmPhCbgIwMvuko30hVxa6W6Gx7426qT5jDlvLhdoErdMbgf9SyAkK1HG1aZc0IqAGXvNUAkm7i3qDHEh6OKVn6HijqDyYEbuzRAU3r7CA1Pyme%2Bn%2Bf1xLlIo85LaeaSQdQgFnKy9Q9ZqCKjZhqBai%2FBQsQrJrQ%3D%3D&response-content-disposition=attachment%3B+filename%3Dfavorita-grocery-sales-forecasting.zip\" -c -O 'favorita-grocery-sales-forecasting.zip'\n",
        "import os\n",
        "    \n",
        "if os.path.exists('favorita-grocery-sales-forecasting.zip'):\n",
        "    !unzip 'favorita-grocery-sales-forecasting.zip'\n",
        "    #print(\"File unzipped Successfully\")\n",
        "else:\n",
        "    sys.exit(\"'favorita-grocery-sales-forecasting.zip' File Not Present to unzip\")  \n",
        "\n",
        "#installing 7zip for extracting .7z files\n",
        "!apt-get install p7zip-full\n",
        "\n",
        "\n",
        "for file in os.listdir():\n",
        "    if file[-3:]=='.7z':\n",
        "        if os.path.exists(file[:-3]):\n",
        "            print(\"=\"*50)\n",
        "            print(\"'{}'Extracted File is Already Present\".format(file[:-3]))\n",
        "                \n",
        "        elif file=='train.csv.7z':\n",
        "            !p7zip -d 'train.csv.7z'\n",
        "            print(\"=\"*50)\n",
        "            print(\"'{}' File Extracted Successfully\".format(file))\n",
        "\n",
        "        elif file=='stores.csv.7z':\n",
        "            !p7zip -d 'stores.csv.7z'\n",
        "            print(\"=\"*50)\n",
        "            print(\"'{}' File Extracted Successfully\".format(file))\n",
        "\n",
        "        elif file=='items.csv.7z':\n",
        "            !p7zip -d 'items.csv.7z'\n",
        "            print(\"=\"*50)\n",
        "            print(\"'{}' File Extracted Successfully\".format(file))\n",
        "\n",
        "        elif file=='test.csv.7z':\n",
        "            !p7zip -d 'test.csv.7z'\n",
        "            print(\"=\"*50)\n",
        "            print(\"'{}' File Extracted Successfully\".format(file))\n",
        "\n",
        "        print(\"=\"*50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-25 16:16:17--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/7391/44328/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1595846545&Signature=fOmnQiBAwPnPPle4jgShB4NFMjbmoiOoOlFQRYjPKCX7GKNFuTWdK0TLICd6qEaosYMvkam3gkTLL1DzSO1fI94bUqpM%2FnI%2FLZq8HWDJYHjeiP06zCajKO4BA3UIytFW3dy1IKbQWfTvY%2Bme7rtMOTJOAr3HpSkXiELNXNepz8G22cVCaZY1P6t2KmPhCbgIwMvuko30hVxa6W6Gx7426qT5jDlvLhdoErdMbgf9SyAkK1HG1aZc0IqAGXvNUAkm7i3qDHEh6OKVn6HijqDyYEbuzRAU3r7CA1Pyme%2Bn%2Bf1xLlIo85LaeaSQdQgFnKy9Q9ZqCKjZhqBai%2FBQsQrJrQ%3D%3D&response-content-disposition=attachment%3B+filename%3Dfavorita-grocery-sales-forecasting.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 74.125.204.128, 64.233.188.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 480014675 (458M) [application/zip]\n",
            "Saving to: ‘favorita-grocery-sales-forecasting.zip’\n",
            "\n",
            "favorita-grocery-sa 100%[===================>] 457.78M  32.1MB/s    in 14s     \n",
            "\n",
            "2020-07-25 16:16:31 (33.6 MB/s) - ‘favorita-grocery-sales-forecasting.zip’ saved [480014675/480014675]\n",
            "\n",
            "Archive:  favorita-grocery-sales-forecasting.zip\n",
            "  inflating: holidays_events.csv.7z  \n",
            "  inflating: items.csv.7z            \n",
            "  inflating: oil.csv.7z              \n",
            "  inflating: sample_submission.csv.7z  \n",
            "  inflating: stores.csv.7z           \n",
            "  inflating: test.csv.7z             \n",
            "  inflating: train.csv.7z            \n",
            "  inflating: transactions.csv.7z     \n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip-full is already the newest version (16.02+dfsg-6).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "==================================================\n",
            "==================================================\n",
            "==================================================\n",
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 474092593 bytes (453 MiB)\n",
            "\n",
            "Extracting archive: train.csv.7z\n",
            "--\n",
            "Path = train.csv.7z\n",
            "Type = 7z\n",
            "Physical Size = 474092593\n",
            "Headers Size = 122\n",
            "Method = LZMA2:24\n",
            "Solid = -\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b100% 1\b\b\b\b\b\b      \b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       4997452288\n",
            "Compressed: 474092593\n",
            "==================================================\n",
            "'train.csv.7z' File Extracted Successfully\n",
            "==================================================\n",
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 4885065 bytes (4771 KiB)\n",
            "\n",
            "Extracting archive: test.csv.7z\n",
            "--\n",
            "Path = test.csv.7z\n",
            "Type = 7z\n",
            "Physical Size = 4885065\n",
            "Headers Size = 122\n",
            "Method = LZMA2:24\n",
            "Solid = -\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 23% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       126163026\n",
            "Compressed: 4885065\n",
            "==================================================\n",
            "'test.csv.7z' File Extracted Successfully\n",
            "==================================================\n",
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 14315 bytes (14 KiB)\n",
            "\n",
            "Extracting archive: items.csv.7z\n",
            "--\n",
            "Path = items.csv.7z\n",
            "Type = 7z\n",
            "Physical Size = 14315\n",
            "Headers Size = 122\n",
            "Method = LZMA2:17\n",
            "Solid = -\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       101841\n",
            "Compressed: 14315\n",
            "==================================================\n",
            "'items.csv.7z' File Extracted Successfully\n",
            "==================================================\n",
            "\n",
            "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 648 bytes (1 KiB)\n",
            "\n",
            "Extracting archive: stores.csv.7z\n",
            "--\n",
            "Path = stores.csv.7z\n",
            "Type = 7z\n",
            "Physical Size = 648\n",
            "Headers Size = 130\n",
            "Method = LZMA2:12\n",
            "Solid = -\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
            "\n",
            "Size:       1387\n",
            "Compressed: 648\n",
            "==================================================\n",
            "'stores.csv.7z' File Extracted Successfully\n",
            "==================================================\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT_jq1ZgmYqY",
        "colab_type": "text"
      },
      "source": [
        "## Create Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypEFwVJPr5mh",
        "colab_type": "text"
      },
      "source": [
        "### Preparing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7wRy08zroJv",
        "colab_type": "text"
      },
      "source": [
        "####Reduce memory usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shqu4zJFqXeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    \n",
        "    #start_mem = df.memory_usage().sum() / 1024**2\n",
        "    #print('Memory usage of Dataframe is {:.3f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        elif 'datetime' not in col_type.name:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    #end_mem = df.memory_usage().sum() / 1024**2\n",
        "    #print('Memory usage after optimization is: {:.3f} MB'.format(end_mem))\n",
        "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ro-r4a9qb5t",
        "colab_type": "text"
      },
      "source": [
        "#### Function for Reading and Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Q_vn1Unj0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_process():\n",
        "    \n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    \n",
        "    \"\"\"### Test Data\"\"\"\n",
        "\n",
        "    #Reading test.csv\n",
        "    df_test = pd.read_csv(\"test.csv\", dtype={'onpromotion': int},parse_dates=[\"date\"] )\n",
        "\n",
        "    \"\"\"###Items Data\"\"\"\n",
        "\n",
        "    #Reading items.csv\n",
        "    items = pd.read_csv(\"items.csv\",)\n",
        "\n",
        "\n",
        "    #Setting item_nbr as the index of the dataframe\n",
        "    items = items.set_index(\"item_nbr\") \n",
        "\n",
        "\n",
        "    \"\"\"#### Label Encoding (item family)\"\"\"\n",
        "\n",
        "    #initializing label encoder\n",
        "    encoder = LabelEncoder()\n",
        "    #transforming item family column\n",
        "    items['family'] = encoder.fit_transform(items['family'].values)\n",
        "\n",
        "    \"\"\"### Stores Data\"\"\"\n",
        "\n",
        "    #Reading store.csv\n",
        "    stores = pd.read_csv(\"stores.csv\")\n",
        "\n",
        "    # Setting store_nbr as the index of the dataframe\n",
        "    stores = stores.set_index(\"store_nbr\")\n",
        "\n",
        "    \"\"\"#### Label Encoding on store state, city and type\"\"\"\n",
        "\n",
        "    #initializing label encoder\n",
        "    encoder = LabelEncoder()\n",
        "    #transforming state column\n",
        "    stores['state'] = encoder.fit_transform(stores['state'].values)\n",
        "    #transforming city column\n",
        "    stores['city'] = encoder.fit_transform(stores['city'].values)\n",
        "    #transforming type column\n",
        "    stores['type'] = encoder.fit_transform(stores['type'].values)\n",
        "\n",
        "\n",
        "    \"\"\"### Train Data\"\"\"\n",
        "\n",
        "    #Skipping rows from 1 to 101688780‬ i.e. reading 2017 data only.\n",
        "    df_train = pd.read_csv('train.csv', dtype={'onpromotion': int}, parse_dates=[\"date\"],converters={'unit_sales': lambda u: np.log1p(\n",
        "        float(u)) if float(u) > 0 else 0}, skiprows=range(1,101688780))\n",
        "\n",
        "    #Dropping Id Column\n",
        "    df_train=df_train.drop('id',axis=1)\n",
        "\n",
        "    \n",
        "    return df_train,df_test,stores,items\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0oWnibzqjwd",
        "colab_type": "text"
      },
      "source": [
        "#### Data based on item_nbr.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9S4fiBOmz2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_itemnbr(promo_2017,sales_2017):\n",
        "    \n",
        "    ''' Prepares Data based on  item_nbr. '''\n",
        "\n",
        "    ##### Promotion Data\n",
        "\n",
        "    #Grouping promotions by item no. over time and filtering only that columns that are in promo_2017 Dataframe.\n",
        "    promo_item_2017 = promo_2017.groupby('item_nbr')[promo_2017.columns].sum()\n",
        "    #promo_item_2017.head()\n",
        "\n",
        "    \"\"\"##### Sales Data\"\"\"\n",
        "\n",
        "    #Grouping sales by item no. through time and keeping only that columns that are present in sales dataframe\n",
        "    sales_item_2017 = sales_2017.groupby('item_nbr')[sales_2017.columns].sum()\n",
        "    #sales_item_2017.head()\n",
        "    \n",
        "    return promo_item_2017,sales_item_2017\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E696LJuWqwCF",
        "colab_type": "text"
      },
      "source": [
        "#### Data based on store_nbr and item_nbr pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Wz1_6Lm0kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_storenbr_itemnbr(df_train,df_test):\n",
        "    ''' Prepares Data based on store_nbr and item_nbr pairs. '''\n",
        "\n",
        "    ##### Promotion Data\n",
        "\n",
        "    #Setting store_nbr, item_nbr and date as the indices.\n",
        "    promo_2017_train = df_train.set_index([\"store_nbr\", \"item_nbr\", \"date\"])\n",
        "\n",
        "    #Using promotions column only and unstacking the dates\n",
        "    promo_2017_train= promo_2017_train[[\"onpromotion\"]].unstack(level=-1)\n",
        "\n",
        "    #Filling the missing values with 0.\n",
        "    promo_2017_train = promo_2017_train.fillna(0)\n",
        "\n",
        "    #promo_2017_train.head()\n",
        "\n",
        "    # Deleting 1st row\n",
        "    promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
        "    promo_2017_train.head()\n",
        "\n",
        "    #Setting store_nbr, item_nbr and date as the indices of the dataframe\n",
        "    promo_2017_test = df_test.set_index(['store_nbr', 'item_nbr', 'date'])\n",
        "\n",
        "    #Using promotions column only and unstacking the dates\n",
        "    promo_2017_test = promo_2017_test[[\"onpromotion\"]].unstack(level=-1).fillna(0)\n",
        "\n",
        "    #Filling the missing information with 0.\n",
        "    promo_2017_test = promo_2017_test.fillna(0)\n",
        "\n",
        "    # Deleting 1st row\n",
        "    promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
        "    #promo_2017_test.head()\n",
        "\n",
        "    #Removing Items from test dataset that are not in train dataset \n",
        "    #Adding Items that are not in the test dataset and filling values with 0\n",
        "\n",
        "    #Re-indexing with train dataframe index. By default values in the new index that do not have corresponding records in the dataframe are assigned NaN\n",
        "    promo_2017_test = promo_2017_test.reindex(promo_2017_train.index)\n",
        "\n",
        "    #Filling the missing information with 0.\n",
        "    promo_2017_test = promo_2017_test.fillna(0)\n",
        "\n",
        "    #promo_2017_test.head()\n",
        "\n",
        "    #Concatenating train and test datasets\n",
        "    promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
        "    #promo_2017.head()\n",
        "\n",
        "    # Deleting unneccesary variables\n",
        "    del promo_2017_test, promo_2017_train , df_test \n",
        "\n",
        "    \"\"\"##### Sales Data\"\"\"\n",
        "\n",
        "    #Setting store_nbr, item_nbr and date as the indices.\n",
        "    sales_2017 = df_train.set_index([\"store_nbr\", \"item_nbr\", \"date\"])\n",
        "\n",
        "    #Using unit_sales column only and unstacking the dates\n",
        "    sales_2017 = sales_2017[[\"unit_sales\"]].unstack(level=-1)\n",
        "\n",
        "    #Filling the missing values with 0's.\n",
        "    sales_2017 = sales_2017.fillna(0)\n",
        "    # Deleting 1st row\n",
        "    sales_2017.columns = sales_2017.columns.get_level_values(1)\n",
        "\n",
        "    #sales_2017.head()\n",
        "    del df_train\n",
        "    \n",
        "    return sales_2017,promo_2017"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veSZwsVOq3YA",
        "colab_type": "text"
      },
      "source": [
        "#### Data based on item_class and store_nbr pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRfDiN78nPRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_itemclass_storenbr(items ,stores,sales_2017 ,promo_2017):\n",
        "    ''' Prepares Data based on item_class and store_nbr pairs. '''\n",
        "    \n",
        "    #Removing items that are not present in year 2017.\n",
        "\n",
        "    #Re-indexing by using index of sales_2017 dataframe.\n",
        "    items = items.reindex(sales_2017.index.get_level_values(1))\n",
        "\n",
        "    #Removing stores that are not present in year 2017.\n",
        "\n",
        "    #Re-indexing by using index of sales_2017 dataframe.\n",
        "    stores = stores.reindex(sales_2017.index.get_level_values(0))\n",
        "\n",
        "    \"\"\"##### Promotion Data\"\"\"\n",
        "\n",
        "    #Fetching promotion data with new sequential index\n",
        "    store_class_promo_2017 = promo_2017.reset_index()\n",
        "\n",
        "    #Adding class column\n",
        "    store_class_promo_2017['class'] = items['class'].values\n",
        "\n",
        "    #Grouping promotions by item class and store no. and filtering on;y that columns that are in promo_2017 Dataframe\n",
        "    store_class_promo_2017 = store_class_promo_2017.groupby(['class', 'store_nbr'])[promo_2017.columns].sum()\n",
        "    #store_class_promo_2017.head()\n",
        "\n",
        "    \"\"\"##### Sales Data\"\"\"\n",
        "\n",
        "    #Fetching sales data with new sequential index\n",
        "    store_class_sales_2017 = sales_2017.reset_index()\n",
        "\n",
        "    #Adding class column\n",
        "    store_class_sales_2017['class'] = items['class'].values \n",
        "\n",
        "    # Storing Item class and store_nbr pairs used for indexing later\n",
        "    store_class_index = store_class_sales_2017[['class', 'store_nbr']]\n",
        "\n",
        "    #Grouping sales by item class and store no. and keeping only that columns present in sales dataframe\n",
        "    store_class_sales_2017 = store_class_sales_2017.groupby(['class', 'store_nbr'])[sales_2017.columns].sum()\n",
        "    \n",
        "    return items,stores,store_class_promo_2017,store_class_index,store_class_sales_2017\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoKmJh99r_sL",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk0lXBYrn85-",
        "colab_type": "text"
      },
      "source": [
        "#### Function for Filtering Data Between dates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ny4PHI8oKwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_timespan(df, Date, minus, periods, freq='D'):\n",
        "    '''Selects ony that dataframe columns which correspond to \n",
        "    the \"periods\" days after the (Date-minus) day .'''\n",
        "\n",
        "    \n",
        "    if minus!=0:\n",
        "        return df[pd.date_range(Date - timedelta(days=minus), periods=periods, freq=freq)]\n",
        "    else:\n",
        "        return df[pd.date_range(Date , periods=periods, freq=freq)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJJcMmNvoLlr",
        "colab_type": "text"
      },
      "source": [
        "#### Function for Creating Promotional Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d8ThCQjobzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def promo_features(promotions,Date,X):\n",
        "    '''Creates features related to promotion'''\n",
        "\n",
        "    \n",
        "    # Sum of Promotions with past data at different day intervals.\n",
        "    for n_days in [14,60,140]:\n",
        "\n",
        "        # Filtering promotions of items from (date-n_days) to (date).\n",
        "        filtered_promo = get_timespan(promotions, Date, n_days, n_days)\n",
        "\n",
        "        # Sum of Promotions for each item sold over date.\n",
        "        X['%sdays_promo_sum (past)'%n_days]=filtered_promo.sum(axis=1).values\n",
        "\n",
        "    # Sum of Promotions with future data at different day intervals.\n",
        "    future_date = Date + timedelta(days=1)  #Shifting date ahead \n",
        "    for n_days in [3,7,14]:\n",
        "\n",
        "        # Filtering promotions of items from (date) to (date+n_days)\n",
        "        filtered_promo = get_timespan(promotions, future_date, 0, n_days)\n",
        "\n",
        "        # Sum of Promotions for each item sold over date.\n",
        "        X['%sdays_promo_sum (future)'%n_days]=filtered_promo.sum(axis=1).values\n",
        "\n",
        "\n",
        "    # Promotion feature (i.e. if there is a promotion or not) for 16 days in past and future.\n",
        "    for n_day in range(-16, 16):\n",
        "\n",
        "        if n_day<0:\n",
        "            flag='past'\n",
        "        elif n_day > 0:\n",
        "            flag='future'\n",
        "        else:\n",
        "            flag='present'\n",
        "\n",
        "        #Promotion feature for each item sold on n_day.\n",
        "        X[\"promo_day{} ({})\".format(abs(n_day),flag)] = promotions[Date + timedelta(days=n_day)].values.astype(np.uint8)\n",
        "\n",
        "    return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQWjE0Y1oeXG",
        "colab_type": "text"
      },
      "source": [
        "#### Function for Creating Sales Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozOrFOOdoo60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def sales_features(sales,Date,X,past_week=False):\n",
        "    '''Creates features related to Sales'''\n",
        "    \n",
        "    name=''\n",
        "    if past_week==True:\n",
        "        name=\" (past_week)\"\n",
        "        Date = Date - timedelta(days=7) # past_week_date is date - 7 days\n",
        "\n",
        "    for n_days in [3, 7, 14, 30, 60, 140]:\n",
        "\n",
        "        # Filtering sales of items n_days before t2017 to t2017\n",
        "        filtered_sales = get_timespan(sales, Date, n_days, n_days)\n",
        "\n",
        "        # mean of sales of each item over date\n",
        "        X['%sdays_sale_mean' % n_days + name] = filtered_sales.mean(axis=1).values\n",
        "\n",
        "        # exponentially weighted sum_of_sales of each item over date\n",
        "        exp_weights = np.power(0.9, np.arange(n_days)[::-1])\n",
        "        X['%sdays_weighted_sale' % n_days + name] = (filtered_sales * exp_weights ).sum(axis=1).values\n",
        "\n",
        "        # mean of difference in sales of each item over date\n",
        "        X['%sdays_sale_diff_mean' % n_days + name] = filtered_sales.diff(axis=1).mean(axis=1).values\n",
        "\n",
        "        # median of sales of each item over date\n",
        "        X['%sdays_sale_median' % n_days + name] = filtered_sales.median(axis=1).values\n",
        "\n",
        "        # min. of sales of each item over date\n",
        "        X['%sdays_min_sale' % n_days + name] = filtered_sales.min(axis=1).values\n",
        "\n",
        "        # max. of sales of each item over date\n",
        "        X['%sdays_max_sale' % n_days + name] = filtered_sales.max(axis=1).values\n",
        "\n",
        "        # std. of sales of each item over date\n",
        "        X['%sdays_sale_std' % n_days + name] = filtered_sales.std(axis=1).values\n",
        "\n",
        "\n",
        "    # Sales on the nth day in past\n",
        "    for n_day in range(1, 16):\n",
        "        X['sales(past_day_%s)' % n_day] = get_timespan(sales, Date, n_day, 1).values.ravel()\n",
        "\n",
        "\n",
        "    \n",
        "    for n_day in range(7):\n",
        "        # mean of sales every same day of week during 4 weeks before today\n",
        "        X['dow%s_mean_sales(4weeks)' % n_day ] = get_timespan(sales, Date, 28-n_day, 4, freq='7D').mean(axis=1).values\n",
        "        # mean of sales every same day of week during  20 weeks before today\n",
        "        X['dow%s_mean_sales(20weeks)' % n_day] = get_timespan(sales, Date, 140-n_day, 20, freq='7D').mean(axis=1).values\n",
        "    \n",
        "    \n",
        "    return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kyk58SKorXR",
        "colab_type": "text"
      },
      "source": [
        "#### Function for Creating Sales Features Depending on Promotion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZhKuz-Io-cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sales_promo_features(sales,promotions,Date,X):\n",
        "    '''Creates features related to Sales and promotion'''\n",
        "\n",
        "    for n_days in [3, 7, 14, 30, 60, 140]:\n",
        "\n",
        "        # Filtering sales of items from (date-n_days) to (date)\n",
        "        filtered_sales = get_timespan(sales, Date, n_days, n_days)\n",
        "\n",
        "        # Filtering promotion on items from (date-n_days) to (date)\n",
        "        filtered_promo = get_timespan(promotions, Date, n_days, n_days)\n",
        "\n",
        "        # mean_of_sales of each item sold on promotion over date\n",
        "        sales_with_promo = filtered_sales * filtered_promo.replace(0, np.nan)           #replacing 0's with nan so that these values get ignored while calculating mean.\n",
        "        X['%sdays_sale_mean(promo)' % n_days] =sales_with_promo.mean(axis=1).values     #pandas DataFrame.mean ignore nan values\n",
        "\n",
        "        # exponentially weighted sum_of_sales of each item sold on promotion over date\n",
        "        exp_weights = np.power(0.9, np.arange(n_days-1,-1,-1))                            \n",
        "        X['%sdays_weighted_sale(promo)' % n_days] = (sales_with_promo * exp_weights).sum(axis=1).values   #Giving more weightage to recent dated sales and decreasing weight with date.\n",
        "        \n",
        "        # mean_of_sales of each item sold without promotion over date\n",
        "        sales_without_promo = filtered_sales * (1 - filtered_promo).replace(0, np.nan)       #replacing 0's with nan so that these values get ignored while calculating mean.\n",
        "        X['%sdays_sale_mean(no_promo)' % n_days] = sales_without_promo.mean(axis=1).values   #pandas DataFrame.mean ignore nan values\n",
        "\n",
        "        # exponentially weighted sum_of_sales of each item sold without promotion over date\n",
        "        X['%sdays_weighted_sale(no_promo)' % n_days] = ( sales_without_promo * exp_weights).sum(axis=1).values \n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YWcT25EpAZ1",
        "colab_type": "text"
      },
      "source": [
        "#### Function for Creating Count Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5i2lCVjpVtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_features(data,Date,X,name):\n",
        "    '''Creates Count features related to Sales and promotion'''\n",
        "\n",
        "    \n",
        "    # Number of days a sale / promotion took place in the time window, and days since first / last sale / promotion\n",
        "    for n_days in [7, 14, 30, 60, 140]:\n",
        "\n",
        "        # Filtering data from (date-n_days) to (date)\n",
        "        filtered_data = get_timespan(data, Date, n_days, n_days)\n",
        "\n",
        "        # Number of days a sale/promotion was made/present (i.e. not equal to 0) for each item\n",
        "        X['num_days_having%s(last_%sdays)' % (name,n_days)] = (filtered_data > 0).sum(axis=1).values\n",
        "\n",
        "        # Number of days since last sale/promotion (in n_days) for each item\n",
        "        X['num_days_since_Last%s(last_%sdays)'  % (name,n_days)] = n_days - ((filtered_data > 0) * np.arange(n_days)).max(axis=1).values\n",
        "\n",
        "        # Number of days since first sale/promotion (in n_days) for each item\n",
        "        X['num_days_since_First%s(last_%sdays)' % (name,n_days)] = ((filtered_data > 0) * np.arange(n_days, 0, -1)).max(axis=1).values\n",
        "\n",
        "    if name=='Promo':\n",
        "        # Number of promotions in the next 15 days, time before first and last promotion in the same time window\n",
        "        Date = Date + timedelta(days=16)\n",
        "        filtered_promo = get_timespan(data,Date, 15, 15)\n",
        "        X['num_days_having%s(after_%sdays)' % (name,n_days)] = (filtered_promo > 0).sum(axis=1).values\n",
        "        X['num_days_since_Last%s(after_%sdays)'  % (name,n_days)] = 15 - ((filtered_promo > 0) * np.arange(15)).max(axis=1).values\n",
        "        X['num_days_since_First%s(after_%sdays)' % (name,n_days)] = ((filtered_promo > 0) * np.arange(15, 0, -1)).max(axis=1).values\n",
        "\n",
        "    return X\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owcavBDWpYeU",
        "colab_type": "text"
      },
      "source": [
        "#### Function for Creating All the Custom Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k85xr3lMphiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_features(sales, promotions, Date, name_prefix=None):\n",
        "    '''Creates all the custom features'''\n",
        "\n",
        "    #Creating empty dictionary for adding features\n",
        "    X={}\n",
        "    # Features only dependent on promotions\n",
        "    X = promo_features(promotions,Date,X)\n",
        "    X = count_features(promotions,Date,X,name='Promo')\n",
        "\n",
        "    # Features only dependent on unit_sales\n",
        "    X = sales_features(sales,Date,X)\n",
        "    X = count_features(sales,Date,X,name='Sales')\n",
        "    # For Past_week\n",
        "    X = sales_features(sales,Date,X,past_week=True)\n",
        "\n",
        "    # Features dependent on both promotions and unit_sales\n",
        "    X = sales_promo_features(sales,promotions,Date,X)\n",
        "\n",
        "    # Creating Dataframe from dictionary having keys as column names and values as column values\n",
        "    X = pd.DataFrame(X)\n",
        "    X = reduce_mem_usage(X)\n",
        "    if name_prefix is not None:\n",
        "        #Replacing column names by adding prefix to each column name\n",
        "        X.columns = [ name_prefix + ' ' + c for c in X.columns]\n",
        "        \n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFH3YA92pjN9",
        "colab_type": "text"
      },
      "source": [
        "#### Function for Creating Dataset Having Custom Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OAK0e4wpxjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def creating_dataset(data, data_item, data_store_class, items, stores, Date, n_weeks,return_labels=True):\n",
        "    \n",
        "    '''Creates dataset having custom features'''\n",
        "\n",
        "\n",
        "    #Format --> data=(sales,promo)\n",
        "    sales = data[0]\n",
        "    promo = data[1]\n",
        "\n",
        "    #Format --> data_item=(sales_item,promo_item)\n",
        "    sales_item = data_item[0]\n",
        "    promo_item = data_item[1]\n",
        "\n",
        "    #Format --> data_store_class=(store_class_sales,store_class_promo)\n",
        "    store_class_sales = data_store_class[0]\n",
        "    store_class_promo = data_store_class[1]\n",
        "    store_class_index = data_store_class[2]\n",
        "    del data,data_item,data_store_class\n",
        "    X = []\n",
        "    Y = []\n",
        "    \n",
        "    #Creating features for every week one by one\n",
        "    for i in range(n_weeks):\n",
        "\n",
        "        # Creating features using sales of each store_nbr and item_nbr pair \n",
        "        x1 = custom_features(sales, promo, Date)\n",
        "\n",
        "        # Creating features using sales of each item_nbr \n",
        "        x2 = custom_features(sales_item, promo_item, Date, name_prefix='item')\n",
        "        # Setting item_nbr as index\n",
        "        x2.index = sales_item.index\n",
        "        # Re-indexing item_nbr acc. to order of item_nbr in sales dataframe\n",
        "        x2 = x2.reindex(sales.index.get_level_values(1))    \n",
        "        # Resetting index with a sequential index and dropping old index\n",
        "        x2 = x2.reset_index(drop=True)     \n",
        "\n",
        "        # Creating features using sales of each item_class and store_nbr pair\n",
        "        x3 = custom_features(store_class_sales, store_class_promo, Date,  name_prefix='store_class')\n",
        "        # Setting item_class and store_nbr as index\n",
        "        x3.index = store_class_sales.index\n",
        "        # Re-indexing item_nbr acc. to order of item_nbr in sales dataframe\n",
        "        x3 = x3.reindex( pd.MultiIndex.from_frame(store_class_index))\n",
        "        # Resetting index with a sequential index and dropping old index\n",
        "        x3 = x3.reset_index(drop=True)   \n",
        "\n",
        "        #Concatenating(horizontally) all the above custom created features and given store and item features.\n",
        "        x = pd.concat([x1, x2, x3, items.reset_index(), stores.reset_index()], axis=1)\n",
        "        #Appending data of each week in final dataset \n",
        "        X.append(x)\n",
        "        \n",
        "        del x,x1,x2,x3\n",
        "\n",
        "        #True sales for the following 16 days (that is to be predicted)\n",
        "        try :\n",
        "            y = sales[pd.date_range(Date, periods=16)].values\n",
        "            Y.append(y)\n",
        "            del y\n",
        "        except:\n",
        "            pass\n",
        "            \n",
        "        # Adding 7 days i.e shifting to next week.\n",
        "        Date = Date + timedelta(days=7)\n",
        "        \n",
        "    X = pd.concat(X, axis=0)\n",
        "\n",
        "    if return_labels==True:\n",
        "        Y = np.concatenate(Y, axis=0)\n",
        "        return X,Y\n",
        "    else:\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8OjEMo8p9Cw",
        "colab_type": "text"
      },
      "source": [
        "### Create Feature Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "001qh8nUmV1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_feature_set(Date):    \n",
        "    ''' Creates feature set '''\n",
        "\n",
        "    \n",
        "    df_train,df_test,stores,items = read_process()\n",
        "\n",
        "    sales_2017,promo_2017 = data_storenbr_itemnbr(df_train,df_test)\n",
        "    promo_item_2017,sales_item_2017 = data_itemnbr(promo_2017,sales_2017)\n",
        "    items,stores,store_class_promo_2017,store_class_index,store_class_sales_2017=data_itemclass_storenbr(items,stores,sales_2017,promo_2017)\n",
        "\n",
        "    \"\"\"#### Defining Data\"\"\"\n",
        "\n",
        "    #data of each store_nbr and item_nbr pair\n",
        "    data=(sales_2017,promo_2017)\n",
        "\n",
        "    #data of each item_nbr\n",
        "    data_item=(sales_item_2017,promo_item_2017)\n",
        "\n",
        "    #data of each item_class and store_nbr pair\n",
        "    data_store_class=(store_class_sales_2017,store_class_promo_2017,store_class_index)\n",
        "\n",
        "    #Deleting unnecessary variables\n",
        "    del promo_2017,sales_item_2017, promo_item_2017, store_class_sales_2017, store_class_promo_2017\n",
        "\n",
        "\n",
        "    \"\"\"#### Creating Feature Set\"\"\"\n",
        "\n",
        "    #no. of weeks for which features have to created\n",
        "    n_weeks = 1\n",
        "\n",
        "    features = creating_dataset(data, data_item, data_store_class, items, stores, Date, n_weeks, return_labels=False)\n",
        "\n",
        "\n",
        "    #Deleting unnecessary variables\n",
        "    del data, data_item,data_store_class\n",
        "\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRHO0wGsKT1w",
        "colab_type": "text"
      },
      "source": [
        "## Function 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk7U8kFT31Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_transform(arr):\n",
        "    ''' Transforms array taking log(x+1) for every element (x) '''\n",
        "\n",
        "    new_arr=[]\n",
        "    for value in arr:\n",
        "        if float(value) > 0:\n",
        "            value=np.log1p(float(value))\n",
        "        else:\n",
        "            value=0\n",
        "        new_arr.append(value)\n",
        "    return np.array(new_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vli9ulo347w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_nwrmsle(true,pred,weight):\n",
        "    ''' \n",
        "    Calculates Normalized Weighted Root Mean Squared Logarithmic Error (nwrmsle)\n",
        "\n",
        "    true = true labels\n",
        "    pred =  predicted labels\n",
        "    weight = weights of datapoints\n",
        "\n",
        "    returns nwrmsle '''\n",
        "\n",
        "    temp=(log_transform(true) - log_transform(pred))**2\n",
        "    temp = temp * weight\n",
        "    nwrmsle = np.sqrt(temp.sum() / weight.sum() )\n",
        "    return nwrmsle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjo_yM5-4D8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X_query):\n",
        "    ''' Predicts sales using the saved models\n",
        "        given query dataframe'''\n",
        "    \n",
        "    # Loading Top 300 Feature Names (got by training random forest)\n",
        "    import pickle\n",
        "    with open('/content/drive/My Drive/self_case_study1/300_filtered_features.pkl','rb') as file:\n",
        "        filtered_features = pickle.load( file)\n",
        "\n",
        "    # Loading Saved Models (16 LGBM Models)\n",
        "    print(\"Loading Models ...\")\n",
        "    import pickle\n",
        "    with open('/content/drive/My Drive/self_case_study1/final_models.pkl', 'rb') as file:\n",
        "        models = pickle.load(file)\n",
        "\n",
        "\n",
        "    print(\"Creating Features ...\")\n",
        "    Date = X_query.iloc[0]['date']\n",
        "    model_no = 0\n",
        "\n",
        "    if Date > pd.to_datetime('2017-08-16'):\n",
        "        model_no = (Date  -  pd.to_datetime('2017-08-16')).days\n",
        "        Date = pd.to_datetime('2017-08-16')\n",
        "\n",
        "    features = create_feature_set(Date)\n",
        "    features = features.set_index([\"store_nbr\", \"item_nbr\"])\n",
        "\n",
        "    #Fetching all unique dates\n",
        "    Dates = X_query.date.unique()\n",
        "    date_column = [ ]\n",
        "\n",
        "    y_pred = np.array([])\n",
        "    temp_df = pd.DataFrame()\n",
        "\n",
        "    print(\"Predicting ...\")\n",
        "    for i,Date in tqdm(enumerate(Dates)):\n",
        "\n",
        "        #Fetching data for each Date\n",
        "        batch = X_query[X_query['date'] == Date]\n",
        "        batch = batch.set_index([\"store_nbr\", \"item_nbr\"])\n",
        "        batch = features.reindex(batch.index)\n",
        "        batch.dropna(axis = 0 , how='all' , inplace=True)\n",
        "        batch.reset_index(inplace=True)\n",
        "        if i == 0:\n",
        "            temp_df = batch[['store_nbr','item_nbr']]\n",
        "        else:\n",
        "            temp_df = pd.concat([temp_df,batch[['store_nbr','item_nbr']]])\n",
        "\n",
        "        #Filtering Features\n",
        "        X = batch[filtered_features[model_no]]\n",
        "\n",
        "        #Predicting \n",
        "        y_pred = np.append( y_pred , models[model_no].predict(X) )\n",
        "        model_no = model_no + 1\n",
        "\n",
        "        for j in range(0,batch.shape[0]):\n",
        "            date_column.append(Date)\n",
        "\n",
        "        del X,batch\n",
        "\n",
        "    #Adding date column\n",
        "    temp_df['date'] = date_column\n",
        "\n",
        "    # setting index as store_nbr,item_nbr,date\n",
        "    temp_df  = temp_df.set_index([\"store_nbr\", \"item_nbr\",'date']) \n",
        "    X_query = X_query.set_index([\"store_nbr\", \"item_nbr\",'date'])\n",
        "\n",
        "    # Creating Dataframe with test predicitons and setting index same as temp_df Dataframe (i.e. str_nbr, item_nbr)\n",
        "    df_preds = pd.DataFrame(y_pred , columns = ['unit_sales'] , index=temp_df.index )   \n",
        "\n",
        "    # Setting names of the indices\n",
        "    df_preds.index.set_names([\"store_nbr\", \"item_nbr\",\"date\"], inplace=True)\n",
        "\n",
        "    # Joining the given query dataset(X_query) for which predictions were to be made\n",
        "    # and the dataframe in which predicited values are present\n",
        "    predicitons = X_query[['id']].join(df_preds, how=\"left\").fillna(0) #The prediciton is only done for 16 days so the other days sales will be filled with 0\n",
        "\n",
        "    # Converting predicted unit_sales back to orginal form by taking exp(unit_sales) - 1 as it was previously converted using log(unit_sales) + 1\n",
        "    predicitons[\"unit_sales\"] = np.clip(np.expm1(predicitons[\"unit_sales\"]), 0, 1000)\n",
        "\n",
        "    return predicitons[\"unit_sales\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P-n8pHw4x7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Function_1(X_query):\n",
        "    ''' Returns sale predictions given raw input '''\n",
        "\n",
        "    if type(X_query)== np.ndarray:\n",
        "        print(\"Got Array as an Input ...\")\n",
        "\n",
        "        #Re-shaping if the array has only 1 row\n",
        "        try:\n",
        "            X_query=X_query.reshape(1,5)\n",
        "        except:\n",
        "            pass\n",
        "        #Creating Dataframe\n",
        "        X_query=pd.DataFrame(X_query)\n",
        "        \n",
        "    elif type(X_query)==pd.DataFrame:\n",
        "        print(\"Got Dataframe as an Input ...\")\n",
        "\n",
        "    #Assigning column names\n",
        "    X_query.columns = ['id','date','store_nbr','item_nbr','onpromotion']\n",
        "    #Changing datatypes of 'date' and 'onpromotion' columns\n",
        "    X_query['date']= X_query['date'].astype('datetime64[ns]')\n",
        "    X_query['onpromotion'] = X_query['onpromotion'].astype('int')\n",
        "    #Predicting Sales\n",
        "    y_pred = predict(X_query)\n",
        "\n",
        "    return X_query,y_pred     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKhyiG3D5eQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "9f200152-73e7-4bd8-ae16-d77685664717"
      },
      "source": [
        "# Sample Data for Testing Function 1\n",
        "\n",
        "X_query = pd.read_csv('test.csv')\n",
        "X_query = X_query.to_numpy()\n",
        "X_query"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[125497040, '2017-08-16', 1, 96995, False],\n",
              "       [125497041, '2017-08-16', 1, 99197, False],\n",
              "       [125497042, '2017-08-16', 1, 103501, False],\n",
              "       ...,\n",
              "       [128867501, '2017-08-31', 54, 2132945, False],\n",
              "       [128867502, '2017-08-31', 54, 2132957, False],\n",
              "       [128867503, '2017-08-31', 54, 2134244, False]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2HIOQQaHzPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "59f375a2b8b04678a15274ea8533fa93",
            "1a6b61ffe08144188a9d7af4dd944559",
            "8dedbfc3d5b34ffabc22cae9ef998930",
            "b889abfccba64c39af9ff1765bc65ddd",
            "02655e7f0375403a8c79e77ab4fff9ec",
            "bab852b3801c40eda7039353b5aef6ce",
            "3ac22252566c4bd58e659b0bf6aa6cbc",
            "e969869e917c427f93de02da0f36f289"
          ]
        },
        "outputId": "90c9cd24-38df-446e-fde7-400c577e69f0"
      },
      "source": [
        "_,y_pred = Function_1(X_query)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got Array as an Input ...\n",
            "Loading Models ...\n",
            "Creating Features ...\n",
            "Predicting ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f375a2b8b04678a15274ea8533fa93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrqzak_6HI-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5e630bf3-ed92-4d8f-d72e-287386b4110b"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.21727337, 0.26708205, 0.        , ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9eNHKOkKWRh",
        "colab_type": "text"
      },
      "source": [
        "## Function 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc-VCPsb37iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Function_2(X_query,true):\n",
        "    ''' Returns NWRMSLE score given raw input '''\n",
        "    \n",
        "    #Prediciting sales \n",
        "    X_query , y_pred = Function_1(X_query)\n",
        "\n",
        "    #Fetching weights\n",
        "    items=pd.read_csv(\"items.csv\")\n",
        "    weight=(X_query.merge( items, on ='item_nbr', how='left')['perishable']) * 0.25 + 1\n",
        "\n",
        "    #Calculating score\n",
        "    score = calculate_nwrmsle(true,y_pred,weight.values)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqoHsu2_NY5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "d1d77414-fbeb-4efd-99a0-89917e766963"
      },
      "source": [
        "# Sample Data for Testing Function 2\n",
        "\n",
        "X_query = pd.read_csv('train.csv', parse_dates=[\"date\"], skiprows=range(1,104688780))\n",
        "X_query = X_query[(X_query.date >= pd.to_datetime('2017-07-31')) & (X_query.date < pd.to_datetime('2017-08-16')) ]\n",
        "X_query['date']=X_query['date'].astype(str)\n",
        "true = X_query['unit_sales'].values\n",
        "del X_query['unit_sales']\n",
        "X_query = X_query.to_numpy()\n",
        "X_query "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[123819696, '2017-07-31', 1, 96995, False],\n",
              "       [123819697, '2017-07-31', 1, 103520, False],\n",
              "       [123819698, '2017-07-31', 1, 103665, False],\n",
              "       ...,\n",
              "       [125497037, '2017-08-15', 54, 2110456, False],\n",
              "       [125497038, '2017-08-15', 54, 2113914, True],\n",
              "       [125497039, '2017-08-15', 54, 2116416, False]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDTEKS0CH1fu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "7c2a26edc1644bfead378282a980d487",
            "4b744174a06a41b196b9098a398f2e05",
            "68b13a87cb374a7aa1218af453b5ceae",
            "8992519e628e48e79c5b9dc484f735cc",
            "5b54196bb3b54c79bcc3dde2f99831b3",
            "890122267f4e41bab23b1e9e80e67df2",
            "e645fc343f084ce792c967fb0dfc5fa6",
            "3bebe896ab6e4afd9f2ead54292d89a2"
          ]
        },
        "outputId": "2d91a2fd-1671-4a11-a2a3-fd98993de1e4"
      },
      "source": [
        "score = Function_2(X_query,true)\n",
        "print(\"Nwrmsle Score --> \",score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got Array as an Input ...\n",
            "Loading Models ...\n",
            "Creating Features ...\n",
            "Predicting ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c2a26edc1644bfead378282a980d487",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Nwrmsle Score -->  0.5897288589434172\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}