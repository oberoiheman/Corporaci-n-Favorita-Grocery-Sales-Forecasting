{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNVpaWaSi_dC"
   },
   "source": [
    "### Enable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "yBBegewm6ZOl",
    "outputId": "fb4420a2-2a6b-416d-d11a-b89afb858faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LightGBM'...\n",
      "remote: Enumerating objects: 5, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 18291 (delta 0), reused 0 (delta 0), pack-reused 18286\u001b[K\n",
      "Receiving objects: 100% (18291/18291), 12.28 MiB | 21.88 MiB/s, done.\n",
      "Resolving deltas: 100% (13362/13362), done.\n",
      "/content/LightGBM\n",
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
      "-- Looking for CL_VERSION_2_2\n",
      "-- Looking for CL_VERSION_2_2 - found\n",
      "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
      "-- OpenCL include directory: /usr/include\n",
      "-- Boost version: 1.65.1\n",
      "-- Found the following Boost libraries:\n",
      "--   filesystem\n",
      "--   system\n",
      "-- Performing Test MM_PREFETCH\n",
      "-- Performing Test MM_PREFETCH - Success\n",
      "-- Using _mm_prefetch\n",
      "-- Performing Test MM_MALLOC\n",
      "-- Performing Test MM_MALLOC - Success\n",
      "-- Using _mm_malloc\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/LightGBM\n",
      "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
      "[  1%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
      "[  3%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
      "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
      "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 96%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
      "[ 98%] \u001b[32m\u001b[1mLinking CXX executable lightgbm\u001b[0m\n",
      "[ 98%] Built target lightgbm\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library lib_lightgbm.so\u001b[0m\n",
      "[100%] Built target _lightgbm\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
      "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
      "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
      "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
      "  python-setuptools python-six python-wheel python-xdg\n",
      "Suggested packages:\n",
      "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
      "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
      "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
      "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
      "The following NEW packages will be installed:\n",
      "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
      "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
      "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
      "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
      "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
      "0 upgraded, 22 newly installed, 0 to remove and 33 not upgraded.\n",
      "Need to get 3,376 kB of archives.\n",
      "After this operation, 10.5 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.3 [221 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.1 [1,653 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1.18.04.1 [151 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-xdg all 0.25-4ubuntu1 [31.3 kB]\n",
      "Fetched 3,376 kB in 1s (2,817 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 22.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package libpython-all-dev:amd64.\n",
      "(Reading database ... 144379 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package python-all.\n",
      "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking python-all (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package python-all-dev.\n",
      "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package python-asn1crypto.\n",
      "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
      "Unpacking python-asn1crypto (0.24.0-1) ...\n",
      "Selecting previously unselected package python-cffi-backend.\n",
      "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
      "Unpacking python-cffi-backend (1.11.5-1) ...\n",
      "Selecting previously unselected package python-crypto.\n",
      "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
      "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
      "Selecting previously unselected package python-enum34.\n",
      "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
      "Unpacking python-enum34 (1.1.6-2) ...\n",
      "Selecting previously unselected package python-idna.\n",
      "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
      "Unpacking python-idna (2.6-1) ...\n",
      "Selecting previously unselected package python-ipaddress.\n",
      "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
      "Unpacking python-ipaddress (1.0.17-1) ...\n",
      "Selecting previously unselected package python-six.\n",
      "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
      "Unpacking python-six (1.11.0-2) ...\n",
      "Selecting previously unselected package python-cryptography.\n",
      "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.3_amd64.deb ...\n",
      "Unpacking python-cryptography (2.1.4-1ubuntu1.3) ...\n",
      "Selecting previously unselected package python-dbus.\n",
      "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
      "Unpacking python-dbus (1.2.6-1) ...\n",
      "Selecting previously unselected package python-gi.\n",
      "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
      "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
      "Selecting previously unselected package python-secretstorage.\n",
      "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
      "Unpacking python-secretstorage (2.3.1-2) ...\n",
      "Selecting previously unselected package python-keyring.\n",
      "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
      "Unpacking python-keyring (10.6.0-1) ...\n",
      "Selecting previously unselected package python-keyrings.alt.\n",
      "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
      "Unpacking python-keyrings.alt (3.0-1) ...\n",
      "Selecting previously unselected package python-pip-whl.\n",
      "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
      "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
      "Selecting previously unselected package python-pip.\n",
      "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
      "Unpacking python-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
      "Selecting previously unselected package python-pkg-resources.\n",
      "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
      "Unpacking python-pkg-resources (39.0.1-2) ...\n",
      "Selecting previously unselected package python-setuptools.\n",
      "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
      "Unpacking python-setuptools (39.0.1-2) ...\n",
      "Selecting previously unselected package python-wheel.\n",
      "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
      "Unpacking python-wheel (0.30.0-0.2) ...\n",
      "Selecting previously unselected package python-xdg.\n",
      "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1_all.deb ...\n",
      "Unpacking python-xdg (0.25-4ubuntu1) ...\n",
      "Setting up python-idna (2.6-1) ...\n",
      "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
      "Setting up python-asn1crypto (0.24.0-1) ...\n",
      "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
      "Setting up python-wheel (0.30.0-0.2) ...\n",
      "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
      "Setting up python-pkg-resources (39.0.1-2) ...\n",
      "Setting up python-cffi-backend (1.11.5-1) ...\n",
      "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
      "Setting up python-six (1.11.0-2) ...\n",
      "Setting up python-enum34 (1.1.6-2) ...\n",
      "Setting up python-dbus (1.2.6-1) ...\n",
      "Setting up python-ipaddress (1.0.17-1) ...\n",
      "Setting up python-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
      "Setting up python-all (2.7.15~rc1-1) ...\n",
      "Setting up python-xdg (0.25-4ubuntu1) ...\n",
      "Setting up python-setuptools (39.0.1-2) ...\n",
      "Setting up python-keyrings.alt (3.0-1) ...\n",
      "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
      "Setting up python-cryptography (2.1.4-1ubuntu1.3) ...\n",
      "Setting up python-secretstorage (2.3.1-2) ...\n",
      "Setting up python-keyring (10.6.0-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (47.3.1)\n",
      "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/0b/71ae818646c1a80fbe6776d41f480649523ed31243f1f34d9d7e41d70195/numpy-1.19.0-cp36-cp36m-manylinux2010_x86_64.whl (14.6MB)\n",
      "\u001b[K     |████████████████████████████████| 14.6MB 199kB/s \n",
      "\u001b[?25hCollecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/20/d4410683e4d416a11ebc60138f6d925f571ffcfcc3794baf78fff982c98d/scipy-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9MB 90kB/s \n",
      "\u001b[?25hCollecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9MB 18.4MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.15.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, scipy, threadpoolctl, scikit-learn\n",
      "  Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed numpy-1.19.0 scikit-learn-0.23.1 scipy-1.5.0 threadpoolctl-2.1.0\n",
      "/content/LightGBM/python-package\n",
      "running install\n",
      "running build\n",
      "running build_py\n",
      "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
      "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/lightgbm\n",
      "copying lightgbm/engine.py -> build/lib/lightgbm\n",
      "copying lightgbm/compat.py -> build/lib/lightgbm\n",
      "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
      "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
      "copying lightgbm/basic.py -> build/lib/lightgbm\n",
      "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
      "copying lightgbm/callback.py -> build/lib/lightgbm\n",
      "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
      "running egg_info\n",
      "creating lightgbm.egg-info\n",
      "writing lightgbm.egg-info/PKG-INFO\n",
      "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
      "writing requirements to lightgbm.egg-info/requires.txt\n",
      "writing top-level names to lightgbm.egg-info/top_level.txt\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "no previously-included directories found matching 'build'\n",
      "warning: no files found matching 'LICENSE'\n",
      "warning: no files found matching '*.txt'\n",
      "warning: no files found matching '*.so' under directory 'lightgbm'\n",
      "warning: no files found matching '*.txt' under directory 'compile'\n",
      "warning: no files found matching '*.so' under directory 'compile'\n",
      "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
      "warning: no files found matching '*' under directory 'compile/compute'\n",
      "warning: no files found matching '*' under directory 'compile/include'\n",
      "warning: no files found matching '*' under directory 'compile/src'\n",
      "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
      "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
      "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
      "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
      "running install_lib\n",
      "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
      "copying ../lib_lightgbm.so -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/engine.py to engine.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/compat.py to compat.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/plotting.py to plotting.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py to sklearn.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/basic.py to basic.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/libpath.py to libpath.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/callback.py to callback.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/__init__.py to __init__.cpython-36.pyc\n",
      "running install_egg_info\n",
      "Copying lightgbm.egg-info to /usr/local/lib/python3.6/dist-packages/lightgbm-2.3.2-py3.6.egg-info\n",
      "running install_scripts\n"
     ]
    }
   ],
   "source": [
    "!git clone -- https://github.com/microsoft/LightGBM.git\n",
    "%cd /content/LightGBM\n",
    "!mkdir build\n",
    "!cmake -DUSE_GPU=1 #avoid ..\n",
    "!make -j$(nproc)\n",
    "!sudo apt-get -y install python-pip\n",
    "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n",
    "%cd /content/LightGBM/python-package\n",
    "!sudo python setup.py install --precompile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edpKYGBbjG50"
   },
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "fB3vnMXBx2fe",
    "outputId": "9af0aa96-f602-458f-fdbe-cc3aaceb584e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/87/310b52debfbc0cb79764e5770fa3f5c18f6f0754809ea9e2fc185e1b67d3/scikit_optimize-0.7.4-py2.py3-none-any.whl (80kB)\n",
      "\r",
      "\u001b[K     |████                            | 10kB 22.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 20kB 26.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 30kB 20.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 40kB 17.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 51kB 13.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 61kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 71kB 13.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 81kB 5.2MB/s \n",
      "\u001b[?25hCollecting pyaml>=16.9\n",
      "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.15.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-20.4.0 scikit-optimize-0.7.4\n"
     ]
    }
   ],
   "source": [
    "# installing scikit-optimize library for using gp minimize \n",
    "!pip3 install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-mMNgYLNu0K"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from functools import partial\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2-DbPcQ50Gl"
   },
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of Dataframe is {:.3f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in tqdm(df.columns):\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        elif 'datetime' not in col_type.name:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.3f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAYxORCE5tBg"
   },
   "source": [
    "### Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "H1YnRHGCxyDw",
    "outputId": "7a4b1dbf-37ea-4550-d4d7-0cb63b113b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-02 23:49:49--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/7391/44328/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1593984946&Signature=TZ8WhKQzNyAp%2B8IRIjBE3f9IPhSdR%2B8izTu2DDZLt1ZJS9M5q5pZsNpMGYYOCFwROdvxHPUf%2FIVoPslSOiRMcBdkBhumDs6xiOt9A5dzgUh6QqH3%2BzX%2F%2Be2FVjW2dg3a%2B%2FmqIwQLD7y%2B8gfRP82VlEMdGcxLLbRliMfy2ZK0BlMZgRZJ7%2BNmsdbm3V6Y%2Fk7YnIiDGH3bBopFwLN02mOhiqb96GC4gD813iLV5DRoSzegViOZjddjSBtKeNlFu86bo9oj2cjI%2BQrxQV%2F2I6IU1lKqXxkkdAl0oFzzfNUwlLForPg0nd8GMaYgdlM6Ga1liBl2QFahMYkwJUM6Hvv%2F6w%3D%3D&response-content-disposition=attachment%3B+filename%3Dfavorita-grocery-sales-forecasting.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.130.128, 74.125.68.128, 172.217.194.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.130.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 480014675 (458M) [application/zip]\n",
      "Saving to: ‘favorita-grocery-sales-forecasting.zip’\n",
      "\n",
      "favorita-grocery-sa 100%[===================>] 457.78M  38.4MB/s    in 12s     \n",
      "\n",
      "2020-07-02 23:50:02 (37.3 MB/s) - ‘favorita-grocery-sales-forecasting.zip’ saved [480014675/480014675]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading data (using wget)\n",
    "\n",
    "file_path=\"favorita-grocery-sales-forecasting.zip\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    !wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/7391/44328/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1593984946&Signature=TZ8WhKQzNyAp%2B8IRIjBE3f9IPhSdR%2B8izTu2DDZLt1ZJS9M5q5pZsNpMGYYOCFwROdvxHPUf%2FIVoPslSOiRMcBdkBhumDs6xiOt9A5dzgUh6QqH3%2BzX%2F%2Be2FVjW2dg3a%2B%2FmqIwQLD7y%2B8gfRP82VlEMdGcxLLbRliMfy2ZK0BlMZgRZJ7%2BNmsdbm3V6Y%2Fk7YnIiDGH3bBopFwLN02mOhiqb96GC4gD813iLV5DRoSzegViOZjddjSBtKeNlFu86bo9oj2cjI%2BQrxQV%2F2I6IU1lKqXxkkdAl0oFzzfNUwlLForPg0nd8GMaYgdlM6Ga1liBl2QFahMYkwJUM6Hvv%2F6w%3D%3D&response-content-disposition=attachment%3B+filename%3Dfavorita-grocery-sales-forecasting.zip\" -c -O 'favorita-grocery-sales-forecasting.zip'\n",
    "else:\n",
    "    print(\"File Already Present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FSyBdZCz0V68",
    "outputId": "502eb5ea-0a36-4d0c-9884-520a42f507c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  favorita-grocery-sales-forecasting.zip\n",
      "  inflating: holidays_events.csv.7z  \n",
      "  inflating: items.csv.7z            \n",
      "  inflating: oil.csv.7z              \n",
      "  inflating: sample_submission.csv.7z  \n",
      "  inflating: stores.csv.7z           \n",
      "  inflating: test.csv.7z             \n",
      "  inflating: train.csv.7z            \n",
      "  inflating: transactions.csv.7z     \n",
      "File unzipped Successfully\n"
     ]
    }
   ],
   "source": [
    "# unzipping favorita-grocery-sales-forecasting.zip\n",
    "\n",
    "if os.path.exists('favorita-grocery-sales-forecasting.zip'):\n",
    "    !unzip 'favorita-grocery-sales-forecasting.zip'\n",
    "    print(\"File unzipped Successfully\")\n",
    "else:\n",
    "    print(\"File Not Present to unzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "7kkS4sXr0bxq",
    "outputId": "5d125971-4b07-4933-f9c6-ff8da3567076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "p7zip-full is already the newest version (16.02+dfsg-6).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "#installing 7zip for extracting .7z files\n",
    "!apt-get install p7zip-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8ix7xDWx0e1j",
    "outputId": "7779867c-6dca-49f9-d77b-87d9c6923948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 666528 bytes (651 KiB)\n",
      "\n",
      "Extracting archive: sample_submission.csv.7z\n",
      "--\n",
      "Path = sample_submission.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 666528\n",
      "Headers Size = 146\n",
      "Method = LZMA2:24\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b 82% - sample_submission.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       40445582\n",
      "Compressed: 666528\n",
      "==================================================\n",
      "'sample_submission.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 474092593 bytes (453 MiB)\n",
      "\n",
      "Extracting archive: train.csv.7z\n",
      "--\n",
      "Path = train.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 474092593\n",
      "Headers Size = 122\n",
      "Method = LZMA2:24\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b  0% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b100% 1\b\b\b\b\b\b      \b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       4997452288\n",
      "Compressed: 474092593\n",
      "==================================================\n",
      "'train.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 3762 bytes (4 KiB)\n",
      "\n",
      "Extracting archive: oil.csv.7z\n",
      "--\n",
      "Path = oil.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 3762\n",
      "Headers Size = 122\n",
      "Method = LZMA2:24k\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       20580\n",
      "Compressed: 3762\n",
      "==================================================\n",
      "'oil.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 648 bytes (1 KiB)\n",
      "\n",
      "Extracting archive: stores.csv.7z\n",
      "--\n",
      "Path = stores.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 648\n",
      "Headers Size = 130\n",
      "Method = LZMA2:12\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       1387\n",
      "Compressed: 648\n",
      "==================================================\n",
      "'stores.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 14315 bytes (14 KiB)\n",
      "\n",
      "Extracting archive: items.csv.7z\n",
      "--\n",
      "Path = items.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 14315\n",
      "Headers Size = 122\n",
      "Method = LZMA2:17\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       101841\n",
      "Compressed: 14315\n",
      "==================================================\n",
      "'items.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 1898 bytes (2 KiB)\n",
      "\n",
      "Extracting archive: holidays_events.csv.7z\n",
      "--\n",
      "Path = holidays_events.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 1898\n",
      "Headers Size = 146\n",
      "Method = LZMA2:24k\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       22309\n",
      "Compressed: 1898\n",
      "==================================================\n",
      "'holidays_events.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 219499 bytes (215 KiB)\n",
      "\n",
      "Extracting archive: transactions.csv.7z\n",
      "--\n",
      "Path = transactions.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 219499\n",
      "Headers Size = 138\n",
      "Method = LZMA2:1536k\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       1552637\n",
      "Compressed: 219499\n",
      "==================================================\n",
      "'transactions.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 4885065 bytes (4771 KiB)\n",
      "\n",
      "Extracting archive: test.csv.7z\n",
      "--\n",
      "Path = test.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 4885065\n",
      "Headers Size = 122\n",
      "Method = LZMA2:24\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b 26% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       126163026\n",
      "Compressed: 4885065\n",
      "==================================================\n",
      "'test.csv.7z' File Extracted Successfully\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#Extracting .7z files if they are not already extracted.\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file[-3:]=='.7z':\n",
    "        if os.path.exists(file[:-3]):\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}'Extracted File is Already Present\".format(file[:-3]))\n",
    "        elif file=='oil.csv.7z':\n",
    "            !p7zip -d 'oil.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='train.csv.7z':\n",
    "            !p7zip -d 'train.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='stores.csv.7z':\n",
    "            !p7zip -d 'stores.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='transactions.csv.7z':\n",
    "            !p7zip -d 'transactions.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='items.csv.7z':\n",
    "            !p7zip -d 'items.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='holidays_events.csv.7z':\n",
    "            !p7zip -d 'holidays_events.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='test.csv.7z':\n",
    "            !p7zip -d 'test.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='sample_submission.csv.7z':\n",
    "            !p7zip -d 'sample_submission.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        print(\"=\"*50)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757,
     "referenced_widgets": [
      "db8a0702c7104de18ec198b3e563c7a8",
      "0fe082c65717473583c27e9d895f4448",
      "5365746658844988a18d323de36ad518",
      "0f309844c96344e3972e1181ce0e0648",
      "bf9f7a10af77430ba8e5ffde6e3d9312",
      "f53dc2a3f120451ab4be106efde54a61",
      "f736a229b5f4477287abadf01510e4cb",
      "8a3b628d33a7466699d6c0438ad554f0",
      "1f7b5147e4b846578f40ffc2c23137d1",
      "da6d96db5917448d902d68e60bd2b9f2",
      "03a9672ab27f47e899c737900756b585",
      "851dbc4edf184d078174ed9c8502deee",
      "a0768261a84146a29984957bd41bd6d1",
      "8496f74321884397aa0db3c4709e3217",
      "dae649ece067447f9175edb5ea360ba8",
      "663019abb6a0488482a709d568c0903a",
      "ec7279d173844345a8e62f4e1e6d41db",
      "8937d13f8ee642188b986a4f6a04c1bf",
      "1abe5e69185840b5ad1eea0ea1b0e564",
      "f6c0192fe8a144fabd9b5bd21a0f88f6",
      "476aa9a41c014519ba2bc5368beb2a94",
      "cd394492a25f4d33851f30a27050fe9a",
      "9e9a2924c1084937bc3e7cc02b8e4268",
      "316edb9187d442bf83bf107d04d42d72",
      "311d372836c340de95f95e6fa5d3007a",
      "1d30f29da7ed4a849d0623a0e5f08039",
      "38ed41334ad8430796eeaf2bd8bbef52",
      "3ca3b32df5af443e838d6999f0810bac",
      "f0f1b43e1666492288c8c9858c18c30c",
      "609a7b0141434111802590cdaff121cc",
      "f173048d22f549769265f279d0d13067",
      "c91e3bf65926457ead45ac8ea00b584a"
     ]
    },
    "colab_type": "code",
    "id": "fobux-QYv68E",
    "outputId": "af4cc35a-fd3d-4012-fbc4-b75f40f88416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pre-Processing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8a0702c7104de18ec198b3e563c7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23808261.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the following for Train Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 28/6/2017\n",
      "No. of weeks --> 2\n",
      "\n",
      "Creating Features for data between Dates --> 2017-06-28 - 2017-07-12 (i.e. 2 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7b5147e4b846578f40ffc2c23137d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_train.csv' File ...\n",
      "Saving 'y_train.csv' File ...\n",
      "\n",
      "Enter the following for Validation Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 26/7/2017\n",
      "No. of weeks --> 1\n",
      "\n",
      "Creating Features for data between Dates --> 2017-07-26 - 2017-08-02 (i.e. 1 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7279d173844345a8e62f4e1e6d41db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_val.csv' File ...\n",
      "Saving 'y_val.csv' File ...\n",
      "\n",
      "Enter the following for Test Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 16/8/2017\n",
      "No. of weeks --> 1\n",
      "\n",
      "Creating Features for data between Dates --> 2017-08-16 - 2017-08-23 (i.e. 1 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311d372836c340de95f95e6fa5d3007a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_test.csv' File ...\n",
      "\n",
      "Saving 'sales_2017.csv' File ...\n",
      "Saving 'stores_items.csv' File ...\n"
     ]
    }
   ],
   "source": [
    "#Creating features by excecuting Pre_Processing Feature_engineering.py\n",
    "\n",
    "exec(open('Pre_Processing Feature_engineering.py').read())\n",
    "\n",
    "# Train Dataset Initial Date 28/6/2017\n",
    "# 2 weeks\n",
    "\n",
    "# Validation Dataset Initial Date 26/7/2017\n",
    "# 1 week\n",
    "\n",
    "# Test Dataset Initial Date 16/8/2017\n",
    "# 1 week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYs6IsHakahn"
   },
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "3f48860e077844a98ea1a1692fbf5e92",
      "637f38687bc8464dabefabfc1060aa9b",
      "db9d9e0698ea4d399cdbb4ee387fc957",
      "6b0aa5e781b6416f89e7c3515a898289",
      "a36d161761ea4d1fb00e390344c803cb",
      "ede94b80fabc4ee9ad4e03f62d3aeeaa",
      "8ac6163e6efd4bfda75065b5d279d905",
      "32aa608c889644f7bef875eac96defa8"
     ]
    },
    "colab_type": "code",
    "id": "PiDmzIxm92He",
    "outputId": "c2af0446-10eb-4d6a-e454-028f2d799eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of Dataframe is 1617.996 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f48860e077844a98ea1a1692fbf5e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=633.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 351.461 MB\n",
      "Decreased by 78.3%\n"
     ]
    }
   ],
   "source": [
    "# Reading X_train.csv and reducing memory usage\n",
    "X_train=pd.read_csv(\"X_train.csv\")\n",
    "X_train=reduce_mem_usage(X_train)\n",
    "\n",
    "# Reading y_train.csv and converting into numpy array\n",
    "y_train = np.array(pd.read_csv( 'y_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "2abc95643ca84593bfaf23e271b95765",
      "246a2ab922f646619e0a2f35f94d7753",
      "d4ab930c3add4e55a7d39531fcfec24a",
      "0496eb5618cd48a7ad284323fc60f3ef",
      "c9c504d797fa4e07a6534d2687765e66",
      "769174068b91435aa1d5fb74ece7e40d",
      "4557042016a2411d8c1b65a778b41f7d",
      "b29e8485ff3f42edae8be9562ab7da1e"
     ]
    },
    "colab_type": "code",
    "id": "w31IYrzO-HQ3",
    "outputId": "3418b61f-d28f-4d20-b30d-d7565c731884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of Dataframe is 808.998 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abc95643ca84593bfaf23e271b95765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=633.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 175.091 MB\n",
      "Decreased by 78.4%\n"
     ]
    }
   ],
   "source": [
    "# Reading X_val.csv and reducing memory usage\n",
    "X_val=pd.read_csv(\"X_val.csv\")\n",
    "X_val=reduce_mem_usage(X_val)\n",
    "\n",
    "# Reading y_val.csv and converting into numpy array\n",
    "y_val = np.array(pd.read_csv( 'y_val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "5f2e08c857f7417a9149766623a164b5",
      "8c459c2a0c014805a13e00643c0786c1",
      "f1f22ff5a0404aada1f7d920b589cca3",
      "b04c16ae093a400d8c7948828ab8c94e",
      "5576247931de47558c0722f123080da5",
      "26092c056a844726a8b46055799e1ed2",
      "ebb0b5e7561249789be6fd900a3374b6",
      "26b16fb978ba4a5284504d222775dc4b"
     ]
    },
    "colab_type": "code",
    "id": "Owd_QrIGztxP",
    "outputId": "585e039f-16e2-4f64-e33b-196a00ad34c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of Dataframe is 808.998 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2e08c857f7417a9149766623a164b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=633.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 175.730 MB\n",
      "Decreased by 78.3%\n"
     ]
    }
   ],
   "source": [
    "# Reading X_test.csv and reducing memory usage\n",
    "X_test=pd.read_csv(\"X_test.csv\")\n",
    "X_test=reduce_mem_usage(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "28217aa7bba24e519441b217db3ee471",
      "1c25fbf929cf4b50af7eb500065d8bdb",
      "7d8f30afcd174b09a1029d8cc0aebf9c",
      "9b1c5437dcf64a598ee09d18d3e9e1ec",
      "e3955ed976ea474da28461162b214e7c",
      "9a144c3885474f44bcedb6377b05d54d",
      "716bbd11133442ab8419fc50daf8de21",
      "81aac40f4e0d4a04a79ec3e964e394a8"
     ]
    },
    "colab_type": "code",
    "id": "DE0eO23Q9zJP",
    "outputId": "5a148504-bbfe-4421-946d-4e02b643bc4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of Dataframe is 5.112 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28217aa7bba24e519441b217db3ee471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 1.919 MB\n",
      "Decreased by 62.5%\n"
     ]
    }
   ],
   "source": [
    "# Reading stores_items.csv\n",
    "stores_items = pd.read_csv('stores_items.csv', index_col=['store_nbr','item_nbr'])\n",
    "\n",
    "# Reading items.csv and setting index as item_nbr\n",
    "items = pd.read_csv( 'items.csv' ).set_index(\"item_nbr\")\n",
    "\n",
    "items = items.reindex( stores_items.index.get_level_values(1) )\n",
    "items=reduce_mem_usage(items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGHCj5TN6MV1"
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o9WeqXFLSci1",
    "outputId": "223102ec-9ca6-4ff3-89b3-870a3c905bc5"
   },
   "outputs": [],
   "source": [
    "# Loading Top 300 Feature Names (got by training random forest)\n",
    "import pickle\n",
    "with open('300_filtered_features.pkl','rb') as file:\n",
    "    filtered_features = pickle.load( file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGg0O77VR1_U"
   },
   "source": [
    "### Defining LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urr_AmQoZ7wA"
   },
   "outputs": [],
   "source": [
    "def train_lgb_model(X_train,y_train,X_val,y_val,params,num_boost_rounds,n_days,items,features,X_test=None):\n",
    "    '''\n",
    "    Filter features from the Dataset and then\n",
    "    Trains 16 different lgb models for predicting next 16 days sales . \n",
    "\n",
    "    Returns --> * val_pred i.e.predicted values of validation data\n",
    "                * test_pred i.e.predicted values of test data if present\n",
    "    '''\n",
    "    val_pred = []\n",
    "    cate_vars = []\n",
    "    test_pred = []\n",
    "\n",
    "    params['device_type']= 'gpu'\n",
    "    params['objective'] = 'regression'\n",
    "    params['metric'] = 'l2'\n",
    "    params ['num_threads']= 16\n",
    "\n",
    "    #Training 16 different models for predicting next 16 days sales.\n",
    "    for i in range(16):\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Step %d\" % (i+1))\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Filtering features\n",
    "        x_train = X_train[features[i]]\n",
    "        x_val = X_val[features[i]]\n",
    "\n",
    "        #Filtering Features from test dataset if it exists.\n",
    "        try:\n",
    "            x_test = X_test[features[i]]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #Creating Train lightgbm Dataset\n",
    "        dtrain = lgb.Dataset( x_train, label=y_train[:, i],\n",
    "                               categorical_feature=cate_vars,\n",
    "                              weight=pd.concat([items[\"perishable\"]] * n_days) * 0.25 + 1  )#As described on kaggle  Items marked as perishable have a score weight of 1.25; otherwise, the weight is 1.0.\n",
    "        \n",
    "        #Creating Val lightgbm Dataset\n",
    "        dval = lgb.Dataset(  x_val, label=y_val[:, i], reference=dtrain,\n",
    "                             categorical_feature=cate_vars,\n",
    "                             weight=items[\"perishable\"] * 0.25 + 1, )\n",
    "            \n",
    "        #Training Lgbm\n",
    "        model = lgb.train( params, dtrain, num_boost_rounds[i],\n",
    "                        valid_sets=[dtrain, dval], verbose_eval=200 )\n",
    "            \n",
    "        # appending results of prediction on val set\n",
    "        val_pred.append(model.predict(x_val, num_iteration=model.best_iteration or num_boost_rounds[i]))\n",
    "\n",
    "        # appending results of prediction on test set if it exists\n",
    "        try:\n",
    "            test_pred.append(model.predict(x_test, num_iteration = model.best_iteration  or num_boost_rounds[i]))\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Deleting unneccessary variables\n",
    "        del model,dtrain,dval,x_train,x_val\n",
    "\n",
    "    if type(X_test) != type(None):\n",
    "        return val_pred,test_pred\n",
    "    else:\n",
    "        return val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vF4KojL_cAa7"
   },
   "source": [
    "### Performance Metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdWFg3dfb_yv"
   },
   "source": [
    "**NWRMSLE** (Normalized Weighted Root Mean Squared Logarithmic Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmjGQnsdIu0p"
   },
   "outputs": [],
   "source": [
    "def calculate_nwrmsle(true,pred,weight):\n",
    "    ''' \n",
    "    Calculates Normalized Weighted Root Mean Squared Logarithmic Error (nwrmsle)\n",
    "\n",
    "    true = true labels\n",
    "    pred =  predicted labels\n",
    "    weight = weights of datapoints\n",
    "\n",
    "    returns nwrmsle '''\n",
    "\n",
    "    temp = (true - np.array(pred).transpose())**2\n",
    "    temp = temp.sum(axis=1) * weight\n",
    "    nwrmsle = np.sqrt(temp.sum() / weight.sum() / 16)\n",
    "    return nwrmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4rTNXDs6Qws"
   },
   "source": [
    "### HyperParameter Tuning (Using gp minimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFH5aO0-ae4C"
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to fit the model and return the performance of the model\n",
    "def return_model_assessment(args, X_train, y_train, X_val, y_val, model, n_days ,items , features ,num_boost_rounds =None):\n",
    "    global model_hyper_params,count\n",
    "    count+=1\n",
    "    print('='*50)\n",
    "    print(\"\\nTraining Model No. {} ...\".format(count))\n",
    "    params = {model_hyper_params[i]: args[i] for i, j in enumerate(model_hyper_params)}\n",
    "    print(\"Parameters --> \",params)\n",
    "\n",
    "\n",
    "    if model=='xgb':\n",
    "        val_pred = train_xgb_model(X_train,y_train,X_val,y_val,params,num_boost_rounds,n_days,items,features)\n",
    "\n",
    "    elif model=='lgb':\n",
    "        val_pred = train_lgb_model(X_train,y_train,X_val,y_val,params,num_boost_rounds,n_days,items,features)\n",
    "\n",
    "    elif model== 'rf' :\n",
    "        val_pred = train_rf_model(X_train,y_train,X_val,y_val,params,n_days,items,features)\n",
    "\n",
    "    #calculating nwrmsle\n",
    "    weight = items[\"perishable\"] * 0.25 + 1\n",
    "    nwrmsle = calculate_nwrmsle(y_val, y_pred, weight)\n",
    "\n",
    "    return nwrmsle      #returning nwrmsle because we want to minimize it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Eg1kg7YL55vg",
    "outputId": "33dcc828-5357-4a0a-aa33-125ec0ac67cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.112111 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.336056\tvalid_1's l2: 0.414623\n",
      "[100]\ttraining's l2: 0.319518\tvalid_1's l2: 0.404971\n",
      "[150]\ttraining's l2: 0.311204\tvalid_1's l2: 0.402398\n",
      "[200]\ttraining's l2: 0.304462\tvalid_1's l2: 0.401557\n",
      "[250]\ttraining's l2: 0.298539\tvalid_1's l2: 0.401505\n",
      "[300]\ttraining's l2: 0.29314\tvalid_1's l2: 0.401598\n",
      "[350]\ttraining's l2: 0.288247\tvalid_1's l2: 0.401196\n",
      "[400]\ttraining's l2: 0.283537\tvalid_1's l2: 0.401272\n",
      "[450]\ttraining's l2: 0.279099\tvalid_1's l2: 0.40104\n",
      "[500]\ttraining's l2: 0.274891\tvalid_1's l2: 0.401304\n",
      "[550]\ttraining's l2: 0.270761\tvalid_1's l2: 0.401221\n",
      "Early stopping, best iteration is:\n",
      "[452]\ttraining's l2: 0.278929\tvalid_1's l2: 0.400977\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.107275 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.318986\tvalid_1's l2: 0.382588\n",
      "[100]\ttraining's l2: 0.303141\tvalid_1's l2: 0.373958\n",
      "[150]\ttraining's l2: 0.294892\tvalid_1's l2: 0.372362\n",
      "[200]\ttraining's l2: 0.288647\tvalid_1's l2: 0.372404\n",
      "[250]\ttraining's l2: 0.28308\tvalid_1's l2: 0.371795\n",
      "[300]\ttraining's l2: 0.278127\tvalid_1's l2: 0.372168\n",
      "[350]\ttraining's l2: 0.273557\tvalid_1's l2: 0.371828\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's l2: 0.282986\tvalid_1's l2: 0.371676\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.108455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.331375\tvalid_1's l2: 0.376715\n",
      "[100]\ttraining's l2: 0.316105\tvalid_1's l2: 0.371382\n",
      "[150]\ttraining's l2: 0.30806\tvalid_1's l2: 0.370109\n",
      "[200]\ttraining's l2: 0.301559\tvalid_1's l2: 0.369618\n",
      "[250]\ttraining's l2: 0.295893\tvalid_1's l2: 0.369783\n",
      "[300]\ttraining's l2: 0.290685\tvalid_1's l2: 0.36965\n",
      "[350]\ttraining's l2: 0.285868\tvalid_1's l2: 0.369777\n",
      "[400]\ttraining's l2: 0.281229\tvalid_1's l2: 0.369829\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's l2: 0.29254\tvalid_1's l2: 0.369482\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.105709 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.331581\tvalid_1's l2: 0.369338\n",
      "[100]\ttraining's l2: 0.3138\tvalid_1's l2: 0.363206\n",
      "[150]\ttraining's l2: 0.305093\tvalid_1's l2: 0.362104\n",
      "[200]\ttraining's l2: 0.298314\tvalid_1's l2: 0.361582\n",
      "[250]\ttraining's l2: 0.292527\tvalid_1's l2: 0.36158\n",
      "[300]\ttraining's l2: 0.287407\tvalid_1's l2: 0.361664\n",
      "[350]\ttraining's l2: 0.282662\tvalid_1's l2: 0.36167\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's l2: 0.294508\tvalid_1's l2: 0.361439\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.112810 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.349831\tvalid_1's l2: 0.374027\n",
      "[100]\ttraining's l2: 0.330429\tvalid_1's l2: 0.36922\n",
      "[150]\ttraining's l2: 0.320505\tvalid_1's l2: 0.36793\n",
      "[200]\ttraining's l2: 0.313117\tvalid_1's l2: 0.367687\n",
      "[250]\ttraining's l2: 0.306625\tvalid_1's l2: 0.367388\n",
      "[300]\ttraining's l2: 0.30089\tvalid_1's l2: 0.367451\n",
      "[350]\ttraining's l2: 0.295684\tvalid_1's l2: 0.367482\n",
      "[400]\ttraining's l2: 0.290949\tvalid_1's l2: 0.36799\n",
      "[450]\ttraining's l2: 0.286352\tvalid_1's l2: 0.368038\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttraining's l2: 0.296469\tvalid_1's l2: 0.36735\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.114061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.359633\tvalid_1's l2: 0.384675\n",
      "[100]\ttraining's l2: 0.336027\tvalid_1's l2: 0.377318\n",
      "[150]\ttraining's l2: 0.325094\tvalid_1's l2: 0.376503\n",
      "[200]\ttraining's l2: 0.317056\tvalid_1's l2: 0.375986\n",
      "[250]\ttraining's l2: 0.310198\tvalid_1's l2: 0.375615\n",
      "[300]\ttraining's l2: 0.304312\tvalid_1's l2: 0.375504\n",
      "[350]\ttraining's l2: 0.298865\tvalid_1's l2: 0.375511\n",
      "[400]\ttraining's l2: 0.293869\tvalid_1's l2: 0.375392\n",
      "[450]\ttraining's l2: 0.289076\tvalid_1's l2: 0.375509\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's l2: 0.29788\tvalid_1's l2: 0.375334\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.118093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.350684\tvalid_1's l2: 0.376965\n",
      "[100]\ttraining's l2: 0.332939\tvalid_1's l2: 0.373485\n",
      "[150]\ttraining's l2: 0.323298\tvalid_1's l2: 0.372708\n",
      "[200]\ttraining's l2: 0.315909\tvalid_1's l2: 0.372493\n",
      "[250]\ttraining's l2: 0.309701\tvalid_1's l2: 0.37269\n",
      "[300]\ttraining's l2: 0.303888\tvalid_1's l2: 0.372806\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's l2: 0.316029\tvalid_1's l2: 0.372475\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.104601 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.33882\tvalid_1's l2: 0.363119\n",
      "[100]\ttraining's l2: 0.322018\tvalid_1's l2: 0.359614\n",
      "[150]\ttraining's l2: 0.313055\tvalid_1's l2: 0.359117\n",
      "[200]\ttraining's l2: 0.306105\tvalid_1's l2: 0.359204\n",
      "[250]\ttraining's l2: 0.30027\tvalid_1's l2: 0.359459\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's l2: 0.315083\tvalid_1's l2: 0.359036\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.109777 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.328515\tvalid_1's l2: 0.347383\n",
      "[100]\ttraining's l2: 0.310663\tvalid_1's l2: 0.34294\n",
      "[150]\ttraining's l2: 0.302027\tvalid_1's l2: 0.341867\n",
      "[200]\ttraining's l2: 0.295495\tvalid_1's l2: 0.341781\n",
      "[250]\ttraining's l2: 0.289814\tvalid_1's l2: 0.342042\n",
      "[300]\ttraining's l2: 0.284739\tvalid_1's l2: 0.342242\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's l2: 0.296532\tvalid_1's l2: 0.341772\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.109879 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.341278\tvalid_1's l2: 0.370663\n",
      "[100]\ttraining's l2: 0.323316\tvalid_1's l2: 0.3666\n",
      "[150]\ttraining's l2: 0.314449\tvalid_1's l2: 0.365941\n",
      "[200]\ttraining's l2: 0.307381\tvalid_1's l2: 0.365857\n",
      "[250]\ttraining's l2: 0.301455\tvalid_1's l2: 0.366028\n",
      "[300]\ttraining's l2: 0.29627\tvalid_1's l2: 0.366296\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's l2: 0.308655\tvalid_1's l2: 0.365757\n",
      "==================================================\n",
      "Training Model No. 2 ...\n",
      "Parameters -->  {'learning_rate': 0.041882364842947134, 'num_leaves': 63, 'min_data_in_leaf': 129, 'feature_fraction': 0.7952665418846558, 'bagging_fraction': 0.5169234737081301, 'bagging_freq': 2}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.109398 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.308198\tvalid_1's l2: 0.306893\n",
      "[100]\ttraining's l2: 0.284081\tvalid_1's l2: 0.290165\n",
      "[150]\ttraining's l2: 0.277062\tvalid_1's l2: 0.287921\n",
      "[200]\ttraining's l2: 0.272157\tvalid_1's l2: 0.287014\n",
      "[250]\ttraining's l2: 0.268061\tvalid_1's l2: 0.286629\n",
      "[300]\ttraining's l2: 0.264416\tvalid_1's l2: 0.286461\n",
      "[350]\ttraining's l2: 0.260958\tvalid_1's l2: 0.286436\n",
      "[400]\ttraining's l2: 0.257764\tvalid_1's l2: 0.286294\n",
      "[450]\ttraining's l2: 0.254661\tvalid_1's l2: 0.286407\n",
      "[500]\ttraining's l2: 0.251718\tvalid_1's l2: 0.2864\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's l2: 0.257028\tvalid_1's l2: 0.286281\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.118834 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.323372\tvalid_1's l2: 0.338467\n",
      "[100]\ttraining's l2: 0.302649\tvalid_1's l2: 0.322906\n",
      "[150]\ttraining's l2: 0.29529\tvalid_1's l2: 0.320092\n",
      "[200]\ttraining's l2: 0.289903\tvalid_1's l2: 0.318715\n",
      "[250]\ttraining's l2: 0.285548\tvalid_1's l2: 0.318504\n",
      "[300]\ttraining's l2: 0.281597\tvalid_1's l2: 0.318119\n",
      "[350]\ttraining's l2: 0.277871\tvalid_1's l2: 0.317902\n",
      "[400]\ttraining's l2: 0.27434\tvalid_1's l2: 0.317923\n",
      "[450]\ttraining's l2: 0.271028\tvalid_1's l2: 0.317696\n",
      "[500]\ttraining's l2: 0.26788\tvalid_1's l2: 0.317625\n",
      "[550]\ttraining's l2: 0.264814\tvalid_1's l2: 0.317526\n",
      "[600]\ttraining's l2: 0.261851\tvalid_1's l2: 0.317728\n",
      "[650]\ttraining's l2: 0.258995\tvalid_1's l2: 0.317767\n",
      "Early stopping, best iteration is:\n",
      "[553]\ttraining's l2: 0.26465\tvalid_1's l2: 0.317503\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.107013 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.32749\tvalid_1's l2: 0.358512\n",
      "[100]\ttraining's l2: 0.302208\tvalid_1's l2: 0.338687\n",
      "[150]\ttraining's l2: 0.293752\tvalid_1's l2: 0.335775\n",
      "[200]\ttraining's l2: 0.288349\tvalid_1's l2: 0.335032\n",
      "[250]\ttraining's l2: 0.283805\tvalid_1's l2: 0.334376\n",
      "[300]\ttraining's l2: 0.279896\tvalid_1's l2: 0.334131\n",
      "[350]\ttraining's l2: 0.276186\tvalid_1's l2: 0.334066\n",
      "[400]\ttraining's l2: 0.272688\tvalid_1's l2: 0.334081\n",
      "[450]\ttraining's l2: 0.269316\tvalid_1's l2: 0.33405\n",
      "[500]\ttraining's l2: 0.266232\tvalid_1's l2: 0.334062\n",
      "[550]\ttraining's l2: 0.263411\tvalid_1's l2: 0.334108\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttraining's l2: 0.27055\tvalid_1's l2: 0.334008\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.129468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.355927\tvalid_1's l2: 0.371871\n",
      "[100]\ttraining's l2: 0.325448\tvalid_1's l2: 0.353496\n",
      "[150]\ttraining's l2: 0.315152\tvalid_1's l2: 0.350237\n",
      "[200]\ttraining's l2: 0.308559\tvalid_1's l2: 0.349337\n",
      "[250]\ttraining's l2: 0.303342\tvalid_1's l2: 0.348914\n",
      "[300]\ttraining's l2: 0.29876\tvalid_1's l2: 0.348317\n",
      "[350]\ttraining's l2: 0.294622\tvalid_1's l2: 0.348231\n",
      "[400]\ttraining's l2: 0.290757\tvalid_1's l2: 0.348155\n",
      "[450]\ttraining's l2: 0.287136\tvalid_1's l2: 0.348043\n",
      "[500]\ttraining's l2: 0.28376\tvalid_1's l2: 0.348145\n",
      "Early stopping, best iteration is:\n",
      "[415]\ttraining's l2: 0.289622\tvalid_1's l2: 0.347951\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.108734 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.368001\tvalid_1's l2: 0.377498\n",
      "[100]\ttraining's l2: 0.333025\tvalid_1's l2: 0.355967\n",
      "[150]\ttraining's l2: 0.320714\tvalid_1's l2: 0.351252\n",
      "[200]\ttraining's l2: 0.313597\tvalid_1's l2: 0.349939\n",
      "[250]\ttraining's l2: 0.307652\tvalid_1's l2: 0.348815\n",
      "[300]\ttraining's l2: 0.302713\tvalid_1's l2: 0.348516\n",
      "[350]\ttraining's l2: 0.298192\tvalid_1's l2: 0.348092\n",
      "[400]\ttraining's l2: 0.294179\tvalid_1's l2: 0.347985\n",
      "[450]\ttraining's l2: 0.29037\tvalid_1's l2: 0.347913\n",
      "[500]\ttraining's l2: 0.286842\tvalid_1's l2: 0.347949\n",
      "[550]\ttraining's l2: 0.283447\tvalid_1's l2: 0.347933\n",
      "Early stopping, best iteration is:\n",
      "[435]\ttraining's l2: 0.291529\tvalid_1's l2: 0.347867\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.111812 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.363707\tvalid_1's l2: 0.378924\n",
      "[100]\ttraining's l2: 0.336396\tvalid_1's l2: 0.357899\n",
      "[150]\ttraining's l2: 0.326754\tvalid_1's l2: 0.353839\n",
      "[200]\ttraining's l2: 0.320324\tvalid_1's l2: 0.352815\n",
      "[250]\ttraining's l2: 0.314934\tvalid_1's l2: 0.352298\n",
      "[300]\ttraining's l2: 0.310279\tvalid_1's l2: 0.351876\n",
      "[350]\ttraining's l2: 0.305962\tvalid_1's l2: 0.351655\n",
      "[400]\ttraining's l2: 0.301952\tvalid_1's l2: 0.351584\n",
      "[450]\ttraining's l2: 0.298273\tvalid_1's l2: 0.351478\n",
      "[500]\ttraining's l2: 0.294708\tvalid_1's l2: 0.351528\n",
      "[550]\ttraining's l2: 0.291271\tvalid_1's l2: 0.35151\n",
      "Early stopping, best iteration is:\n",
      "[474]\ttraining's l2: 0.29651\tvalid_1's l2: 0.351314\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.112320 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.355408\tvalid_1's l2: 0.439294\n",
      "[100]\ttraining's l2: 0.328728\tvalid_1's l2: 0.410409\n",
      "[150]\ttraining's l2: 0.318733\tvalid_1's l2: 0.405449\n",
      "[200]\ttraining's l2: 0.312384\tvalid_1's l2: 0.403755\n",
      "[250]\ttraining's l2: 0.307364\tvalid_1's l2: 0.402694\n",
      "[300]\ttraining's l2: 0.302832\tvalid_1's l2: 0.402066\n",
      "[350]\ttraining's l2: 0.2986\tvalid_1's l2: 0.401726\n",
      "[400]\ttraining's l2: 0.294719\tvalid_1's l2: 0.40142\n",
      "[450]\ttraining's l2: 0.291065\tvalid_1's l2: 0.401258\n",
      "[500]\ttraining's l2: 0.287479\tvalid_1's l2: 0.401084\n",
      "[550]\ttraining's l2: 0.284151\tvalid_1's l2: 0.400931\n",
      "[600]\ttraining's l2: 0.28101\tvalid_1's l2: 0.401125\n",
      "Early stopping, best iteration is:\n",
      "[524]\ttraining's l2: 0.285883\tvalid_1's l2: 0.400875\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.137642 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.338956\tvalid_1's l2: 0.404576\n",
      "[100]\ttraining's l2: 0.31194\tvalid_1's l2: 0.377958\n",
      "[150]\ttraining's l2: 0.302723\tvalid_1's l2: 0.373741\n",
      "[200]\ttraining's l2: 0.296783\tvalid_1's l2: 0.372158\n",
      "[250]\ttraining's l2: 0.291924\tvalid_1's l2: 0.371571\n",
      "[300]\ttraining's l2: 0.287627\tvalid_1's l2: 0.371059\n",
      "[350]\ttraining's l2: 0.283692\tvalid_1's l2: 0.370836\n",
      "[400]\ttraining's l2: 0.279978\tvalid_1's l2: 0.370772\n",
      "[450]\ttraining's l2: 0.276564\tvalid_1's l2: 0.370598\n",
      "[500]\ttraining's l2: 0.273318\tvalid_1's l2: 0.370471\n",
      "[550]\ttraining's l2: 0.270208\tvalid_1's l2: 0.370508\n",
      "[600]\ttraining's l2: 0.267181\tvalid_1's l2: 0.370658\n",
      "Early stopping, best iteration is:\n",
      "[520]\ttraining's l2: 0.272074\tvalid_1's l2: 0.370364\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.108321 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.348739\tvalid_1's l2: 0.393272\n",
      "[100]\ttraining's l2: 0.324891\tvalid_1's l2: 0.374343\n",
      "[150]\ttraining's l2: 0.315727\tvalid_1's l2: 0.371249\n",
      "[200]\ttraining's l2: 0.309555\tvalid_1's l2: 0.36979\n",
      "[250]\ttraining's l2: 0.304692\tvalid_1's l2: 0.36999\n",
      "[300]\ttraining's l2: 0.300318\tvalid_1's l2: 0.369631\n",
      "[350]\ttraining's l2: 0.296301\tvalid_1's l2: 0.369512\n",
      "[400]\ttraining's l2: 0.292688\tvalid_1's l2: 0.369296\n",
      "[450]\ttraining's l2: 0.28918\tvalid_1's l2: 0.369243\n",
      "[500]\ttraining's l2: 0.285703\tvalid_1's l2: 0.369113\n",
      "[550]\ttraining's l2: 0.282456\tvalid_1's l2: 0.369065\n",
      "[600]\ttraining's l2: 0.279355\tvalid_1's l2: 0.368966\n",
      "[650]\ttraining's l2: 0.276319\tvalid_1's l2: 0.368815\n",
      "[700]\ttraining's l2: 0.273446\tvalid_1's l2: 0.368766\n",
      "[750]\ttraining's l2: 0.270648\tvalid_1's l2: 0.368778\n",
      "[800]\ttraining's l2: 0.267845\tvalid_1's l2: 0.368946\n",
      "[850]\ttraining's l2: 0.265154\tvalid_1's l2: 0.369165\n",
      "Early stopping, best iteration is:\n",
      "[754]\ttraining's l2: 0.270407\tvalid_1's l2: 0.36874\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.103056 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.352549\tvalid_1's l2: 0.38731\n",
      "[100]\ttraining's l2: 0.324259\tvalid_1's l2: 0.366662\n",
      "[150]\ttraining's l2: 0.313158\tvalid_1's l2: 0.363139\n",
      "[200]\ttraining's l2: 0.306669\tvalid_1's l2: 0.362148\n",
      "[250]\ttraining's l2: 0.301332\tvalid_1's l2: 0.361536\n",
      "[300]\ttraining's l2: 0.296874\tvalid_1's l2: 0.361547\n",
      "[350]\ttraining's l2: 0.29289\tvalid_1's l2: 0.361373\n",
      "[400]\ttraining's l2: 0.28898\tvalid_1's l2: 0.36124\n",
      "[450]\ttraining's l2: 0.285321\tvalid_1's l2: 0.361098\n",
      "[500]\ttraining's l2: 0.281966\tvalid_1's l2: 0.361028\n",
      "[550]\ttraining's l2: 0.278746\tvalid_1's l2: 0.36087\n",
      "[600]\ttraining's l2: 0.275675\tvalid_1's l2: 0.360911\n",
      "[650]\ttraining's l2: 0.272746\tvalid_1's l2: 0.361195\n",
      "Early stopping, best iteration is:\n",
      "[559]\ttraining's l2: 0.278195\tvalid_1's l2: 0.360804\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.110628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.372743\tvalid_1's l2: 0.391561\n",
      "[100]\ttraining's l2: 0.342065\tvalid_1's l2: 0.372522\n",
      "[150]\ttraining's l2: 0.32977\tvalid_1's l2: 0.369162\n",
      "[200]\ttraining's l2: 0.32223\tvalid_1's l2: 0.367829\n",
      "[250]\ttraining's l2: 0.3164\tvalid_1's l2: 0.367415\n",
      "[300]\ttraining's l2: 0.311394\tvalid_1's l2: 0.367039\n",
      "[350]\ttraining's l2: 0.307056\tvalid_1's l2: 0.367074\n",
      "[400]\ttraining's l2: 0.303019\tvalid_1's l2: 0.367089\n",
      "[450]\ttraining's l2: 0.2993\tvalid_1's l2: 0.367024\n",
      "[500]\ttraining's l2: 0.29562\tvalid_1's l2: 0.366903\n",
      "[550]\ttraining's l2: 0.292199\tvalid_1's l2: 0.366889\n",
      "[600]\ttraining's l2: 0.288978\tvalid_1's l2: 0.367002\n",
      "Early stopping, best iteration is:\n",
      "[479]\ttraining's l2: 0.29711\tvalid_1's l2: 0.36678\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.105069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.385518\tvalid_1's l2: 0.402727\n",
      "[100]\ttraining's l2: 0.349953\tvalid_1's l2: 0.381469\n",
      "[150]\ttraining's l2: 0.335931\tvalid_1's l2: 0.377637\n",
      "[200]\ttraining's l2: 0.327561\tvalid_1's l2: 0.376423\n",
      "[250]\ttraining's l2: 0.321005\tvalid_1's l2: 0.375468\n",
      "[300]\ttraining's l2: 0.315759\tvalid_1's l2: 0.375113\n",
      "[350]\ttraining's l2: 0.311097\tvalid_1's l2: 0.374783\n",
      "[400]\ttraining's l2: 0.30664\tvalid_1's l2: 0.374919\n",
      "[450]\ttraining's l2: 0.302678\tvalid_1's l2: 0.374885\n",
      "Early stopping, best iteration is:\n",
      "[351]\ttraining's l2: 0.311022\tvalid_1's l2: 0.374776\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.109852 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.371208\tvalid_1's l2: 0.390604\n",
      "[100]\ttraining's l2: 0.342679\tvalid_1's l2: 0.374058\n",
      "[150]\ttraining's l2: 0.332095\tvalid_1's l2: 0.371949\n",
      "[200]\ttraining's l2: 0.325126\tvalid_1's l2: 0.371392\n",
      "[250]\ttraining's l2: 0.319448\tvalid_1's l2: 0.371239\n",
      "[300]\ttraining's l2: 0.31443\tvalid_1's l2: 0.371175\n",
      "[350]\ttraining's l2: 0.310011\tvalid_1's l2: 0.371309\n",
      "[400]\ttraining's l2: 0.305884\tvalid_1's l2: 0.371368\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttraining's l2: 0.315081\tvalid_1's l2: 0.371102\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.104939 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.358527\tvalid_1's l2: 0.376084\n",
      "[100]\ttraining's l2: 0.331353\tvalid_1's l2: 0.360148\n",
      "[150]\ttraining's l2: 0.321011\tvalid_1's l2: 0.358613\n",
      "[200]\ttraining's l2: 0.314464\tvalid_1's l2: 0.358377\n",
      "[250]\ttraining's l2: 0.309365\tvalid_1's l2: 0.358204\n",
      "[300]\ttraining's l2: 0.304822\tvalid_1's l2: 0.358145\n",
      "[350]\ttraining's l2: 0.300525\tvalid_1's l2: 0.358189\n",
      "[400]\ttraining's l2: 0.296654\tvalid_1's l2: 0.358276\n",
      "Early stopping, best iteration is:\n",
      "[308]\ttraining's l2: 0.304119\tvalid_1's l2: 0.358106\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.105839 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.349147\tvalid_1's l2: 0.36242\n",
      "[100]\ttraining's l2: 0.320168\tvalid_1's l2: 0.344341\n",
      "[150]\ttraining's l2: 0.309611\tvalid_1's l2: 0.342242\n",
      "[200]\ttraining's l2: 0.303124\tvalid_1's l2: 0.341386\n",
      "[250]\ttraining's l2: 0.297973\tvalid_1's l2: 0.341088\n",
      "[300]\ttraining's l2: 0.29359\tvalid_1's l2: 0.340725\n",
      "[350]\ttraining's l2: 0.289637\tvalid_1's l2: 0.340805\n",
      "[400]\ttraining's l2: 0.285944\tvalid_1's l2: 0.340797\n",
      "[450]\ttraining's l2: 0.282524\tvalid_1's l2: 0.340881\n",
      "[500]\ttraining's l2: 0.279306\tvalid_1's l2: 0.340987\n",
      "Early stopping, best iteration is:\n",
      "[383]\ttraining's l2: 0.287182\tvalid_1's l2: 0.340714\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.109585 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.358936\tvalid_1's l2: 0.382556\n",
      "[100]\ttraining's l2: 0.33349\tvalid_1's l2: 0.36815\n",
      "[150]\ttraining's l2: 0.32262\tvalid_1's l2: 0.366763\n",
      "[200]\ttraining's l2: 0.316084\tvalid_1's l2: 0.365918\n",
      "[250]\ttraining's l2: 0.311006\tvalid_1's l2: 0.365602\n",
      "[300]\ttraining's l2: 0.306348\tvalid_1's l2: 0.365541\n",
      "[350]\ttraining's l2: 0.30204\tvalid_1's l2: 0.365459\n",
      "[400]\ttraining's l2: 0.298082\tvalid_1's l2: 0.365512\n",
      "[450]\ttraining's l2: 0.294418\tvalid_1's l2: 0.365596\n",
      "Early stopping, best iteration is:\n",
      "[334]\ttraining's l2: 0.303332\tvalid_1's l2: 0.365425\n",
      "==================================================\n",
      "Training Model No. 3 ...\n",
      "Parameters -->  {'learning_rate': 0.09058372727462635, 'num_leaves': 50, 'min_data_in_leaf': 298, 'feature_fraction': 0.785244452888315, 'bagging_fraction': 0.6834959481464843, 'bagging_freq': 1}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.115373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.286792\tvalid_1's l2: 0.291316\n",
      "[100]\ttraining's l2: 0.276315\tvalid_1's l2: 0.287873\n",
      "[150]\ttraining's l2: 0.269729\tvalid_1's l2: 0.287228\n",
      "[200]\ttraining's l2: 0.264152\tvalid_1's l2: 0.28699\n",
      "[250]\ttraining's l2: 0.259083\tvalid_1's l2: 0.28705\n",
      "[300]\ttraining's l2: 0.254528\tvalid_1's l2: 0.287144\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's l2: 0.264152\tvalid_1's l2: 0.28699\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.111043 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.304732\tvalid_1's l2: 0.323495\n",
      "[100]\ttraining's l2: 0.29414\tvalid_1's l2: 0.320247\n",
      "[150]\ttraining's l2: 0.286982\tvalid_1's l2: 0.319665\n",
      "[200]\ttraining's l2: 0.280855\tvalid_1's l2: 0.319592\n",
      "[250]\ttraining's l2: 0.275324\tvalid_1's l2: 0.319397\n",
      "[300]\ttraining's l2: 0.27036\tvalid_1's l2: 0.319658\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's l2: 0.279991\tvalid_1's l2: 0.319355\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.106007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.304883\tvalid_1's l2: 0.339756\n",
      "[100]\ttraining's l2: 0.292761\tvalid_1's l2: 0.335821\n",
      "[150]\ttraining's l2: 0.285489\tvalid_1's l2: 0.334971\n",
      "[200]\ttraining's l2: 0.279427\tvalid_1's l2: 0.334792\n",
      "[250]\ttraining's l2: 0.274052\tvalid_1's l2: 0.334941\n",
      "[300]\ttraining's l2: 0.269032\tvalid_1's l2: 0.334985\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's l2: 0.280582\tvalid_1's l2: 0.334753\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.109494 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.327803\tvalid_1's l2: 0.35359\n",
      "[100]\ttraining's l2: 0.313025\tvalid_1's l2: 0.349658\n",
      "[150]\ttraining's l2: 0.304432\tvalid_1's l2: 0.348893\n",
      "[200]\ttraining's l2: 0.297502\tvalid_1's l2: 0.348695\n",
      "[250]\ttraining's l2: 0.29167\tvalid_1's l2: 0.348457\n",
      "[300]\ttraining's l2: 0.286344\tvalid_1's l2: 0.348279\n",
      "[350]\ttraining's l2: 0.281471\tvalid_1's l2: 0.348509\n",
      "[400]\ttraining's l2: 0.276799\tvalid_1's l2: 0.348878\n",
      "Early stopping, best iteration is:\n",
      "[303]\ttraining's l2: 0.286044\tvalid_1's l2: 0.348275\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.115962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.336303\tvalid_1's l2: 0.35739\n",
      "[100]\ttraining's l2: 0.318596\tvalid_1's l2: 0.351212\n",
      "[150]\ttraining's l2: 0.309532\tvalid_1's l2: 0.350661\n",
      "[200]\ttraining's l2: 0.302177\tvalid_1's l2: 0.349999\n",
      "[250]\ttraining's l2: 0.295888\tvalid_1's l2: 0.350093\n",
      "[300]\ttraining's l2: 0.290298\tvalid_1's l2: 0.350156\n",
      "[350]\ttraining's l2: 0.285006\tvalid_1's l2: 0.350413\n",
      "Early stopping, best iteration is:\n",
      "[268]\ttraining's l2: 0.293786\tvalid_1's l2: 0.349838\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.113004 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.339462\tvalid_1's l2: 0.358625\n",
      "[100]\ttraining's l2: 0.325741\tvalid_1's l2: 0.354467\n",
      "[150]\ttraining's l2: 0.316852\tvalid_1's l2: 0.353882\n",
      "[200]\ttraining's l2: 0.309866\tvalid_1's l2: 0.35354\n",
      "[250]\ttraining's l2: 0.303619\tvalid_1's l2: 0.353293\n",
      "[300]\ttraining's l2: 0.298011\tvalid_1's l2: 0.353305\n",
      "[350]\ttraining's l2: 0.292777\tvalid_1's l2: 0.353688\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's l2: 0.304764\tvalid_1's l2: 0.353214\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.109476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.331634\tvalid_1's l2: 0.411112\n",
      "[100]\ttraining's l2: 0.317622\tvalid_1's l2: 0.404785\n",
      "[150]\ttraining's l2: 0.309429\tvalid_1's l2: 0.402458\n",
      "[200]\ttraining's l2: 0.302488\tvalid_1's l2: 0.402579\n",
      "[250]\ttraining's l2: 0.296296\tvalid_1's l2: 0.40216\n",
      "[300]\ttraining's l2: 0.290657\tvalid_1's l2: 0.402346\n",
      "[350]\ttraining's l2: 0.285547\tvalid_1's l2: 0.40223\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's l2: 0.295543\tvalid_1's l2: 0.401909\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.107360 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.314673\tvalid_1's l2: 0.378126\n",
      "[100]\ttraining's l2: 0.301284\tvalid_1's l2: 0.372751\n",
      "[150]\ttraining's l2: 0.293405\tvalid_1's l2: 0.371954\n",
      "[200]\ttraining's l2: 0.286846\tvalid_1's l2: 0.372162\n",
      "[250]\ttraining's l2: 0.281244\tvalid_1's l2: 0.371743\n",
      "[300]\ttraining's l2: 0.276166\tvalid_1's l2: 0.372155\n",
      "[350]\ttraining's l2: 0.271245\tvalid_1's l2: 0.371873\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's l2: 0.281613\tvalid_1's l2: 0.371704\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.108022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.327824\tvalid_1's l2: 0.375325\n",
      "[100]\ttraining's l2: 0.314513\tvalid_1's l2: 0.371825\n",
      "[150]\ttraining's l2: 0.306536\tvalid_1's l2: 0.371519\n",
      "[200]\ttraining's l2: 0.299925\tvalid_1's l2: 0.370906\n",
      "[250]\ttraining's l2: 0.294059\tvalid_1's l2: 0.371151\n",
      "[300]\ttraining's l2: 0.288682\tvalid_1's l2: 0.370969\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's l2: 0.299263\tvalid_1's l2: 0.370857\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.102484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.327404\tvalid_1's l2: 0.367057\n",
      "[100]\ttraining's l2: 0.311694\tvalid_1's l2: 0.362898\n",
      "[150]\ttraining's l2: 0.302991\tvalid_1's l2: 0.361676\n",
      "[200]\ttraining's l2: 0.296315\tvalid_1's l2: 0.361156\n",
      "[250]\ttraining's l2: 0.290428\tvalid_1's l2: 0.360788\n",
      "[300]\ttraining's l2: 0.285004\tvalid_1's l2: 0.360694\n",
      "[350]\ttraining's l2: 0.280027\tvalid_1's l2: 0.360973\n",
      "[400]\ttraining's l2: 0.275316\tvalid_1's l2: 0.3613\n",
      "Early stopping, best iteration is:\n",
      "[281]\ttraining's l2: 0.287059\tvalid_1's l2: 0.360629\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.112371 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.345869\tvalid_1's l2: 0.372548\n",
      "[100]\ttraining's l2: 0.327996\tvalid_1's l2: 0.368682\n",
      "[150]\ttraining's l2: 0.318398\tvalid_1's l2: 0.367695\n",
      "[200]\ttraining's l2: 0.310997\tvalid_1's l2: 0.36738\n",
      "[250]\ttraining's l2: 0.304612\tvalid_1's l2: 0.36748\n",
      "[300]\ttraining's l2: 0.298851\tvalid_1's l2: 0.367713\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's l2: 0.312815\tvalid_1's l2: 0.36727\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.105308 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.352818\tvalid_1's l2: 0.382991\n",
      "[100]\ttraining's l2: 0.333234\tvalid_1's l2: 0.377981\n",
      "[150]\ttraining's l2: 0.322804\tvalid_1's l2: 0.376442\n",
      "[200]\ttraining's l2: 0.314786\tvalid_1's l2: 0.375957\n",
      "[250]\ttraining's l2: 0.307885\tvalid_1's l2: 0.375676\n",
      "[300]\ttraining's l2: 0.301823\tvalid_1's l2: 0.37568\n",
      "[350]\ttraining's l2: 0.29612\tvalid_1's l2: 0.375927\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's l2: 0.308384\tvalid_1's l2: 0.375612\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.108247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.346086\tvalid_1's l2: 0.375128\n",
      "[100]\ttraining's l2: 0.330392\tvalid_1's l2: 0.37294\n",
      "[150]\ttraining's l2: 0.321091\tvalid_1's l2: 0.372675\n",
      "[200]\ttraining's l2: 0.313773\tvalid_1's l2: 0.372759\n",
      "[250]\ttraining's l2: 0.307331\tvalid_1's l2: 0.372599\n",
      "[300]\ttraining's l2: 0.301403\tvalid_1's l2: 0.372902\n",
      "[350]\ttraining's l2: 0.295979\tvalid_1's l2: 0.373235\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttraining's l2: 0.308845\tvalid_1's l2: 0.372425\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.103769 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.335026\tvalid_1's l2: 0.361946\n",
      "[100]\ttraining's l2: 0.320318\tvalid_1's l2: 0.359722\n",
      "[150]\ttraining's l2: 0.311577\tvalid_1's l2: 0.359727\n",
      "[200]\ttraining's l2: 0.304595\tvalid_1's l2: 0.360264\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's l2: 0.317299\tvalid_1's l2: 0.359466\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.103538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.323266\tvalid_1's l2: 0.345904\n",
      "[100]\ttraining's l2: 0.308186\tvalid_1's l2: 0.343013\n",
      "[150]\ttraining's l2: 0.29989\tvalid_1's l2: 0.342318\n",
      "[200]\ttraining's l2: 0.293276\tvalid_1's l2: 0.342151\n",
      "[250]\ttraining's l2: 0.287661\tvalid_1's l2: 0.342181\n",
      "[300]\ttraining's l2: 0.282513\tvalid_1's l2: 0.342309\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's l2: 0.294488\tvalid_1's l2: 0.342113\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.106170 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.336196\tvalid_1's l2: 0.368825\n",
      "[100]\ttraining's l2: 0.320926\tvalid_1's l2: 0.366703\n",
      "[150]\ttraining's l2: 0.312364\tvalid_1's l2: 0.366329\n",
      "[200]\ttraining's l2: 0.305397\tvalid_1's l2: 0.366609\n",
      "[250]\ttraining's l2: 0.299412\tvalid_1's l2: 0.366952\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's l2: 0.315489\tvalid_1's l2: 0.366261\n",
      "==================================================\n",
      "Training Model No. 4 ...\n",
      "Parameters -->  {'learning_rate': 0.02075629999409107, 'num_leaves': 71, 'min_data_in_leaf': 180, 'feature_fraction': 0.6139996989640846, 'bagging_fraction': 0.7921266556524378, 'bagging_freq': 1}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.110026 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.40869\tvalid_1's l2: 0.398094\n",
      "[100]\ttraining's l2: 0.309397\tvalid_1's l2: 0.308371\n",
      "[150]\ttraining's l2: 0.29017\tvalid_1's l2: 0.293711\n",
      "[200]\ttraining's l2: 0.28252\tvalid_1's l2: 0.2891\n",
      "[250]\ttraining's l2: 0.277863\tvalid_1's l2: 0.286875\n",
      "[300]\ttraining's l2: 0.274735\tvalid_1's l2: 0.286058\n",
      "[350]\ttraining's l2: 0.272074\tvalid_1's l2: 0.285701\n",
      "[400]\ttraining's l2: 0.269687\tvalid_1's l2: 0.285371\n",
      "[450]\ttraining's l2: 0.267518\tvalid_1's l2: 0.285205\n",
      "[500]\ttraining's l2: 0.265476\tvalid_1's l2: 0.285044\n",
      "[550]\ttraining's l2: 0.263518\tvalid_1's l2: 0.284965\n",
      "[600]\ttraining's l2: 0.261591\tvalid_1's l2: 0.28486\n",
      "[650]\ttraining's l2: 0.259757\tvalid_1's l2: 0.284764\n",
      "[700]\ttraining's l2: 0.258007\tvalid_1's l2: 0.284699\n",
      "[750]\ttraining's l2: 0.256264\tvalid_1's l2: 0.284631\n",
      "[800]\ttraining's l2: 0.254638\tvalid_1's l2: 0.284634\n",
      "[850]\ttraining's l2: 0.253016\tvalid_1's l2: 0.284641\n",
      "[900]\ttraining's l2: 0.251403\tvalid_1's l2: 0.284644\n",
      "[950]\ttraining's l2: 0.24982\tvalid_1's l2: 0.284632\n",
      "[1000]\ttraining's l2: 0.248292\tvalid_1's l2: 0.284563\n",
      "[1050]\ttraining's l2: 0.2468\tvalid_1's l2: 0.284552\n",
      "[1100]\ttraining's l2: 0.245297\tvalid_1's l2: 0.284546\n",
      "[1150]\ttraining's l2: 0.243874\tvalid_1's l2: 0.284558\n",
      "[1200]\ttraining's l2: 0.242454\tvalid_1's l2: 0.284555\n",
      "Early stopping, best iteration is:\n",
      "[1079]\ttraining's l2: 0.245924\tvalid_1's l2: 0.28453\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.111079 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.405189\tvalid_1's l2: 0.415092\n",
      "[100]\ttraining's l2: 0.323598\tvalid_1's l2: 0.339039\n",
      "[150]\ttraining's l2: 0.307555\tvalid_1's l2: 0.325767\n",
      "[200]\ttraining's l2: 0.301194\tvalid_1's l2: 0.321917\n",
      "[250]\ttraining's l2: 0.29685\tvalid_1's l2: 0.319941\n",
      "[300]\ttraining's l2: 0.293356\tvalid_1's l2: 0.318933\n",
      "[350]\ttraining's l2: 0.290421\tvalid_1's l2: 0.318354\n",
      "[400]\ttraining's l2: 0.287783\tvalid_1's l2: 0.317994\n",
      "[450]\ttraining's l2: 0.285323\tvalid_1's l2: 0.317552\n",
      "[500]\ttraining's l2: 0.283041\tvalid_1's l2: 0.317277\n",
      "[550]\ttraining's l2: 0.280981\tvalid_1's l2: 0.317168\n",
      "[600]\ttraining's l2: 0.278941\tvalid_1's l2: 0.317013\n",
      "[650]\ttraining's l2: 0.276956\tvalid_1's l2: 0.316908\n",
      "[700]\ttraining's l2: 0.274993\tvalid_1's l2: 0.316828\n",
      "[750]\ttraining's l2: 0.273129\tvalid_1's l2: 0.31675\n",
      "[800]\ttraining's l2: 0.271379\tvalid_1's l2: 0.316693\n",
      "[850]\ttraining's l2: 0.269621\tvalid_1's l2: 0.316583\n",
      "[900]\ttraining's l2: 0.267908\tvalid_1's l2: 0.316522\n",
      "[950]\ttraining's l2: 0.266237\tvalid_1's l2: 0.316479\n",
      "[1000]\ttraining's l2: 0.26459\tvalid_1's l2: 0.316439\n",
      "[1050]\ttraining's l2: 0.262977\tvalid_1's l2: 0.316428\n",
      "[1100]\ttraining's l2: 0.261382\tvalid_1's l2: 0.316383\n",
      "[1150]\ttraining's l2: 0.259862\tvalid_1's l2: 0.316337\n",
      "[1200]\ttraining's l2: 0.25833\tvalid_1's l2: 0.316321\n",
      "[1250]\ttraining's l2: 0.256837\tvalid_1's l2: 0.316333\n",
      "Early stopping, best iteration is:\n",
      "[1172]\ttraining's l2: 0.25916\tvalid_1's l2: 0.316309\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.108304 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.425715\tvalid_1's l2: 0.453768\n",
      "[100]\ttraining's l2: 0.327269\tvalid_1's l2: 0.358356\n",
      "[150]\ttraining's l2: 0.308279\tvalid_1's l2: 0.342147\n",
      "[200]\ttraining's l2: 0.300753\tvalid_1's l2: 0.337766\n",
      "[250]\ttraining's l2: 0.295727\tvalid_1's l2: 0.335728\n",
      "[300]\ttraining's l2: 0.291819\tvalid_1's l2: 0.33459\n",
      "[350]\ttraining's l2: 0.288682\tvalid_1's l2: 0.333857\n",
      "[400]\ttraining's l2: 0.285973\tvalid_1's l2: 0.333429\n",
      "[450]\ttraining's l2: 0.283534\tvalid_1's l2: 0.333158\n",
      "[500]\ttraining's l2: 0.281197\tvalid_1's l2: 0.332871\n",
      "[550]\ttraining's l2: 0.27907\tvalid_1's l2: 0.332686\n",
      "[600]\ttraining's l2: 0.277033\tvalid_1's l2: 0.332466\n",
      "[650]\ttraining's l2: 0.275028\tvalid_1's l2: 0.332382\n",
      "[700]\ttraining's l2: 0.273165\tvalid_1's l2: 0.332266\n",
      "[750]\ttraining's l2: 0.271334\tvalid_1's l2: 0.332183\n",
      "[800]\ttraining's l2: 0.269591\tvalid_1's l2: 0.332141\n",
      "[850]\ttraining's l2: 0.267827\tvalid_1's l2: 0.332088\n",
      "[900]\ttraining's l2: 0.266095\tvalid_1's l2: 0.332072\n",
      "[950]\ttraining's l2: 0.264437\tvalid_1's l2: 0.332045\n",
      "[1000]\ttraining's l2: 0.262801\tvalid_1's l2: 0.332071\n",
      "Early stopping, best iteration is:\n",
      "[924]\ttraining's l2: 0.265299\tvalid_1's l2: 0.332037\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.108144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.471348\tvalid_1's l2: 0.471809\n",
      "[100]\ttraining's l2: 0.355923\tvalid_1's l2: 0.371763\n",
      "[150]\ttraining's l2: 0.33288\tvalid_1's l2: 0.356294\n",
      "[200]\ttraining's l2: 0.323814\tvalid_1's l2: 0.352223\n",
      "[250]\ttraining's l2: 0.317709\tvalid_1's l2: 0.350306\n",
      "[300]\ttraining's l2: 0.312989\tvalid_1's l2: 0.349105\n",
      "[350]\ttraining's l2: 0.309198\tvalid_1's l2: 0.34835\n",
      "[400]\ttraining's l2: 0.305838\tvalid_1's l2: 0.347714\n",
      "[450]\ttraining's l2: 0.302948\tvalid_1's l2: 0.347294\n",
      "[500]\ttraining's l2: 0.300243\tvalid_1's l2: 0.347017\n",
      "[550]\ttraining's l2: 0.297743\tvalid_1's l2: 0.346755\n",
      "[600]\ttraining's l2: 0.295409\tvalid_1's l2: 0.346539\n",
      "[650]\ttraining's l2: 0.293162\tvalid_1's l2: 0.346239\n",
      "[700]\ttraining's l2: 0.29112\tvalid_1's l2: 0.346198\n",
      "[750]\ttraining's l2: 0.289141\tvalid_1's l2: 0.346125\n",
      "[800]\ttraining's l2: 0.287177\tvalid_1's l2: 0.34604\n",
      "[850]\ttraining's l2: 0.285317\tvalid_1's l2: 0.345969\n",
      "[900]\ttraining's l2: 0.283435\tvalid_1's l2: 0.345863\n",
      "[950]\ttraining's l2: 0.281634\tvalid_1's l2: 0.345781\n",
      "[1000]\ttraining's l2: 0.279846\tvalid_1's l2: 0.345703\n",
      "[1050]\ttraining's l2: 0.278163\tvalid_1's l2: 0.345689\n",
      "[1100]\ttraining's l2: 0.27647\tvalid_1's l2: 0.345649\n",
      "[1150]\ttraining's l2: 0.274788\tvalid_1's l2: 0.345619\n",
      "[1200]\ttraining's l2: 0.273146\tvalid_1's l2: 0.345603\n",
      "[1250]\ttraining's l2: 0.271562\tvalid_1's l2: 0.3456\n",
      "[1300]\ttraining's l2: 0.269985\tvalid_1's l2: 0.345623\n",
      "[1350]\ttraining's l2: 0.268414\tvalid_1's l2: 0.345583\n",
      "[1400]\ttraining's l2: 0.266915\tvalid_1's l2: 0.345527\n",
      "[1450]\ttraining's l2: 0.265452\tvalid_1's l2: 0.345494\n",
      "[1500]\ttraining's l2: 0.264019\tvalid_1's l2: 0.345536\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.264019\tvalid_1's l2: 0.345536\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.107814 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.492015\tvalid_1's l2: 0.484748\n",
      "[100]\ttraining's l2: 0.367196\tvalid_1's l2: 0.377019\n",
      "[150]\ttraining's l2: 0.341988\tvalid_1's l2: 0.359865\n",
      "[200]\ttraining's l2: 0.331529\tvalid_1's l2: 0.35469\n",
      "[250]\ttraining's l2: 0.324131\tvalid_1's l2: 0.351575\n",
      "[300]\ttraining's l2: 0.318628\tvalid_1's l2: 0.349735\n",
      "[350]\ttraining's l2: 0.314214\tvalid_1's l2: 0.348723\n",
      "[400]\ttraining's l2: 0.310641\tvalid_1's l2: 0.348044\n",
      "[450]\ttraining's l2: 0.307409\tvalid_1's l2: 0.347607\n",
      "[500]\ttraining's l2: 0.304497\tvalid_1's l2: 0.347287\n",
      "[550]\ttraining's l2: 0.301847\tvalid_1's l2: 0.346989\n",
      "[600]\ttraining's l2: 0.29936\tvalid_1's l2: 0.346708\n",
      "[650]\ttraining's l2: 0.297078\tvalid_1's l2: 0.346609\n",
      "[700]\ttraining's l2: 0.294844\tvalid_1's l2: 0.346392\n",
      "[750]\ttraining's l2: 0.292726\tvalid_1's l2: 0.346345\n",
      "[800]\ttraining's l2: 0.290627\tvalid_1's l2: 0.346272\n",
      "[850]\ttraining's l2: 0.288577\tvalid_1's l2: 0.346162\n",
      "[900]\ttraining's l2: 0.286675\tvalid_1's l2: 0.346135\n",
      "[950]\ttraining's l2: 0.284766\tvalid_1's l2: 0.346175\n",
      "[1000]\ttraining's l2: 0.282942\tvalid_1's l2: 0.346119\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttraining's l2: 0.287417\tvalid_1's l2: 0.346076\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.108423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.463102\tvalid_1's l2: 0.477325\n",
      "[100]\ttraining's l2: 0.363889\tvalid_1's l2: 0.379607\n",
      "[150]\ttraining's l2: 0.343733\tvalid_1's l2: 0.36225\n",
      "[200]\ttraining's l2: 0.335222\tvalid_1's l2: 0.357187\n",
      "[250]\ttraining's l2: 0.329207\tvalid_1's l2: 0.354205\n",
      "[300]\ttraining's l2: 0.324679\tvalid_1's l2: 0.352617\n",
      "[350]\ttraining's l2: 0.32101\tvalid_1's l2: 0.351754\n",
      "[400]\ttraining's l2: 0.31785\tvalid_1's l2: 0.351339\n",
      "[450]\ttraining's l2: 0.314911\tvalid_1's l2: 0.350924\n",
      "[500]\ttraining's l2: 0.312192\tvalid_1's l2: 0.350742\n",
      "[550]\ttraining's l2: 0.309657\tvalid_1's l2: 0.350538\n",
      "[600]\ttraining's l2: 0.307302\tvalid_1's l2: 0.350301\n",
      "[650]\ttraining's l2: 0.305055\tvalid_1's l2: 0.350285\n",
      "[700]\ttraining's l2: 0.302896\tvalid_1's l2: 0.350289\n",
      "[750]\ttraining's l2: 0.300889\tvalid_1's l2: 0.350209\n",
      "[800]\ttraining's l2: 0.298818\tvalid_1's l2: 0.350087\n",
      "[850]\ttraining's l2: 0.296791\tvalid_1's l2: 0.350059\n",
      "[900]\ttraining's l2: 0.294828\tvalid_1's l2: 0.35\n",
      "[950]\ttraining's l2: 0.292908\tvalid_1's l2: 0.350038\n",
      "[1000]\ttraining's l2: 0.291092\tvalid_1's l2: 0.34997\n",
      "[1050]\ttraining's l2: 0.289325\tvalid_1's l2: 0.349972\n",
      "[1100]\ttraining's l2: 0.287515\tvalid_1's l2: 0.349889\n",
      "[1150]\ttraining's l2: 0.285777\tvalid_1's l2: 0.349894\n",
      "[1200]\ttraining's l2: 0.284081\tvalid_1's l2: 0.349872\n",
      "[1250]\ttraining's l2: 0.282425\tvalid_1's l2: 0.349893\n",
      "[1300]\ttraining's l2: 0.280728\tvalid_1's l2: 0.349844\n",
      "[1350]\ttraining's l2: 0.279137\tvalid_1's l2: 0.349857\n",
      "[1400]\ttraining's l2: 0.277621\tvalid_1's l2: 0.34989\n",
      "Early stopping, best iteration is:\n",
      "[1283]\ttraining's l2: 0.281313\tvalid_1's l2: 0.349832\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.109680 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.450639\tvalid_1's l2: 0.550119\n",
      "[100]\ttraining's l2: 0.355215\tvalid_1's l2: 0.440411\n",
      "[150]\ttraining's l2: 0.335519\tvalid_1's l2: 0.417648\n",
      "[200]\ttraining's l2: 0.327103\tvalid_1's l2: 0.410658\n",
      "[250]\ttraining's l2: 0.321061\tvalid_1's l2: 0.407549\n",
      "[300]\ttraining's l2: 0.316745\tvalid_1's l2: 0.405685\n",
      "[350]\ttraining's l2: 0.313163\tvalid_1's l2: 0.404499\n",
      "[400]\ttraining's l2: 0.310078\tvalid_1's l2: 0.403764\n",
      "[450]\ttraining's l2: 0.307217\tvalid_1's l2: 0.40301\n",
      "[500]\ttraining's l2: 0.304566\tvalid_1's l2: 0.402607\n",
      "[550]\ttraining's l2: 0.302135\tvalid_1's l2: 0.402199\n",
      "[600]\ttraining's l2: 0.299807\tvalid_1's l2: 0.401743\n",
      "[650]\ttraining's l2: 0.297638\tvalid_1's l2: 0.401519\n",
      "[700]\ttraining's l2: 0.295517\tvalid_1's l2: 0.401412\n",
      "[750]\ttraining's l2: 0.293485\tvalid_1's l2: 0.401171\n",
      "[800]\ttraining's l2: 0.291488\tvalid_1's l2: 0.400989\n",
      "[850]\ttraining's l2: 0.28956\tvalid_1's l2: 0.401002\n",
      "[900]\ttraining's l2: 0.287704\tvalid_1's l2: 0.400938\n",
      "[950]\ttraining's l2: 0.285902\tvalid_1's l2: 0.400733\n",
      "[1000]\ttraining's l2: 0.284162\tvalid_1's l2: 0.400687\n",
      "[1050]\ttraining's l2: 0.282417\tvalid_1's l2: 0.400584\n",
      "[1100]\ttraining's l2: 0.280669\tvalid_1's l2: 0.400563\n",
      "[1150]\ttraining's l2: 0.278979\tvalid_1's l2: 0.40044\n",
      "[1200]\ttraining's l2: 0.277321\tvalid_1's l2: 0.400384\n",
      "[1250]\ttraining's l2: 0.275673\tvalid_1's l2: 0.400366\n",
      "[1300]\ttraining's l2: 0.274111\tvalid_1's l2: 0.400394\n",
      "[1350]\ttraining's l2: 0.272573\tvalid_1's l2: 0.400296\n",
      "[1400]\ttraining's l2: 0.27104\tvalid_1's l2: 0.400214\n",
      "[1450]\ttraining's l2: 0.269488\tvalid_1's l2: 0.400142\n",
      "[1500]\ttraining's l2: 0.26801\tvalid_1's l2: 0.400158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.26801\tvalid_1's l2: 0.400158\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.105734 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.439308\tvalid_1's l2: 0.516446\n",
      "[100]\ttraining's l2: 0.338941\tvalid_1's l2: 0.405836\n",
      "[150]\ttraining's l2: 0.318942\tvalid_1's l2: 0.384278\n",
      "[200]\ttraining's l2: 0.310441\tvalid_1's l2: 0.377628\n",
      "[250]\ttraining's l2: 0.304639\tvalid_1's l2: 0.374106\n",
      "[300]\ttraining's l2: 0.300513\tvalid_1's l2: 0.372454\n",
      "[350]\ttraining's l2: 0.297135\tvalid_1's l2: 0.371689\n",
      "[400]\ttraining's l2: 0.294156\tvalid_1's l2: 0.371196\n",
      "[450]\ttraining's l2: 0.291454\tvalid_1's l2: 0.370786\n",
      "[500]\ttraining's l2: 0.288967\tvalid_1's l2: 0.370356\n",
      "[550]\ttraining's l2: 0.286679\tvalid_1's l2: 0.370142\n",
      "[600]\ttraining's l2: 0.284502\tvalid_1's l2: 0.369981\n",
      "[650]\ttraining's l2: 0.282372\tvalid_1's l2: 0.369832\n",
      "[700]\ttraining's l2: 0.280416\tvalid_1's l2: 0.369579\n",
      "[750]\ttraining's l2: 0.278511\tvalid_1's l2: 0.369506\n",
      "[800]\ttraining's l2: 0.276668\tvalid_1's l2: 0.369361\n",
      "[850]\ttraining's l2: 0.274866\tvalid_1's l2: 0.369228\n",
      "[900]\ttraining's l2: 0.273086\tvalid_1's l2: 0.369129\n",
      "[950]\ttraining's l2: 0.271406\tvalid_1's l2: 0.369065\n",
      "[1000]\ttraining's l2: 0.269768\tvalid_1's l2: 0.368948\n",
      "[1050]\ttraining's l2: 0.268144\tvalid_1's l2: 0.36899\n",
      "[1100]\ttraining's l2: 0.266541\tvalid_1's l2: 0.368937\n",
      "[1150]\ttraining's l2: 0.26502\tvalid_1's l2: 0.368836\n",
      "[1200]\ttraining's l2: 0.263482\tvalid_1's l2: 0.368836\n",
      "[1250]\ttraining's l2: 0.261994\tvalid_1's l2: 0.368765\n",
      "[1300]\ttraining's l2: 0.260495\tvalid_1's l2: 0.368746\n",
      "[1350]\ttraining's l2: 0.259014\tvalid_1's l2: 0.368743\n",
      "[1400]\ttraining's l2: 0.257575\tvalid_1's l2: 0.368733\n",
      "[1450]\ttraining's l2: 0.256106\tvalid_1's l2: 0.36876\n",
      "[1500]\ttraining's l2: 0.254723\tvalid_1's l2: 0.368794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.254723\tvalid_1's l2: 0.368794\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.109510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.432761\tvalid_1's l2: 0.480118\n",
      "[100]\ttraining's l2: 0.349154\tvalid_1's l2: 0.394292\n",
      "[150]\ttraining's l2: 0.330867\tvalid_1's l2: 0.377933\n",
      "[200]\ttraining's l2: 0.322679\tvalid_1's l2: 0.373149\n",
      "[250]\ttraining's l2: 0.317074\tvalid_1's l2: 0.370914\n",
      "[300]\ttraining's l2: 0.312948\tvalid_1's l2: 0.369806\n",
      "[350]\ttraining's l2: 0.309751\tvalid_1's l2: 0.368968\n",
      "[400]\ttraining's l2: 0.306851\tvalid_1's l2: 0.368523\n",
      "[450]\ttraining's l2: 0.304211\tvalid_1's l2: 0.3683\n",
      "[500]\ttraining's l2: 0.301817\tvalid_1's l2: 0.368121\n",
      "[550]\ttraining's l2: 0.29945\tvalid_1's l2: 0.367939\n",
      "[600]\ttraining's l2: 0.297252\tvalid_1's l2: 0.367753\n",
      "[650]\ttraining's l2: 0.295149\tvalid_1's l2: 0.367627\n",
      "[700]\ttraining's l2: 0.293112\tvalid_1's l2: 0.367616\n",
      "[750]\ttraining's l2: 0.291182\tvalid_1's l2: 0.367592\n",
      "[800]\ttraining's l2: 0.289303\tvalid_1's l2: 0.36754\n",
      "[850]\ttraining's l2: 0.287444\tvalid_1's l2: 0.367424\n",
      "[900]\ttraining's l2: 0.285601\tvalid_1's l2: 0.36744\n",
      "[950]\ttraining's l2: 0.283803\tvalid_1's l2: 0.367458\n",
      "[1000]\ttraining's l2: 0.282075\tvalid_1's l2: 0.367364\n",
      "[1050]\ttraining's l2: 0.280395\tvalid_1's l2: 0.36733\n",
      "[1100]\ttraining's l2: 0.278695\tvalid_1's l2: 0.367323\n",
      "[1150]\ttraining's l2: 0.277073\tvalid_1's l2: 0.367305\n",
      "[1200]\ttraining's l2: 0.275473\tvalid_1's l2: 0.367342\n",
      "Early stopping, best iteration is:\n",
      "[1085]\ttraining's l2: 0.279185\tvalid_1's l2: 0.367269\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.103900 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.449453\tvalid_1's l2: 0.48465\n",
      "[100]\ttraining's l2: 0.35305\tvalid_1's l2: 0.388383\n",
      "[150]\ttraining's l2: 0.331629\tvalid_1's l2: 0.370419\n",
      "[200]\ttraining's l2: 0.32196\tvalid_1's l2: 0.365345\n",
      "[250]\ttraining's l2: 0.315185\tvalid_1's l2: 0.363086\n",
      "[300]\ttraining's l2: 0.310501\tvalid_1's l2: 0.361902\n",
      "[350]\ttraining's l2: 0.30673\tvalid_1's l2: 0.361135\n",
      "[400]\ttraining's l2: 0.30354\tvalid_1's l2: 0.360486\n",
      "[450]\ttraining's l2: 0.300677\tvalid_1's l2: 0.360116\n",
      "[500]\ttraining's l2: 0.29807\tvalid_1's l2: 0.359846\n",
      "[550]\ttraining's l2: 0.295662\tvalid_1's l2: 0.359656\n",
      "[600]\ttraining's l2: 0.2934\tvalid_1's l2: 0.359508\n",
      "[650]\ttraining's l2: 0.29124\tvalid_1's l2: 0.359359\n",
      "[700]\ttraining's l2: 0.289264\tvalid_1's l2: 0.359241\n",
      "[750]\ttraining's l2: 0.287287\tvalid_1's l2: 0.359189\n",
      "[800]\ttraining's l2: 0.285362\tvalid_1's l2: 0.359149\n",
      "[850]\ttraining's l2: 0.28348\tvalid_1's l2: 0.359085\n",
      "[900]\ttraining's l2: 0.281673\tvalid_1's l2: 0.359006\n",
      "[950]\ttraining's l2: 0.279945\tvalid_1's l2: 0.358875\n",
      "[1000]\ttraining's l2: 0.278214\tvalid_1's l2: 0.358857\n",
      "[1050]\ttraining's l2: 0.276522\tvalid_1's l2: 0.358785\n",
      "[1100]\ttraining's l2: 0.274881\tvalid_1's l2: 0.358777\n",
      "[1150]\ttraining's l2: 0.27325\tvalid_1's l2: 0.358785\n",
      "Early stopping, best iteration is:\n",
      "[1043]\ttraining's l2: 0.276739\tvalid_1's l2: 0.358759\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.117991 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.478353\tvalid_1's l2: 0.491861\n",
      "[100]\ttraining's l2: 0.372584\tvalid_1's l2: 0.392852\n",
      "[150]\ttraining's l2: 0.349582\tvalid_1's l2: 0.375958\n",
      "[200]\ttraining's l2: 0.339382\tvalid_1's l2: 0.371586\n",
      "[250]\ttraining's l2: 0.332496\tvalid_1's l2: 0.369422\n",
      "[300]\ttraining's l2: 0.327281\tvalid_1's l2: 0.367985\n",
      "[350]\ttraining's l2: 0.323078\tvalid_1's l2: 0.367294\n",
      "[400]\ttraining's l2: 0.319316\tvalid_1's l2: 0.366575\n",
      "[450]\ttraining's l2: 0.316076\tvalid_1's l2: 0.365934\n",
      "[500]\ttraining's l2: 0.313153\tvalid_1's l2: 0.365676\n",
      "[550]\ttraining's l2: 0.310432\tvalid_1's l2: 0.365369\n",
      "[600]\ttraining's l2: 0.30794\tvalid_1's l2: 0.365147\n",
      "[650]\ttraining's l2: 0.305637\tvalid_1's l2: 0.364952\n",
      "[700]\ttraining's l2: 0.303413\tvalid_1's l2: 0.36486\n",
      "[750]\ttraining's l2: 0.301317\tvalid_1's l2: 0.364714\n",
      "[800]\ttraining's l2: 0.29927\tvalid_1's l2: 0.364685\n",
      "[850]\ttraining's l2: 0.297232\tvalid_1's l2: 0.364671\n",
      "[900]\ttraining's l2: 0.2953\tvalid_1's l2: 0.364638\n",
      "[950]\ttraining's l2: 0.293475\tvalid_1's l2: 0.364615\n",
      "[1000]\ttraining's l2: 0.291644\tvalid_1's l2: 0.364561\n",
      "[1050]\ttraining's l2: 0.289835\tvalid_1's l2: 0.364486\n",
      "[1100]\ttraining's l2: 0.288136\tvalid_1's l2: 0.364485\n",
      "[1150]\ttraining's l2: 0.286437\tvalid_1's l2: 0.364525\n",
      "[1200]\ttraining's l2: 0.284751\tvalid_1's l2: 0.364518\n",
      "Early stopping, best iteration is:\n",
      "[1111]\ttraining's l2: 0.287738\tvalid_1's l2: 0.364477\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.104240 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.503549\tvalid_1's l2: 0.510088\n",
      "[100]\ttraining's l2: 0.384843\tvalid_1's l2: 0.403143\n",
      "[150]\ttraining's l2: 0.359257\tvalid_1's l2: 0.385473\n",
      "[200]\ttraining's l2: 0.347555\tvalid_1's l2: 0.380211\n",
      "[250]\ttraining's l2: 0.338861\tvalid_1's l2: 0.377508\n",
      "[300]\ttraining's l2: 0.332825\tvalid_1's l2: 0.376016\n",
      "[350]\ttraining's l2: 0.32802\tvalid_1's l2: 0.375129\n",
      "[400]\ttraining's l2: 0.32405\tvalid_1's l2: 0.374659\n",
      "[450]\ttraining's l2: 0.320563\tvalid_1's l2: 0.374133\n",
      "[500]\ttraining's l2: 0.317474\tvalid_1's l2: 0.373922\n",
      "[550]\ttraining's l2: 0.314562\tvalid_1's l2: 0.373675\n",
      "[600]\ttraining's l2: 0.31187\tvalid_1's l2: 0.373454\n",
      "[650]\ttraining's l2: 0.309338\tvalid_1's l2: 0.373264\n",
      "[700]\ttraining's l2: 0.306947\tvalid_1's l2: 0.373078\n",
      "[750]\ttraining's l2: 0.304661\tvalid_1's l2: 0.372987\n",
      "[800]\ttraining's l2: 0.302454\tvalid_1's l2: 0.372813\n",
      "[850]\ttraining's l2: 0.300395\tvalid_1's l2: 0.37269\n",
      "[900]\ttraining's l2: 0.298317\tvalid_1's l2: 0.372681\n",
      "[950]\ttraining's l2: 0.296333\tvalid_1's l2: 0.372657\n",
      "[1000]\ttraining's l2: 0.294386\tvalid_1's l2: 0.372577\n",
      "[1050]\ttraining's l2: 0.292522\tvalid_1's l2: 0.372573\n",
      "[1100]\ttraining's l2: 0.290696\tvalid_1's l2: 0.372521\n",
      "[1150]\ttraining's l2: 0.288891\tvalid_1's l2: 0.372403\n",
      "[1200]\ttraining's l2: 0.287175\tvalid_1's l2: 0.372397\n",
      "[1250]\ttraining's l2: 0.285439\tvalid_1's l2: 0.372331\n",
      "[1300]\ttraining's l2: 0.283747\tvalid_1's l2: 0.372302\n",
      "[1350]\ttraining's l2: 0.282133\tvalid_1's l2: 0.3723\n",
      "[1400]\ttraining's l2: 0.280502\tvalid_1's l2: 0.37226\n",
      "[1450]\ttraining's l2: 0.278914\tvalid_1's l2: 0.372272\n",
      "[1500]\ttraining's l2: 0.277339\tvalid_1's l2: 0.372258\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.277339\tvalid_1's l2: 0.372258\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.107813 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.466725\tvalid_1's l2: 0.479931\n",
      "[100]\ttraining's l2: 0.371197\tvalid_1's l2: 0.391702\n",
      "[150]\ttraining's l2: 0.350532\tvalid_1's l2: 0.377534\n",
      "[200]\ttraining's l2: 0.341171\tvalid_1's l2: 0.374325\n",
      "[250]\ttraining's l2: 0.334583\tvalid_1's l2: 0.372796\n",
      "[300]\ttraining's l2: 0.329611\tvalid_1's l2: 0.371891\n",
      "[350]\ttraining's l2: 0.325741\tvalid_1's l2: 0.371447\n",
      "[400]\ttraining's l2: 0.322367\tvalid_1's l2: 0.371084\n",
      "[450]\ttraining's l2: 0.319304\tvalid_1's l2: 0.370893\n",
      "[500]\ttraining's l2: 0.31635\tvalid_1's l2: 0.370762\n",
      "[550]\ttraining's l2: 0.313756\tvalid_1's l2: 0.370638\n",
      "[600]\ttraining's l2: 0.311225\tvalid_1's l2: 0.370688\n",
      "[650]\ttraining's l2: 0.30884\tvalid_1's l2: 0.370629\n",
      "[700]\ttraining's l2: 0.306642\tvalid_1's l2: 0.370601\n",
      "[750]\ttraining's l2: 0.304447\tvalid_1's l2: 0.370622\n",
      "[800]\ttraining's l2: 0.302311\tvalid_1's l2: 0.37061\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's l2: 0.306253\tvalid_1's l2: 0.370576\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.104250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.449094\tvalid_1's l2: 0.46073\n",
      "[100]\ttraining's l2: 0.358095\tvalid_1's l2: 0.376952\n",
      "[150]\ttraining's l2: 0.338416\tvalid_1's l2: 0.363255\n",
      "[200]\ttraining's l2: 0.329391\tvalid_1's l2: 0.359904\n",
      "[250]\ttraining's l2: 0.32308\tvalid_1's l2: 0.35853\n",
      "[300]\ttraining's l2: 0.318523\tvalid_1's l2: 0.35774\n",
      "[350]\ttraining's l2: 0.314918\tvalid_1's l2: 0.357304\n",
      "[400]\ttraining's l2: 0.311707\tvalid_1's l2: 0.357118\n",
      "[450]\ttraining's l2: 0.308893\tvalid_1's l2: 0.357035\n",
      "[500]\ttraining's l2: 0.306243\tvalid_1's l2: 0.356813\n",
      "[550]\ttraining's l2: 0.303806\tvalid_1's l2: 0.356703\n",
      "[600]\ttraining's l2: 0.301514\tvalid_1's l2: 0.356737\n",
      "[650]\ttraining's l2: 0.299309\tvalid_1's l2: 0.356606\n",
      "[700]\ttraining's l2: 0.297213\tvalid_1's l2: 0.356621\n",
      "[750]\ttraining's l2: 0.295182\tvalid_1's l2: 0.356641\n",
      "Early stopping, best iteration is:\n",
      "[661]\ttraining's l2: 0.298833\tvalid_1's l2: 0.356585\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.103199 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.445375\tvalid_1's l2: 0.450609\n",
      "[100]\ttraining's l2: 0.348665\tvalid_1's l2: 0.362706\n",
      "[150]\ttraining's l2: 0.328136\tvalid_1's l2: 0.348009\n",
      "[200]\ttraining's l2: 0.318654\tvalid_1's l2: 0.343925\n",
      "[250]\ttraining's l2: 0.311777\tvalid_1's l2: 0.341987\n",
      "[300]\ttraining's l2: 0.30732\tvalid_1's l2: 0.341228\n",
      "[350]\ttraining's l2: 0.303759\tvalid_1's l2: 0.340741\n",
      "[400]\ttraining's l2: 0.300612\tvalid_1's l2: 0.340348\n",
      "[450]\ttraining's l2: 0.297788\tvalid_1's l2: 0.340177\n",
      "[500]\ttraining's l2: 0.295247\tvalid_1's l2: 0.339945\n",
      "[550]\ttraining's l2: 0.292894\tvalid_1's l2: 0.339686\n",
      "[600]\ttraining's l2: 0.290682\tvalid_1's l2: 0.339564\n",
      "[650]\ttraining's l2: 0.288553\tvalid_1's l2: 0.339446\n",
      "[700]\ttraining's l2: 0.286562\tvalid_1's l2: 0.339337\n",
      "[750]\ttraining's l2: 0.284635\tvalid_1's l2: 0.339191\n",
      "[800]\ttraining's l2: 0.282819\tvalid_1's l2: 0.339149\n",
      "[850]\ttraining's l2: 0.281059\tvalid_1's l2: 0.339076\n",
      "[900]\ttraining's l2: 0.279281\tvalid_1's l2: 0.339016\n",
      "[950]\ttraining's l2: 0.277574\tvalid_1's l2: 0.339017\n",
      "[1000]\ttraining's l2: 0.275915\tvalid_1's l2: 0.339004\n",
      "[1050]\ttraining's l2: 0.274336\tvalid_1's l2: 0.339008\n",
      "Early stopping, best iteration is:\n",
      "[971]\ttraining's l2: 0.276885\tvalid_1's l2: 0.338981\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.107631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.440234\tvalid_1's l2: 0.457749\n",
      "[100]\ttraining's l2: 0.358916\tvalid_1's l2: 0.383695\n",
      "[150]\ttraining's l2: 0.340575\tvalid_1's l2: 0.371368\n",
      "[200]\ttraining's l2: 0.331685\tvalid_1's l2: 0.368316\n",
      "[250]\ttraining's l2: 0.324998\tvalid_1's l2: 0.366745\n",
      "[300]\ttraining's l2: 0.320197\tvalid_1's l2: 0.365773\n",
      "[350]\ttraining's l2: 0.316465\tvalid_1's l2: 0.365062\n",
      "[400]\ttraining's l2: 0.313244\tvalid_1's l2: 0.364641\n",
      "[450]\ttraining's l2: 0.310427\tvalid_1's l2: 0.364458\n",
      "[500]\ttraining's l2: 0.30784\tvalid_1's l2: 0.364239\n",
      "[550]\ttraining's l2: 0.305418\tvalid_1's l2: 0.364068\n",
      "[600]\ttraining's l2: 0.303121\tvalid_1's l2: 0.36393\n",
      "[650]\ttraining's l2: 0.300968\tvalid_1's l2: 0.363865\n",
      "[700]\ttraining's l2: 0.298883\tvalid_1's l2: 0.363705\n",
      "[750]\ttraining's l2: 0.296842\tvalid_1's l2: 0.363692\n",
      "[800]\ttraining's l2: 0.294865\tvalid_1's l2: 0.363674\n",
      "[850]\ttraining's l2: 0.29294\tvalid_1's l2: 0.363673\n",
      "[900]\ttraining's l2: 0.291074\tvalid_1's l2: 0.363672\n",
      "[950]\ttraining's l2: 0.289258\tvalid_1's l2: 0.363691\n",
      "[1000]\ttraining's l2: 0.287505\tvalid_1's l2: 0.363645\n",
      "[1050]\ttraining's l2: 0.28582\tvalid_1's l2: 0.363621\n",
      "[1100]\ttraining's l2: 0.284118\tvalid_1's l2: 0.363673\n",
      "[1150]\ttraining's l2: 0.2825\tvalid_1's l2: 0.363706\n",
      "Early stopping, best iteration is:\n",
      "[1038]\ttraining's l2: 0.286211\tvalid_1's l2: 0.363608\n",
      "==================================================\n",
      "Training Model No. 5 ...\n",
      "Parameters -->  {'learning_rate': 0.023139883898489706, 'num_leaves': 75, 'min_data_in_leaf': 176, 'feature_fraction': 0.8949692657420365, 'bagging_fraction': 0.6400288679743941, 'bagging_freq': 3}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.108946 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.382323\tvalid_1's l2: 0.37358\n",
      "[100]\ttraining's l2: 0.300834\tvalid_1's l2: 0.301361\n",
      "[150]\ttraining's l2: 0.286424\tvalid_1's l2: 0.291611\n",
      "[200]\ttraining's l2: 0.280005\tvalid_1's l2: 0.288563\n",
      "[250]\ttraining's l2: 0.275634\tvalid_1's l2: 0.287125\n",
      "[300]\ttraining's l2: 0.272385\tvalid_1's l2: 0.286566\n",
      "[350]\ttraining's l2: 0.269489\tvalid_1's l2: 0.286288\n",
      "[400]\ttraining's l2: 0.266863\tvalid_1's l2: 0.286041\n",
      "[450]\ttraining's l2: 0.264435\tvalid_1's l2: 0.285919\n",
      "[500]\ttraining's l2: 0.262026\tvalid_1's l2: 0.285725\n",
      "[550]\ttraining's l2: 0.25976\tvalid_1's l2: 0.285582\n",
      "[600]\ttraining's l2: 0.257703\tvalid_1's l2: 0.28553\n",
      "[650]\ttraining's l2: 0.255626\tvalid_1's l2: 0.285425\n",
      "[700]\ttraining's l2: 0.253585\tvalid_1's l2: 0.285437\n",
      "[750]\ttraining's l2: 0.251596\tvalid_1's l2: 0.285414\n",
      "[800]\ttraining's l2: 0.249721\tvalid_1's l2: 0.285358\n",
      "[850]\ttraining's l2: 0.247846\tvalid_1's l2: 0.285362\n",
      "[900]\ttraining's l2: 0.246044\tvalid_1's l2: 0.285311\n",
      "[950]\ttraining's l2: 0.244244\tvalid_1's l2: 0.285257\n",
      "[1000]\ttraining's l2: 0.242445\tvalid_1's l2: 0.28527\n",
      "Early stopping, best iteration is:\n",
      "[920]\ttraining's l2: 0.245341\tvalid_1's l2: 0.285237\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.110903 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.385377\tvalid_1's l2: 0.396327\n",
      "[100]\ttraining's l2: 0.317236\tvalid_1's l2: 0.333841\n",
      "[150]\ttraining's l2: 0.304449\tvalid_1's l2: 0.32437\n",
      "[200]\ttraining's l2: 0.298275\tvalid_1's l2: 0.321037\n",
      "[250]\ttraining's l2: 0.293826\tvalid_1's l2: 0.319242\n",
      "[300]\ttraining's l2: 0.290288\tvalid_1's l2: 0.318603\n",
      "[350]\ttraining's l2: 0.287142\tvalid_1's l2: 0.318188\n",
      "[400]\ttraining's l2: 0.284272\tvalid_1's l2: 0.317996\n",
      "[450]\ttraining's l2: 0.281643\tvalid_1's l2: 0.317564\n",
      "[500]\ttraining's l2: 0.279049\tvalid_1's l2: 0.317331\n",
      "[550]\ttraining's l2: 0.276586\tvalid_1's l2: 0.317161\n",
      "[600]\ttraining's l2: 0.274206\tvalid_1's l2: 0.316975\n",
      "[650]\ttraining's l2: 0.272007\tvalid_1's l2: 0.316894\n",
      "[700]\ttraining's l2: 0.269827\tvalid_1's l2: 0.316843\n",
      "[750]\ttraining's l2: 0.267789\tvalid_1's l2: 0.316805\n",
      "[800]\ttraining's l2: 0.26568\tvalid_1's l2: 0.316861\n",
      "[850]\ttraining's l2: 0.263648\tvalid_1's l2: 0.316844\n",
      "Early stopping, best iteration is:\n",
      "[751]\ttraining's l2: 0.26775\tvalid_1's l2: 0.316803\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.106456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.40044\tvalid_1's l2: 0.429349\n",
      "[100]\ttraining's l2: 0.320176\tvalid_1's l2: 0.352351\n",
      "[150]\ttraining's l2: 0.304916\tvalid_1's l2: 0.340589\n",
      "[200]\ttraining's l2: 0.297862\tvalid_1's l2: 0.337082\n",
      "[250]\ttraining's l2: 0.292838\tvalid_1's l2: 0.335292\n",
      "[300]\ttraining's l2: 0.289054\tvalid_1's l2: 0.334668\n",
      "[350]\ttraining's l2: 0.28562\tvalid_1's l2: 0.334068\n",
      "[400]\ttraining's l2: 0.282775\tvalid_1's l2: 0.333609\n",
      "[450]\ttraining's l2: 0.280119\tvalid_1's l2: 0.33332\n",
      "[500]\ttraining's l2: 0.277612\tvalid_1's l2: 0.333167\n",
      "[550]\ttraining's l2: 0.275169\tvalid_1's l2: 0.332913\n",
      "[600]\ttraining's l2: 0.272733\tvalid_1's l2: 0.332803\n",
      "[650]\ttraining's l2: 0.270396\tvalid_1's l2: 0.332706\n",
      "[700]\ttraining's l2: 0.268256\tvalid_1's l2: 0.332766\n",
      "[750]\ttraining's l2: 0.266187\tvalid_1's l2: 0.332799\n",
      "Early stopping, best iteration is:\n",
      "[645]\ttraining's l2: 0.270612\tvalid_1's l2: 0.332687\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.115626 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.442697\tvalid_1's l2: 0.44574\n",
      "[100]\ttraining's l2: 0.347287\tvalid_1's l2: 0.365632\n",
      "[150]\ttraining's l2: 0.328816\tvalid_1's l2: 0.354791\n",
      "[200]\ttraining's l2: 0.320382\tvalid_1's l2: 0.351699\n",
      "[250]\ttraining's l2: 0.314206\tvalid_1's l2: 0.349927\n",
      "[300]\ttraining's l2: 0.309474\tvalid_1's l2: 0.349084\n",
      "[350]\ttraining's l2: 0.305539\tvalid_1's l2: 0.348388\n",
      "[400]\ttraining's l2: 0.30218\tvalid_1's l2: 0.347995\n",
      "[450]\ttraining's l2: 0.299104\tvalid_1's l2: 0.347673\n",
      "[500]\ttraining's l2: 0.296202\tvalid_1's l2: 0.347552\n",
      "[550]\ttraining's l2: 0.293453\tvalid_1's l2: 0.347433\n",
      "[600]\ttraining's l2: 0.290886\tvalid_1's l2: 0.347412\n",
      "[650]\ttraining's l2: 0.288347\tvalid_1's l2: 0.347159\n",
      "[700]\ttraining's l2: 0.286041\tvalid_1's l2: 0.347138\n",
      "[750]\ttraining's l2: 0.283766\tvalid_1's l2: 0.34708\n",
      "[800]\ttraining's l2: 0.28156\tvalid_1's l2: 0.347039\n",
      "[850]\ttraining's l2: 0.279408\tvalid_1's l2: 0.34701\n",
      "[900]\ttraining's l2: 0.277327\tvalid_1's l2: 0.347021\n",
      "[950]\ttraining's l2: 0.275357\tvalid_1's l2: 0.347079\n",
      "Early stopping, best iteration is:\n",
      "[858]\ttraining's l2: 0.279037\tvalid_1's l2: 0.346966\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.107762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.461793\tvalid_1's l2: 0.457456\n",
      "[100]\ttraining's l2: 0.35816\tvalid_1's l2: 0.370422\n",
      "[150]\ttraining's l2: 0.337545\tvalid_1's l2: 0.358131\n",
      "[200]\ttraining's l2: 0.327481\tvalid_1's l2: 0.353506\n",
      "[250]\ttraining's l2: 0.320166\tvalid_1's l2: 0.350749\n",
      "[300]\ttraining's l2: 0.314778\tvalid_1's l2: 0.34915\n",
      "[350]\ttraining's l2: 0.310637\tvalid_1's l2: 0.348509\n",
      "[400]\ttraining's l2: 0.306913\tvalid_1's l2: 0.347991\n",
      "[450]\ttraining's l2: 0.303634\tvalid_1's l2: 0.347961\n",
      "[500]\ttraining's l2: 0.300465\tvalid_1's l2: 0.347563\n",
      "[550]\ttraining's l2: 0.297452\tvalid_1's l2: 0.347127\n",
      "[600]\ttraining's l2: 0.294726\tvalid_1's l2: 0.347093\n",
      "[650]\ttraining's l2: 0.29215\tvalid_1's l2: 0.347061\n",
      "[700]\ttraining's l2: 0.289574\tvalid_1's l2: 0.346879\n",
      "[750]\ttraining's l2: 0.287117\tvalid_1's l2: 0.34686\n",
      "[800]\ttraining's l2: 0.284874\tvalid_1's l2: 0.346758\n",
      "[850]\ttraining's l2: 0.282587\tvalid_1's l2: 0.34676\n",
      "[900]\ttraining's l2: 0.280441\tvalid_1's l2: 0.346737\n",
      "Early stopping, best iteration is:\n",
      "[818]\ttraining's l2: 0.284012\tvalid_1's l2: 0.346707\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.108316 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.438045\tvalid_1's l2: 0.452323\n",
      "[100]\ttraining's l2: 0.356203\tvalid_1's l2: 0.372837\n",
      "[150]\ttraining's l2: 0.339748\tvalid_1's l2: 0.360256\n",
      "[200]\ttraining's l2: 0.33159\tvalid_1's l2: 0.356203\n",
      "[250]\ttraining's l2: 0.325803\tvalid_1's l2: 0.353765\n",
      "[300]\ttraining's l2: 0.321195\tvalid_1's l2: 0.352691\n",
      "[350]\ttraining's l2: 0.317287\tvalid_1's l2: 0.352001\n",
      "[400]\ttraining's l2: 0.313805\tvalid_1's l2: 0.351718\n",
      "[450]\ttraining's l2: 0.310643\tvalid_1's l2: 0.351482\n",
      "[500]\ttraining's l2: 0.307593\tvalid_1's l2: 0.351235\n",
      "[550]\ttraining's l2: 0.304782\tvalid_1's l2: 0.351021\n",
      "[600]\ttraining's l2: 0.302176\tvalid_1's l2: 0.350807\n",
      "[650]\ttraining's l2: 0.299664\tvalid_1's l2: 0.350805\n",
      "[700]\ttraining's l2: 0.297231\tvalid_1's l2: 0.350683\n",
      "[750]\ttraining's l2: 0.29488\tvalid_1's l2: 0.350705\n",
      "[800]\ttraining's l2: 0.292619\tvalid_1's l2: 0.350684\n",
      "Early stopping, best iteration is:\n",
      "[719]\ttraining's l2: 0.29635\tvalid_1's l2: 0.350607\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.116874 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.426094\tvalid_1's l2: 0.523569\n",
      "[100]\ttraining's l2: 0.347875\tvalid_1's l2: 0.432168\n",
      "[150]\ttraining's l2: 0.331753\tvalid_1's l2: 0.414223\n",
      "[200]\ttraining's l2: 0.323598\tvalid_1's l2: 0.408051\n",
      "[250]\ttraining's l2: 0.31783\tvalid_1's l2: 0.405083\n",
      "[300]\ttraining's l2: 0.31349\tvalid_1's l2: 0.403457\n",
      "[350]\ttraining's l2: 0.309698\tvalid_1's l2: 0.402535\n",
      "[400]\ttraining's l2: 0.306434\tvalid_1's l2: 0.401658\n",
      "[450]\ttraining's l2: 0.303404\tvalid_1's l2: 0.40099\n",
      "[500]\ttraining's l2: 0.300594\tvalid_1's l2: 0.400748\n",
      "[550]\ttraining's l2: 0.297845\tvalid_1's l2: 0.400329\n",
      "[600]\ttraining's l2: 0.295292\tvalid_1's l2: 0.399895\n",
      "[650]\ttraining's l2: 0.292793\tvalid_1's l2: 0.399567\n",
      "[700]\ttraining's l2: 0.29033\tvalid_1's l2: 0.399639\n",
      "[750]\ttraining's l2: 0.288054\tvalid_1's l2: 0.399497\n",
      "[800]\ttraining's l2: 0.285796\tvalid_1's l2: 0.39943\n",
      "[850]\ttraining's l2: 0.283621\tvalid_1's l2: 0.399419\n",
      "[900]\ttraining's l2: 0.281404\tvalid_1's l2: 0.399395\n",
      "[950]\ttraining's l2: 0.27936\tvalid_1's l2: 0.399392\n",
      "Early stopping, best iteration is:\n",
      "[831]\ttraining's l2: 0.284441\tvalid_1's l2: 0.399313\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.105930 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.412629\tvalid_1's l2: 0.488543\n",
      "[100]\ttraining's l2: 0.331055\tvalid_1's l2: 0.397504\n",
      "[150]\ttraining's l2: 0.315128\tvalid_1's l2: 0.381794\n",
      "[200]\ttraining's l2: 0.306971\tvalid_1's l2: 0.376039\n",
      "[250]\ttraining's l2: 0.301513\tvalid_1's l2: 0.37368\n",
      "[300]\ttraining's l2: 0.297479\tvalid_1's l2: 0.372186\n",
      "[350]\ttraining's l2: 0.293767\tvalid_1's l2: 0.371485\n",
      "[400]\ttraining's l2: 0.290637\tvalid_1's l2: 0.371101\n",
      "[450]\ttraining's l2: 0.28776\tvalid_1's l2: 0.37084\n",
      "[500]\ttraining's l2: 0.285124\tvalid_1's l2: 0.370486\n",
      "[550]\ttraining's l2: 0.282518\tvalid_1's l2: 0.370176\n",
      "[600]\ttraining's l2: 0.280139\tvalid_1's l2: 0.370152\n",
      "[650]\ttraining's l2: 0.277703\tvalid_1's l2: 0.369738\n",
      "[700]\ttraining's l2: 0.275486\tvalid_1's l2: 0.369666\n",
      "[750]\ttraining's l2: 0.273327\tvalid_1's l2: 0.369742\n",
      "[800]\ttraining's l2: 0.271291\tvalid_1's l2: 0.36979\n",
      "Early stopping, best iteration is:\n",
      "[696]\ttraining's l2: 0.275649\tvalid_1's l2: 0.369658\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.107478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.411181\tvalid_1's l2: 0.459257\n",
      "[100]\ttraining's l2: 0.342116\tvalid_1's l2: 0.387821\n",
      "[150]\ttraining's l2: 0.327359\tvalid_1's l2: 0.375846\n",
      "[200]\ttraining's l2: 0.319859\tvalid_1's l2: 0.372439\n",
      "[250]\ttraining's l2: 0.314268\tvalid_1's l2: 0.370356\n",
      "[300]\ttraining's l2: 0.310242\tvalid_1's l2: 0.36946\n",
      "[350]\ttraining's l2: 0.306768\tvalid_1's l2: 0.369028\n",
      "[400]\ttraining's l2: 0.30359\tvalid_1's l2: 0.368736\n",
      "[450]\ttraining's l2: 0.300638\tvalid_1's l2: 0.368391\n",
      "[500]\ttraining's l2: 0.297951\tvalid_1's l2: 0.368288\n",
      "[550]\ttraining's l2: 0.29538\tvalid_1's l2: 0.3682\n",
      "[600]\ttraining's l2: 0.292908\tvalid_1's l2: 0.36808\n",
      "[650]\ttraining's l2: 0.290528\tvalid_1's l2: 0.367968\n",
      "[700]\ttraining's l2: 0.288225\tvalid_1's l2: 0.367955\n",
      "[750]\ttraining's l2: 0.285995\tvalid_1's l2: 0.368118\n",
      "[800]\ttraining's l2: 0.283812\tvalid_1's l2: 0.36798\n",
      "Early stopping, best iteration is:\n",
      "[704]\ttraining's l2: 0.288057\tvalid_1's l2: 0.367919\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.113394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.424689\tvalid_1's l2: 0.459969\n",
      "[100]\ttraining's l2: 0.344752\tvalid_1's l2: 0.38078\n",
      "[150]\ttraining's l2: 0.327588\tvalid_1's l2: 0.368322\n",
      "[200]\ttraining's l2: 0.318483\tvalid_1's l2: 0.364884\n",
      "[250]\ttraining's l2: 0.312232\tvalid_1's l2: 0.363235\n",
      "[300]\ttraining's l2: 0.307563\tvalid_1's l2: 0.362106\n",
      "[350]\ttraining's l2: 0.303713\tvalid_1's l2: 0.361381\n",
      "[400]\ttraining's l2: 0.300431\tvalid_1's l2: 0.361074\n",
      "[450]\ttraining's l2: 0.297526\tvalid_1's l2: 0.360955\n",
      "[500]\ttraining's l2: 0.294724\tvalid_1's l2: 0.360819\n",
      "[550]\ttraining's l2: 0.292102\tvalid_1's l2: 0.360488\n",
      "[600]\ttraining's l2: 0.289583\tvalid_1's l2: 0.360281\n",
      "[650]\ttraining's l2: 0.287115\tvalid_1's l2: 0.360084\n",
      "[700]\ttraining's l2: 0.284753\tvalid_1's l2: 0.359846\n",
      "[750]\ttraining's l2: 0.282489\tvalid_1's l2: 0.359892\n",
      "[800]\ttraining's l2: 0.280287\tvalid_1's l2: 0.359886\n",
      "[850]\ttraining's l2: 0.278233\tvalid_1's l2: 0.359818\n",
      "[900]\ttraining's l2: 0.276127\tvalid_1's l2: 0.359825\n",
      "[950]\ttraining's l2: 0.27412\tvalid_1's l2: 0.359736\n",
      "[1000]\ttraining's l2: 0.272189\tvalid_1's l2: 0.359794\n",
      "[1050]\ttraining's l2: 0.270285\tvalid_1's l2: 0.35977\n",
      "[1100]\ttraining's l2: 0.268433\tvalid_1's l2: 0.359696\n",
      "[1150]\ttraining's l2: 0.26655\tvalid_1's l2: 0.359591\n",
      "[1200]\ttraining's l2: 0.264731\tvalid_1's l2: 0.359731\n",
      "[1250]\ttraining's l2: 0.26298\tvalid_1's l2: 0.359765\n",
      "Early stopping, best iteration is:\n",
      "[1157]\ttraining's l2: 0.266287\tvalid_1's l2: 0.359568\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.110326 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.452514\tvalid_1's l2: 0.467101\n",
      "[100]\ttraining's l2: 0.364123\tvalid_1's l2: 0.385549\n",
      "[150]\ttraining's l2: 0.345599\tvalid_1's l2: 0.374018\n",
      "[200]\ttraining's l2: 0.336168\tvalid_1's l2: 0.370695\n",
      "[250]\ttraining's l2: 0.329098\tvalid_1's l2: 0.368859\n",
      "[300]\ttraining's l2: 0.323908\tvalid_1's l2: 0.36771\n",
      "[350]\ttraining's l2: 0.319358\tvalid_1's l2: 0.36698\n",
      "[400]\ttraining's l2: 0.315541\tvalid_1's l2: 0.366666\n",
      "[450]\ttraining's l2: 0.312138\tvalid_1's l2: 0.366427\n",
      "[500]\ttraining's l2: 0.309034\tvalid_1's l2: 0.36608\n",
      "[550]\ttraining's l2: 0.306133\tvalid_1's l2: 0.365951\n",
      "[600]\ttraining's l2: 0.303425\tvalid_1's l2: 0.36584\n",
      "[650]\ttraining's l2: 0.300786\tvalid_1's l2: 0.365709\n",
      "[700]\ttraining's l2: 0.298297\tvalid_1's l2: 0.365617\n",
      "[750]\ttraining's l2: 0.295836\tvalid_1's l2: 0.365584\n",
      "[800]\ttraining's l2: 0.293591\tvalid_1's l2: 0.36553\n",
      "[850]\ttraining's l2: 0.29133\tvalid_1's l2: 0.365498\n",
      "[900]\ttraining's l2: 0.289007\tvalid_1's l2: 0.365445\n",
      "[950]\ttraining's l2: 0.286982\tvalid_1's l2: 0.36541\n",
      "[1000]\ttraining's l2: 0.28489\tvalid_1's l2: 0.365394\n",
      "[1050]\ttraining's l2: 0.282907\tvalid_1's l2: 0.365362\n",
      "[1100]\ttraining's l2: 0.280973\tvalid_1's l2: 0.365459\n",
      "[1150]\ttraining's l2: 0.27901\tvalid_1's l2: 0.36547\n",
      "Early stopping, best iteration is:\n",
      "[1045]\ttraining's l2: 0.283122\tvalid_1's l2: 0.365342\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.106686 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.474584\tvalid_1's l2: 0.482537\n",
      "[100]\ttraining's l2: 0.37582\tvalid_1's l2: 0.395751\n",
      "[150]\ttraining's l2: 0.354235\tvalid_1's l2: 0.383125\n",
      "[200]\ttraining's l2: 0.343\tvalid_1's l2: 0.379122\n",
      "[250]\ttraining's l2: 0.33484\tvalid_1's l2: 0.377037\n",
      "[300]\ttraining's l2: 0.328981\tvalid_1's l2: 0.375956\n",
      "[350]\ttraining's l2: 0.323936\tvalid_1's l2: 0.375157\n",
      "[400]\ttraining's l2: 0.319813\tvalid_1's l2: 0.374702\n",
      "[450]\ttraining's l2: 0.316045\tvalid_1's l2: 0.374267\n",
      "[500]\ttraining's l2: 0.312691\tvalid_1's l2: 0.374179\n",
      "[550]\ttraining's l2: 0.309712\tvalid_1's l2: 0.373929\n",
      "[600]\ttraining's l2: 0.30681\tvalid_1's l2: 0.373825\n",
      "[650]\ttraining's l2: 0.304068\tvalid_1's l2: 0.373636\n",
      "[700]\ttraining's l2: 0.301529\tvalid_1's l2: 0.373464\n",
      "[750]\ttraining's l2: 0.298995\tvalid_1's l2: 0.373382\n",
      "[800]\ttraining's l2: 0.296569\tvalid_1's l2: 0.373301\n",
      "[850]\ttraining's l2: 0.294286\tvalid_1's l2: 0.373277\n",
      "[900]\ttraining's l2: 0.291947\tvalid_1's l2: 0.37326\n",
      "[950]\ttraining's l2: 0.289736\tvalid_1's l2: 0.373233\n",
      "[1000]\ttraining's l2: 0.287576\tvalid_1's l2: 0.373274\n",
      "[1050]\ttraining's l2: 0.285473\tvalid_1's l2: 0.373275\n",
      "Early stopping, best iteration is:\n",
      "[954]\ttraining's l2: 0.289548\tvalid_1's l2: 0.373187\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.109535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.442651\tvalid_1's l2: 0.457142\n",
      "[100]\ttraining's l2: 0.363447\tvalid_1's l2: 0.385464\n",
      "[150]\ttraining's l2: 0.346629\tvalid_1's l2: 0.375734\n",
      "[200]\ttraining's l2: 0.337302\tvalid_1's l2: 0.373442\n",
      "[250]\ttraining's l2: 0.330629\tvalid_1's l2: 0.37182\n",
      "[300]\ttraining's l2: 0.325843\tvalid_1's l2: 0.371103\n",
      "[350]\ttraining's l2: 0.321779\tvalid_1's l2: 0.370886\n",
      "[400]\ttraining's l2: 0.318154\tvalid_1's l2: 0.370654\n",
      "[450]\ttraining's l2: 0.314749\tvalid_1's l2: 0.370471\n",
      "[500]\ttraining's l2: 0.311825\tvalid_1's l2: 0.37035\n",
      "[550]\ttraining's l2: 0.308886\tvalid_1's l2: 0.370237\n",
      "[600]\ttraining's l2: 0.306164\tvalid_1's l2: 0.370228\n",
      "[650]\ttraining's l2: 0.303559\tvalid_1's l2: 0.370322\n",
      "[700]\ttraining's l2: 0.301085\tvalid_1's l2: 0.370406\n",
      "Early stopping, best iteration is:\n",
      "[584]\ttraining's l2: 0.307005\tvalid_1's l2: 0.370165\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.105552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.426356\tvalid_1's l2: 0.439331\n",
      "[100]\ttraining's l2: 0.350812\tvalid_1's l2: 0.371313\n",
      "[150]\ttraining's l2: 0.334464\tvalid_1's l2: 0.362074\n",
      "[200]\ttraining's l2: 0.325979\tvalid_1's l2: 0.35988\n",
      "[250]\ttraining's l2: 0.319899\tvalid_1's l2: 0.359017\n",
      "[300]\ttraining's l2: 0.315415\tvalid_1's l2: 0.358469\n",
      "[350]\ttraining's l2: 0.31162\tvalid_1's l2: 0.358172\n",
      "[400]\ttraining's l2: 0.308256\tvalid_1's l2: 0.358118\n",
      "[450]\ttraining's l2: 0.305257\tvalid_1's l2: 0.358103\n",
      "[500]\ttraining's l2: 0.302327\tvalid_1's l2: 0.357996\n",
      "[550]\ttraining's l2: 0.2996\tvalid_1's l2: 0.358118\n",
      "[600]\ttraining's l2: 0.297108\tvalid_1's l2: 0.358126\n",
      "Early stopping, best iteration is:\n",
      "[501]\ttraining's l2: 0.302269\tvalid_1's l2: 0.357989\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.103944 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.420186\tvalid_1's l2: 0.427195\n",
      "[100]\ttraining's l2: 0.340818\tvalid_1's l2: 0.356741\n",
      "[150]\ttraining's l2: 0.323886\tvalid_1's l2: 0.34627\n",
      "[200]\ttraining's l2: 0.314538\tvalid_1's l2: 0.343121\n",
      "[250]\ttraining's l2: 0.308346\tvalid_1's l2: 0.342139\n",
      "[300]\ttraining's l2: 0.303917\tvalid_1's l2: 0.341379\n",
      "[350]\ttraining's l2: 0.300054\tvalid_1's l2: 0.340977\n",
      "[400]\ttraining's l2: 0.296775\tvalid_1's l2: 0.340527\n",
      "[450]\ttraining's l2: 0.293984\tvalid_1's l2: 0.34032\n",
      "[500]\ttraining's l2: 0.291194\tvalid_1's l2: 0.340293\n",
      "[550]\ttraining's l2: 0.288636\tvalid_1's l2: 0.340133\n",
      "[600]\ttraining's l2: 0.286171\tvalid_1's l2: 0.340098\n",
      "[650]\ttraining's l2: 0.283864\tvalid_1's l2: 0.339947\n",
      "[700]\ttraining's l2: 0.281658\tvalid_1's l2: 0.33995\n",
      "[750]\ttraining's l2: 0.279538\tvalid_1's l2: 0.340016\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's l2: 0.284395\tvalid_1's l2: 0.339934\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.106983 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.420357\tvalid_1's l2: 0.439241\n",
      "[100]\ttraining's l2: 0.351999\tvalid_1's l2: 0.377927\n",
      "[150]\ttraining's l2: 0.336444\tvalid_1's l2: 0.368982\n",
      "[200]\ttraining's l2: 0.32786\tvalid_1's l2: 0.366847\n",
      "[250]\ttraining's l2: 0.321401\tvalid_1's l2: 0.365844\n",
      "[300]\ttraining's l2: 0.316865\tvalid_1's l2: 0.365447\n",
      "[350]\ttraining's l2: 0.313092\tvalid_1's l2: 0.365075\n",
      "[400]\ttraining's l2: 0.309663\tvalid_1's l2: 0.364734\n",
      "[450]\ttraining's l2: 0.306617\tvalid_1's l2: 0.364671\n",
      "[500]\ttraining's l2: 0.303732\tvalid_1's l2: 0.364572\n",
      "[550]\ttraining's l2: 0.300922\tvalid_1's l2: 0.364476\n",
      "[600]\ttraining's l2: 0.298282\tvalid_1's l2: 0.3645\n",
      "[650]\ttraining's l2: 0.295776\tvalid_1's l2: 0.364454\n",
      "[700]\ttraining's l2: 0.293389\tvalid_1's l2: 0.364498\n",
      "[750]\ttraining's l2: 0.29111\tvalid_1's l2: 0.364432\n",
      "[800]\ttraining's l2: 0.288909\tvalid_1's l2: 0.364441\n",
      "[850]\ttraining's l2: 0.286787\tvalid_1's l2: 0.364475\n",
      "[900]\ttraining's l2: 0.284672\tvalid_1's l2: 0.364433\n",
      "[950]\ttraining's l2: 0.282555\tvalid_1's l2: 0.36447\n",
      "[1000]\ttraining's l2: 0.280544\tvalid_1's l2: 0.364505\n",
      "Early stopping, best iteration is:\n",
      "[912]\ttraining's l2: 0.284151\tvalid_1's l2: 0.364424\n",
      "==================================================\n",
      "Training Model No. 6 ...\n",
      "Parameters -->  {'learning_rate': 0.0597784374558757, 'num_leaves': 68, 'min_data_in_leaf': 103, 'feature_fraction': 0.8826605267054559, 'bagging_fraction': 0.6689864653536619, 'bagging_freq': 2}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.109970 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.290692\tvalid_1's l2: 0.293452\n",
      "[100]\ttraining's l2: 0.276144\tvalid_1's l2: 0.287638\n",
      "[150]\ttraining's l2: 0.268733\tvalid_1's l2: 0.286785\n",
      "[200]\ttraining's l2: 0.262761\tvalid_1's l2: 0.286705\n",
      "[250]\ttraining's l2: 0.257403\tvalid_1's l2: 0.286488\n",
      "[300]\ttraining's l2: 0.252434\tvalid_1's l2: 0.286453\n",
      "[350]\ttraining's l2: 0.247831\tvalid_1's l2: 0.286588\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's l2: 0.256136\tvalid_1's l2: 0.286381\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.109474 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.308281\tvalid_1's l2: 0.327111\n",
      "[100]\ttraining's l2: 0.29375\tvalid_1's l2: 0.319656\n",
      "[150]\ttraining's l2: 0.28583\tvalid_1's l2: 0.31856\n",
      "[200]\ttraining's l2: 0.27933\tvalid_1's l2: 0.318321\n",
      "[250]\ttraining's l2: 0.273645\tvalid_1's l2: 0.318243\n",
      "[300]\ttraining's l2: 0.268379\tvalid_1's l2: 0.318219\n",
      "[350]\ttraining's l2: 0.263465\tvalid_1's l2: 0.31834\n",
      "[400]\ttraining's l2: 0.258704\tvalid_1's l2: 0.318312\n",
      "Early stopping, best iteration is:\n",
      "[303]\ttraining's l2: 0.268054\tvalid_1's l2: 0.318197\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.104710 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.309082\tvalid_1's l2: 0.343758\n",
      "[100]\ttraining's l2: 0.292717\tvalid_1's l2: 0.336233\n",
      "[150]\ttraining's l2: 0.284224\tvalid_1's l2: 0.334996\n",
      "[200]\ttraining's l2: 0.277987\tvalid_1's l2: 0.334372\n",
      "[250]\ttraining's l2: 0.272321\tvalid_1's l2: 0.334323\n",
      "[300]\ttraining's l2: 0.267141\tvalid_1's l2: 0.33438\n",
      "[350]\ttraining's l2: 0.262425\tvalid_1's l2: 0.334403\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's l2: 0.274108\tvalid_1's l2: 0.334244\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.108771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.333425\tvalid_1's l2: 0.357844\n",
      "[100]\ttraining's l2: 0.313697\tvalid_1's l2: 0.350461\n",
      "[150]\ttraining's l2: 0.303531\tvalid_1's l2: 0.348379\n",
      "[200]\ttraining's l2: 0.296311\tvalid_1's l2: 0.348145\n",
      "[250]\ttraining's l2: 0.290009\tvalid_1's l2: 0.347924\n",
      "[300]\ttraining's l2: 0.284371\tvalid_1's l2: 0.34773\n",
      "[350]\ttraining's l2: 0.279074\tvalid_1's l2: 0.347566\n",
      "[400]\ttraining's l2: 0.274113\tvalid_1's l2: 0.347635\n",
      "[450]\ttraining's l2: 0.269373\tvalid_1's l2: 0.347756\n",
      "Early stopping, best iteration is:\n",
      "[346]\ttraining's l2: 0.279526\tvalid_1's l2: 0.347511\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.114558 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.343267\tvalid_1's l2: 0.361483\n",
      "[100]\ttraining's l2: 0.319388\tvalid_1's l2: 0.351356\n",
      "[150]\ttraining's l2: 0.308179\tvalid_1's l2: 0.348901\n",
      "[200]\ttraining's l2: 0.300332\tvalid_1's l2: 0.348\n",
      "[250]\ttraining's l2: 0.293806\tvalid_1's l2: 0.348359\n",
      "[300]\ttraining's l2: 0.287798\tvalid_1's l2: 0.348551\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's l2: 0.297596\tvalid_1's l2: 0.347964\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.108569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.344283\tvalid_1's l2: 0.363519\n",
      "[100]\ttraining's l2: 0.324953\tvalid_1's l2: 0.354539\n",
      "[150]\ttraining's l2: 0.315157\tvalid_1's l2: 0.352536\n",
      "[200]\ttraining's l2: 0.307708\tvalid_1's l2: 0.352553\n",
      "[250]\ttraining's l2: 0.301154\tvalid_1's l2: 0.35245\n",
      "[300]\ttraining's l2: 0.295236\tvalid_1's l2: 0.352386\n",
      "[350]\ttraining's l2: 0.289693\tvalid_1's l2: 0.352412\n",
      "[400]\ttraining's l2: 0.284478\tvalid_1's l2: 0.352142\n",
      "[450]\ttraining's l2: 0.279602\tvalid_1's l2: 0.352353\n",
      "[500]\ttraining's l2: 0.275095\tvalid_1's l2: 0.352578\n",
      "Early stopping, best iteration is:\n",
      "[401]\ttraining's l2: 0.284369\tvalid_1's l2: 0.352126\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.112128 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.336269\tvalid_1's l2: 0.419474\n",
      "[100]\ttraining's l2: 0.317462\tvalid_1's l2: 0.406612\n",
      "[150]\ttraining's l2: 0.308056\tvalid_1's l2: 0.404163\n",
      "[200]\ttraining's l2: 0.300757\tvalid_1's l2: 0.403821\n",
      "[250]\ttraining's l2: 0.294459\tvalid_1's l2: 0.402853\n",
      "[300]\ttraining's l2: 0.288685\tvalid_1's l2: 0.402659\n",
      "[350]\ttraining's l2: 0.283239\tvalid_1's l2: 0.402179\n",
      "[400]\ttraining's l2: 0.278159\tvalid_1's l2: 0.402145\n",
      "[450]\ttraining's l2: 0.273564\tvalid_1's l2: 0.402149\n",
      "[500]\ttraining's l2: 0.268919\tvalid_1's l2: 0.402355\n",
      "Early stopping, best iteration is:\n",
      "[407]\ttraining's l2: 0.27754\tvalid_1's l2: 0.401999\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.105987 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.320095\tvalid_1's l2: 0.385525\n",
      "[100]\ttraining's l2: 0.301502\tvalid_1's l2: 0.37338\n",
      "[150]\ttraining's l2: 0.292478\tvalid_1's l2: 0.371729\n",
      "[200]\ttraining's l2: 0.285646\tvalid_1's l2: 0.371139\n",
      "[250]\ttraining's l2: 0.279684\tvalid_1's l2: 0.370567\n",
      "[300]\ttraining's l2: 0.274301\tvalid_1's l2: 0.370507\n",
      "[350]\ttraining's l2: 0.26927\tvalid_1's l2: 0.370472\n",
      "[400]\ttraining's l2: 0.264551\tvalid_1's l2: 0.370706\n",
      "Early stopping, best iteration is:\n",
      "[278]\ttraining's l2: 0.276535\tvalid_1's l2: 0.370345\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.106658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.331715\tvalid_1's l2: 0.379675\n",
      "[100]\ttraining's l2: 0.31429\tvalid_1's l2: 0.371942\n",
      "[150]\ttraining's l2: 0.305389\tvalid_1's l2: 0.370863\n",
      "[200]\ttraining's l2: 0.298163\tvalid_1's l2: 0.370692\n",
      "[250]\ttraining's l2: 0.292163\tvalid_1's l2: 0.370698\n",
      "[300]\ttraining's l2: 0.286514\tvalid_1's l2: 0.370497\n",
      "[350]\ttraining's l2: 0.281381\tvalid_1's l2: 0.370248\n",
      "[400]\ttraining's l2: 0.276363\tvalid_1's l2: 0.370367\n",
      "[450]\ttraining's l2: 0.271716\tvalid_1's l2: 0.370051\n",
      "[500]\ttraining's l2: 0.267293\tvalid_1's l2: 0.370286\n",
      "[550]\ttraining's l2: 0.262981\tvalid_1's l2: 0.370447\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttraining's l2: 0.272235\tvalid_1's l2: 0.370026\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.103412 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.332504\tvalid_1's l2: 0.371708\n",
      "[100]\ttraining's l2: 0.31205\tvalid_1's l2: 0.363229\n",
      "[150]\ttraining's l2: 0.302297\tvalid_1's l2: 0.36172\n",
      "[200]\ttraining's l2: 0.295038\tvalid_1's l2: 0.361032\n",
      "[250]\ttraining's l2: 0.288789\tvalid_1's l2: 0.36035\n",
      "[300]\ttraining's l2: 0.283185\tvalid_1's l2: 0.360219\n",
      "[350]\ttraining's l2: 0.278072\tvalid_1's l2: 0.360423\n",
      "[400]\ttraining's l2: 0.273205\tvalid_1's l2: 0.360571\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttraining's l2: 0.28398\tvalid_1's l2: 0.360145\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.109245 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.350803\tvalid_1's l2: 0.37747\n",
      "[100]\ttraining's l2: 0.328413\tvalid_1's l2: 0.369687\n",
      "[150]\ttraining's l2: 0.317309\tvalid_1's l2: 0.367865\n",
      "[200]\ttraining's l2: 0.309249\tvalid_1's l2: 0.367505\n",
      "[250]\ttraining's l2: 0.30267\tvalid_1's l2: 0.367711\n",
      "[300]\ttraining's l2: 0.296515\tvalid_1's l2: 0.367818\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's l2: 0.308781\tvalid_1's l2: 0.367415\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.103485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.3602\tvalid_1's l2: 0.387145\n",
      "[100]\ttraining's l2: 0.333918\tvalid_1's l2: 0.377888\n",
      "[150]\ttraining's l2: 0.321686\tvalid_1's l2: 0.376065\n",
      "[200]\ttraining's l2: 0.312998\tvalid_1's l2: 0.375665\n",
      "[250]\ttraining's l2: 0.305968\tvalid_1's l2: 0.375579\n",
      "[300]\ttraining's l2: 0.29956\tvalid_1's l2: 0.375388\n",
      "[350]\ttraining's l2: 0.293631\tvalid_1's l2: 0.375277\n",
      "[400]\ttraining's l2: 0.28829\tvalid_1's l2: 0.375081\n",
      "[450]\ttraining's l2: 0.283266\tvalid_1's l2: 0.374901\n",
      "[500]\ttraining's l2: 0.278522\tvalid_1's l2: 0.374929\n",
      "[550]\ttraining's l2: 0.273842\tvalid_1's l2: 0.375213\n",
      "Early stopping, best iteration is:\n",
      "[448]\ttraining's l2: 0.283439\tvalid_1's l2: 0.374886\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.113456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.350848\tvalid_1's l2: 0.379058\n",
      "[100]\ttraining's l2: 0.329913\tvalid_1's l2: 0.373538\n",
      "[150]\ttraining's l2: 0.319628\tvalid_1's l2: 0.372616\n",
      "[200]\ttraining's l2: 0.311699\tvalid_1's l2: 0.372518\n",
      "[250]\ttraining's l2: 0.305071\tvalid_1's l2: 0.372652\n",
      "[300]\ttraining's l2: 0.29896\tvalid_1's l2: 0.372631\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's l2: 0.315377\tvalid_1's l2: 0.372366\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.106789 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.339184\tvalid_1's l2: 0.363986\n",
      "[100]\ttraining's l2: 0.319483\tvalid_1's l2: 0.359109\n",
      "[150]\ttraining's l2: 0.309811\tvalid_1's l2: 0.358292\n",
      "[200]\ttraining's l2: 0.30237\tvalid_1's l2: 0.358527\n",
      "[250]\ttraining's l2: 0.296085\tvalid_1's l2: 0.358237\n",
      "[300]\ttraining's l2: 0.290577\tvalid_1's l2: 0.358407\n",
      "[350]\ttraining's l2: 0.285204\tvalid_1's l2: 0.35884\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttraining's l2: 0.294948\tvalid_1's l2: 0.358216\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.105117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.32879\tvalid_1's l2: 0.349616\n",
      "[100]\ttraining's l2: 0.308152\tvalid_1's l2: 0.342592\n",
      "[150]\ttraining's l2: 0.298662\tvalid_1's l2: 0.341291\n",
      "[200]\ttraining's l2: 0.291457\tvalid_1's l2: 0.340978\n",
      "[250]\ttraining's l2: 0.285484\tvalid_1's l2: 0.340676\n",
      "[300]\ttraining's l2: 0.280497\tvalid_1's l2: 0.340682\n",
      "[350]\ttraining's l2: 0.275406\tvalid_1's l2: 0.34075\n",
      "Early stopping, best iteration is:\n",
      "[268]\ttraining's l2: 0.283657\tvalid_1's l2: 0.340582\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.112280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.34124\tvalid_1's l2: 0.371794\n",
      "[100]\ttraining's l2: 0.320987\tvalid_1's l2: 0.365938\n",
      "[150]\ttraining's l2: 0.311397\tvalid_1's l2: 0.365377\n",
      "[200]\ttraining's l2: 0.304145\tvalid_1's l2: 0.365184\n",
      "[250]\ttraining's l2: 0.297904\tvalid_1's l2: 0.365232\n",
      "[300]\ttraining's l2: 0.292115\tvalid_1's l2: 0.365225\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's l2: 0.305243\tvalid_1's l2: 0.365081\n",
      "==================================================\n",
      "Training Model No. 7 ...\n",
      "Parameters -->  {'learning_rate': 0.020520593957823328, 'num_leaves': 59, 'min_data_in_leaf': 148, 'feature_fraction': 0.8049790556476375, 'bagging_fraction': 0.6829989973347863, 'bagging_freq': 3}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.112481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.410371\tvalid_1's l2: 0.399557\n",
      "[100]\ttraining's l2: 0.310421\tvalid_1's l2: 0.308532\n",
      "[150]\ttraining's l2: 0.291664\tvalid_1's l2: 0.294045\n",
      "[200]\ttraining's l2: 0.284803\tvalid_1's l2: 0.290032\n",
      "[250]\ttraining's l2: 0.280437\tvalid_1's l2: 0.288058\n",
      "[300]\ttraining's l2: 0.27752\tvalid_1's l2: 0.287265\n",
      "[350]\ttraining's l2: 0.274904\tvalid_1's l2: 0.2867\n",
      "[400]\ttraining's l2: 0.272701\tvalid_1's l2: 0.286429\n",
      "[450]\ttraining's l2: 0.270632\tvalid_1's l2: 0.286227\n",
      "[500]\ttraining's l2: 0.268753\tvalid_1's l2: 0.286041\n",
      "[550]\ttraining's l2: 0.26693\tvalid_1's l2: 0.285881\n",
      "[600]\ttraining's l2: 0.265231\tvalid_1's l2: 0.285805\n",
      "[650]\ttraining's l2: 0.263576\tvalid_1's l2: 0.28574\n",
      "[700]\ttraining's l2: 0.26196\tvalid_1's l2: 0.285694\n",
      "[750]\ttraining's l2: 0.260382\tvalid_1's l2: 0.285643\n",
      "[800]\ttraining's l2: 0.258855\tvalid_1's l2: 0.28557\n",
      "[850]\ttraining's l2: 0.257344\tvalid_1's l2: 0.285474\n",
      "[900]\ttraining's l2: 0.255914\tvalid_1's l2: 0.285431\n",
      "[950]\ttraining's l2: 0.254503\tvalid_1's l2: 0.285427\n",
      "[1000]\ttraining's l2: 0.253081\tvalid_1's l2: 0.285394\n",
      "[1050]\ttraining's l2: 0.251699\tvalid_1's l2: 0.28543\n",
      "[1100]\ttraining's l2: 0.250327\tvalid_1's l2: 0.285384\n",
      "[1150]\ttraining's l2: 0.249\tvalid_1's l2: 0.285378\n",
      "[1200]\ttraining's l2: 0.247627\tvalid_1's l2: 0.285348\n",
      "[1250]\ttraining's l2: 0.246332\tvalid_1's l2: 0.285296\n",
      "[1300]\ttraining's l2: 0.245061\tvalid_1's l2: 0.285315\n",
      "[1350]\ttraining's l2: 0.243816\tvalid_1's l2: 0.285297\n",
      "[1400]\ttraining's l2: 0.242553\tvalid_1's l2: 0.285276\n",
      "[1450]\ttraining's l2: 0.241374\tvalid_1's l2: 0.285313\n",
      "[1500]\ttraining's l2: 0.240193\tvalid_1's l2: 0.285353\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.240193\tvalid_1's l2: 0.285353\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.115319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.408394\tvalid_1's l2: 0.417914\n",
      "[100]\ttraining's l2: 0.325443\tvalid_1's l2: 0.340272\n",
      "[150]\ttraining's l2: 0.309377\tvalid_1's l2: 0.326654\n",
      "[200]\ttraining's l2: 0.303063\tvalid_1's l2: 0.322439\n",
      "[250]\ttraining's l2: 0.298977\tvalid_1's l2: 0.320492\n",
      "[300]\ttraining's l2: 0.295677\tvalid_1's l2: 0.319244\n",
      "[350]\ttraining's l2: 0.292942\tvalid_1's l2: 0.318569\n",
      "[400]\ttraining's l2: 0.290478\tvalid_1's l2: 0.318104\n",
      "[450]\ttraining's l2: 0.288328\tvalid_1's l2: 0.317848\n",
      "[500]\ttraining's l2: 0.286314\tvalid_1's l2: 0.317582\n",
      "[550]\ttraining's l2: 0.2843\tvalid_1's l2: 0.317435\n",
      "[600]\ttraining's l2: 0.282391\tvalid_1's l2: 0.31718\n",
      "[650]\ttraining's l2: 0.280628\tvalid_1's l2: 0.317005\n",
      "[700]\ttraining's l2: 0.278855\tvalid_1's l2: 0.316826\n",
      "[750]\ttraining's l2: 0.27726\tvalid_1's l2: 0.316791\n",
      "[800]\ttraining's l2: 0.275573\tvalid_1's l2: 0.316781\n",
      "[850]\ttraining's l2: 0.273945\tvalid_1's l2: 0.316734\n",
      "[900]\ttraining's l2: 0.2724\tvalid_1's l2: 0.31664\n",
      "[950]\ttraining's l2: 0.270889\tvalid_1's l2: 0.316579\n",
      "[1000]\ttraining's l2: 0.269429\tvalid_1's l2: 0.316536\n",
      "[1050]\ttraining's l2: 0.267932\tvalid_1's l2: 0.316526\n",
      "[1100]\ttraining's l2: 0.266439\tvalid_1's l2: 0.316529\n",
      "[1150]\ttraining's l2: 0.265021\tvalid_1's l2: 0.316533\n",
      "[1200]\ttraining's l2: 0.263637\tvalid_1's l2: 0.316473\n",
      "[1250]\ttraining's l2: 0.262234\tvalid_1's l2: 0.316466\n",
      "[1300]\ttraining's l2: 0.260842\tvalid_1's l2: 0.316435\n",
      "[1350]\ttraining's l2: 0.259554\tvalid_1's l2: 0.316443\n",
      "[1400]\ttraining's l2: 0.258283\tvalid_1's l2: 0.316426\n",
      "[1450]\ttraining's l2: 0.257002\tvalid_1's l2: 0.31638\n",
      "[1500]\ttraining's l2: 0.255701\tvalid_1's l2: 0.316312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.255701\tvalid_1's l2: 0.316312\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.106115 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.428286\tvalid_1's l2: 0.456263\n",
      "[100]\ttraining's l2: 0.329641\tvalid_1's l2: 0.360469\n",
      "[150]\ttraining's l2: 0.310424\tvalid_1's l2: 0.343503\n",
      "[200]\ttraining's l2: 0.303044\tvalid_1's l2: 0.338858\n",
      "[250]\ttraining's l2: 0.298166\tvalid_1's l2: 0.336863\n",
      "[300]\ttraining's l2: 0.29445\tvalid_1's l2: 0.335768\n",
      "[350]\ttraining's l2: 0.291436\tvalid_1's l2: 0.335\n",
      "[400]\ttraining's l2: 0.289079\tvalid_1's l2: 0.334672\n",
      "[450]\ttraining's l2: 0.286826\tvalid_1's l2: 0.334342\n",
      "[500]\ttraining's l2: 0.284624\tvalid_1's l2: 0.334037\n",
      "[550]\ttraining's l2: 0.282599\tvalid_1's l2: 0.333829\n",
      "[600]\ttraining's l2: 0.280673\tvalid_1's l2: 0.333639\n",
      "[650]\ttraining's l2: 0.278848\tvalid_1's l2: 0.33353\n",
      "[700]\ttraining's l2: 0.277111\tvalid_1's l2: 0.333453\n",
      "[750]\ttraining's l2: 0.275454\tvalid_1's l2: 0.333409\n",
      "[800]\ttraining's l2: 0.273852\tvalid_1's l2: 0.333402\n",
      "[850]\ttraining's l2: 0.272234\tvalid_1's l2: 0.333333\n",
      "[900]\ttraining's l2: 0.270725\tvalid_1's l2: 0.333266\n",
      "[950]\ttraining's l2: 0.2692\tvalid_1's l2: 0.333218\n",
      "[1000]\ttraining's l2: 0.267722\tvalid_1's l2: 0.333215\n",
      "[1050]\ttraining's l2: 0.26625\tvalid_1's l2: 0.333131\n",
      "[1100]\ttraining's l2: 0.264798\tvalid_1's l2: 0.33305\n",
      "[1150]\ttraining's l2: 0.263418\tvalid_1's l2: 0.333051\n",
      "[1200]\ttraining's l2: 0.262026\tvalid_1's l2: 0.333087\n",
      "Early stopping, best iteration is:\n",
      "[1079]\ttraining's l2: 0.265366\tvalid_1's l2: 0.333034\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.125116 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.474952\tvalid_1's l2: 0.473993\n",
      "[100]\ttraining's l2: 0.35869\tvalid_1's l2: 0.373739\n",
      "[150]\ttraining's l2: 0.335233\tvalid_1's l2: 0.357533\n",
      "[200]\ttraining's l2: 0.326115\tvalid_1's l2: 0.353107\n",
      "[250]\ttraining's l2: 0.320302\tvalid_1's l2: 0.351093\n",
      "[300]\ttraining's l2: 0.315717\tvalid_1's l2: 0.349744\n",
      "[350]\ttraining's l2: 0.312004\tvalid_1's l2: 0.348774\n",
      "[400]\ttraining's l2: 0.308996\tvalid_1's l2: 0.348353\n",
      "[450]\ttraining's l2: 0.306299\tvalid_1's l2: 0.347941\n",
      "[500]\ttraining's l2: 0.303822\tvalid_1's l2: 0.347502\n",
      "[550]\ttraining's l2: 0.301492\tvalid_1's l2: 0.347017\n",
      "[600]\ttraining's l2: 0.299397\tvalid_1's l2: 0.346935\n",
      "[650]\ttraining's l2: 0.297383\tvalid_1's l2: 0.346803\n",
      "[700]\ttraining's l2: 0.295451\tvalid_1's l2: 0.346552\n",
      "[750]\ttraining's l2: 0.293649\tvalid_1's l2: 0.346465\n",
      "[800]\ttraining's l2: 0.291889\tvalid_1's l2: 0.346449\n",
      "[850]\ttraining's l2: 0.290117\tvalid_1's l2: 0.346305\n",
      "[900]\ttraining's l2: 0.288445\tvalid_1's l2: 0.346218\n",
      "[950]\ttraining's l2: 0.286809\tvalid_1's l2: 0.346155\n",
      "[1000]\ttraining's l2: 0.285217\tvalid_1's l2: 0.346092\n",
      "[1050]\ttraining's l2: 0.283673\tvalid_1's l2: 0.345991\n",
      "[1100]\ttraining's l2: 0.282154\tvalid_1's l2: 0.346016\n",
      "[1150]\ttraining's l2: 0.280575\tvalid_1's l2: 0.346025\n",
      "Early stopping, best iteration is:\n",
      "[1060]\ttraining's l2: 0.283358\tvalid_1's l2: 0.345969\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.107957 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.496428\tvalid_1's l2: 0.487654\n",
      "[100]\ttraining's l2: 0.370684\tvalid_1's l2: 0.379065\n",
      "[150]\ttraining's l2: 0.344787\tvalid_1's l2: 0.361476\n",
      "[200]\ttraining's l2: 0.334273\tvalid_1's l2: 0.355857\n",
      "[250]\ttraining's l2: 0.327086\tvalid_1's l2: 0.352743\n",
      "[300]\ttraining's l2: 0.321802\tvalid_1's l2: 0.350684\n",
      "[350]\ttraining's l2: 0.3177\tvalid_1's l2: 0.349603\n",
      "[400]\ttraining's l2: 0.314278\tvalid_1's l2: 0.348988\n",
      "[450]\ttraining's l2: 0.311412\tvalid_1's l2: 0.348765\n",
      "[500]\ttraining's l2: 0.308576\tvalid_1's l2: 0.348033\n",
      "[550]\ttraining's l2: 0.306004\tvalid_1's l2: 0.347608\n",
      "[600]\ttraining's l2: 0.303722\tvalid_1's l2: 0.347493\n",
      "[650]\ttraining's l2: 0.30157\tvalid_1's l2: 0.347459\n",
      "[700]\ttraining's l2: 0.29948\tvalid_1's l2: 0.347327\n",
      "[750]\ttraining's l2: 0.29744\tvalid_1's l2: 0.347238\n",
      "[800]\ttraining's l2: 0.295587\tvalid_1's l2: 0.34724\n",
      "[850]\ttraining's l2: 0.293749\tvalid_1's l2: 0.347076\n",
      "[900]\ttraining's l2: 0.29194\tvalid_1's l2: 0.346957\n",
      "[950]\ttraining's l2: 0.290167\tvalid_1's l2: 0.346969\n",
      "[1000]\ttraining's l2: 0.288495\tvalid_1's l2: 0.346993\n",
      "Early stopping, best iteration is:\n",
      "[885]\ttraining's l2: 0.292482\tvalid_1's l2: 0.346936\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.108099 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.465908\tvalid_1's l2: 0.479136\n",
      "[100]\ttraining's l2: 0.366119\tvalid_1's l2: 0.381198\n",
      "[150]\ttraining's l2: 0.345822\tvalid_1's l2: 0.363749\n",
      "[200]\ttraining's l2: 0.337397\tvalid_1's l2: 0.358252\n",
      "[250]\ttraining's l2: 0.331629\tvalid_1's l2: 0.355176\n",
      "[300]\ttraining's l2: 0.327381\tvalid_1's l2: 0.353512\n",
      "[350]\ttraining's l2: 0.324053\tvalid_1's l2: 0.352577\n",
      "[400]\ttraining's l2: 0.321043\tvalid_1's l2: 0.352116\n",
      "[450]\ttraining's l2: 0.318304\tvalid_1's l2: 0.351848\n",
      "[500]\ttraining's l2: 0.315779\tvalid_1's l2: 0.351451\n",
      "[550]\ttraining's l2: 0.31347\tvalid_1's l2: 0.351223\n",
      "[600]\ttraining's l2: 0.311218\tvalid_1's l2: 0.350885\n",
      "[650]\ttraining's l2: 0.309119\tvalid_1's l2: 0.350833\n",
      "[700]\ttraining's l2: 0.3071\tvalid_1's l2: 0.35073\n",
      "[750]\ttraining's l2: 0.305226\tvalid_1's l2: 0.350704\n",
      "[800]\ttraining's l2: 0.303313\tvalid_1's l2: 0.350439\n",
      "[850]\ttraining's l2: 0.301466\tvalid_1's l2: 0.350386\n",
      "[900]\ttraining's l2: 0.299685\tvalid_1's l2: 0.350249\n",
      "[950]\ttraining's l2: 0.297969\tvalid_1's l2: 0.350249\n",
      "[1000]\ttraining's l2: 0.296264\tvalid_1's l2: 0.350289\n",
      "[1050]\ttraining's l2: 0.294613\tvalid_1's l2: 0.350294\n",
      "Early stopping, best iteration is:\n",
      "[958]\ttraining's l2: 0.297674\tvalid_1's l2: 0.350226\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.109600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.452671\tvalid_1's l2: 0.551627\n",
      "[100]\ttraining's l2: 0.357778\tvalid_1's l2: 0.44254\n",
      "[150]\ttraining's l2: 0.338\tvalid_1's l2: 0.419266\n",
      "[200]\ttraining's l2: 0.329521\tvalid_1's l2: 0.411847\n",
      "[250]\ttraining's l2: 0.32367\tvalid_1's l2: 0.408064\n",
      "[300]\ttraining's l2: 0.3197\tvalid_1's l2: 0.406255\n",
      "[350]\ttraining's l2: 0.316223\tvalid_1's l2: 0.404972\n",
      "[400]\ttraining's l2: 0.313319\tvalid_1's l2: 0.40396\n",
      "[450]\ttraining's l2: 0.310752\tvalid_1's l2: 0.40328\n",
      "[500]\ttraining's l2: 0.308415\tvalid_1's l2: 0.402765\n",
      "[550]\ttraining's l2: 0.30619\tvalid_1's l2: 0.402392\n",
      "[600]\ttraining's l2: 0.304094\tvalid_1's l2: 0.402063\n",
      "[650]\ttraining's l2: 0.302007\tvalid_1's l2: 0.401637\n",
      "[700]\ttraining's l2: 0.300006\tvalid_1's l2: 0.401428\n",
      "[750]\ttraining's l2: 0.298204\tvalid_1's l2: 0.401375\n",
      "[800]\ttraining's l2: 0.296374\tvalid_1's l2: 0.40121\n",
      "[850]\ttraining's l2: 0.29458\tvalid_1's l2: 0.40112\n",
      "[900]\ttraining's l2: 0.292835\tvalid_1's l2: 0.401079\n",
      "[950]\ttraining's l2: 0.29117\tvalid_1's l2: 0.401017\n",
      "[1000]\ttraining's l2: 0.289506\tvalid_1's l2: 0.400689\n",
      "[1050]\ttraining's l2: 0.287897\tvalid_1's l2: 0.400664\n",
      "[1100]\ttraining's l2: 0.286342\tvalid_1's l2: 0.40071\n",
      "[1150]\ttraining's l2: 0.284829\tvalid_1's l2: 0.400595\n",
      "[1200]\ttraining's l2: 0.283305\tvalid_1's l2: 0.400612\n",
      "[1250]\ttraining's l2: 0.281783\tvalid_1's l2: 0.400557\n",
      "[1300]\ttraining's l2: 0.280358\tvalid_1's l2: 0.400332\n",
      "[1350]\ttraining's l2: 0.278915\tvalid_1's l2: 0.400326\n",
      "[1400]\ttraining's l2: 0.277454\tvalid_1's l2: 0.400391\n",
      "Early stopping, best iteration is:\n",
      "[1290]\ttraining's l2: 0.280659\tvalid_1's l2: 0.400272\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.105173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.441078\tvalid_1's l2: 0.518281\n",
      "[100]\ttraining's l2: 0.34116\tvalid_1's l2: 0.4077\n",
      "[150]\ttraining's l2: 0.321266\tvalid_1's l2: 0.386042\n",
      "[200]\ttraining's l2: 0.31281\tvalid_1's l2: 0.379101\n",
      "[250]\ttraining's l2: 0.307046\tvalid_1's l2: 0.375229\n",
      "[300]\ttraining's l2: 0.303295\tvalid_1's l2: 0.373451\n",
      "[350]\ttraining's l2: 0.299989\tvalid_1's l2: 0.372482\n",
      "[400]\ttraining's l2: 0.297294\tvalid_1's l2: 0.372016\n",
      "[450]\ttraining's l2: 0.294812\tvalid_1's l2: 0.371553\n",
      "[500]\ttraining's l2: 0.292548\tvalid_1's l2: 0.371406\n",
      "[550]\ttraining's l2: 0.290442\tvalid_1's l2: 0.371108\n",
      "[600]\ttraining's l2: 0.288461\tvalid_1's l2: 0.370805\n",
      "[650]\ttraining's l2: 0.286543\tvalid_1's l2: 0.370375\n",
      "[700]\ttraining's l2: 0.284762\tvalid_1's l2: 0.370241\n",
      "[750]\ttraining's l2: 0.283072\tvalid_1's l2: 0.370017\n",
      "[800]\ttraining's l2: 0.281391\tvalid_1's l2: 0.370061\n",
      "[850]\ttraining's l2: 0.279716\tvalid_1's l2: 0.370029\n",
      "Early stopping, best iteration is:\n",
      "[764]\ttraining's l2: 0.282605\tvalid_1's l2: 0.369971\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.108026 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.434193\tvalid_1's l2: 0.481851\n",
      "[100]\ttraining's l2: 0.350868\tvalid_1's l2: 0.395444\n",
      "[150]\ttraining's l2: 0.333179\tvalid_1's l2: 0.378962\n",
      "[200]\ttraining's l2: 0.325562\tvalid_1's l2: 0.374595\n",
      "[250]\ttraining's l2: 0.320084\tvalid_1's l2: 0.372417\n",
      "[300]\ttraining's l2: 0.3162\tvalid_1's l2: 0.371277\n",
      "[350]\ttraining's l2: 0.31295\tvalid_1's l2: 0.370422\n",
      "[400]\ttraining's l2: 0.310193\tvalid_1's l2: 0.369896\n",
      "[450]\ttraining's l2: 0.307781\tvalid_1's l2: 0.369533\n",
      "[500]\ttraining's l2: 0.305541\tvalid_1's l2: 0.369426\n",
      "[550]\ttraining's l2: 0.303364\tvalid_1's l2: 0.369158\n",
      "[600]\ttraining's l2: 0.301358\tvalid_1's l2: 0.368943\n",
      "[650]\ttraining's l2: 0.299402\tvalid_1's l2: 0.368935\n",
      "[700]\ttraining's l2: 0.2976\tvalid_1's l2: 0.368783\n",
      "[750]\ttraining's l2: 0.295762\tvalid_1's l2: 0.368697\n",
      "[800]\ttraining's l2: 0.293985\tvalid_1's l2: 0.368559\n",
      "[850]\ttraining's l2: 0.292264\tvalid_1's l2: 0.368475\n",
      "[900]\ttraining's l2: 0.290661\tvalid_1's l2: 0.368417\n",
      "[950]\ttraining's l2: 0.289019\tvalid_1's l2: 0.36836\n",
      "[1000]\ttraining's l2: 0.287419\tvalid_1's l2: 0.368347\n",
      "[1050]\ttraining's l2: 0.285876\tvalid_1's l2: 0.368377\n",
      "[1100]\ttraining's l2: 0.284397\tvalid_1's l2: 0.368345\n",
      "[1150]\ttraining's l2: 0.28292\tvalid_1's l2: 0.368221\n",
      "[1200]\ttraining's l2: 0.281378\tvalid_1's l2: 0.368224\n",
      "[1250]\ttraining's l2: 0.27994\tvalid_1's l2: 0.368257\n",
      "Early stopping, best iteration is:\n",
      "[1155]\ttraining's l2: 0.282774\tvalid_1's l2: 0.368202\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.102607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.451819\tvalid_1's l2: 0.486096\n",
      "[100]\ttraining's l2: 0.35518\tvalid_1's l2: 0.389483\n",
      "[150]\ttraining's l2: 0.334185\tvalid_1's l2: 0.371638\n",
      "[200]\ttraining's l2: 0.324894\tvalid_1's l2: 0.366489\n",
      "[250]\ttraining's l2: 0.318708\tvalid_1's l2: 0.364339\n",
      "[300]\ttraining's l2: 0.314206\tvalid_1's l2: 0.362986\n",
      "[350]\ttraining's l2: 0.310695\tvalid_1's l2: 0.362062\n",
      "[400]\ttraining's l2: 0.307613\tvalid_1's l2: 0.361508\n",
      "[450]\ttraining's l2: 0.304838\tvalid_1's l2: 0.360991\n",
      "[500]\ttraining's l2: 0.302427\tvalid_1's l2: 0.360798\n",
      "[550]\ttraining's l2: 0.300213\tvalid_1's l2: 0.360545\n",
      "[600]\ttraining's l2: 0.297996\tvalid_1's l2: 0.360316\n",
      "[650]\ttraining's l2: 0.295935\tvalid_1's l2: 0.359915\n",
      "[700]\ttraining's l2: 0.294073\tvalid_1's l2: 0.359732\n",
      "[750]\ttraining's l2: 0.292204\tvalid_1's l2: 0.35971\n",
      "[800]\ttraining's l2: 0.290409\tvalid_1's l2: 0.359648\n",
      "[850]\ttraining's l2: 0.288699\tvalid_1's l2: 0.3596\n",
      "[900]\ttraining's l2: 0.286993\tvalid_1's l2: 0.359541\n",
      "[950]\ttraining's l2: 0.285378\tvalid_1's l2: 0.359418\n",
      "[1000]\ttraining's l2: 0.283768\tvalid_1's l2: 0.359401\n",
      "[1050]\ttraining's l2: 0.282187\tvalid_1's l2: 0.359357\n",
      "[1100]\ttraining's l2: 0.280677\tvalid_1's l2: 0.35938\n",
      "[1150]\ttraining's l2: 0.279156\tvalid_1's l2: 0.35936\n",
      "Early stopping, best iteration is:\n",
      "[1030]\ttraining's l2: 0.282803\tvalid_1's l2: 0.359309\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.113487 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.481999\tvalid_1's l2: 0.4946\n",
      "[100]\ttraining's l2: 0.375331\tvalid_1's l2: 0.39425\n",
      "[150]\ttraining's l2: 0.352484\tvalid_1's l2: 0.377089\n",
      "[200]\ttraining's l2: 0.342604\tvalid_1's l2: 0.372605\n",
      "[250]\ttraining's l2: 0.335717\tvalid_1's l2: 0.370396\n",
      "[300]\ttraining's l2: 0.330709\tvalid_1's l2: 0.36899\n",
      "[350]\ttraining's l2: 0.326725\tvalid_1's l2: 0.368187\n",
      "[400]\ttraining's l2: 0.323167\tvalid_1's l2: 0.367289\n",
      "[450]\ttraining's l2: 0.320065\tvalid_1's l2: 0.366712\n",
      "[500]\ttraining's l2: 0.317321\tvalid_1's l2: 0.366363\n",
      "[550]\ttraining's l2: 0.314756\tvalid_1's l2: 0.366025\n",
      "[600]\ttraining's l2: 0.312424\tvalid_1's l2: 0.365896\n",
      "[650]\ttraining's l2: 0.310162\tvalid_1's l2: 0.365844\n",
      "[700]\ttraining's l2: 0.308132\tvalid_1's l2: 0.365702\n",
      "[750]\ttraining's l2: 0.306015\tvalid_1's l2: 0.365586\n",
      "[800]\ttraining's l2: 0.304131\tvalid_1's l2: 0.365526\n",
      "[850]\ttraining's l2: 0.302237\tvalid_1's l2: 0.365399\n",
      "[900]\ttraining's l2: 0.30042\tvalid_1's l2: 0.365327\n",
      "[950]\ttraining's l2: 0.298741\tvalid_1's l2: 0.365339\n",
      "[1000]\ttraining's l2: 0.297081\tvalid_1's l2: 0.365315\n",
      "[1050]\ttraining's l2: 0.295423\tvalid_1's l2: 0.365242\n",
      "[1100]\ttraining's l2: 0.293827\tvalid_1's l2: 0.365265\n",
      "[1150]\ttraining's l2: 0.292294\tvalid_1's l2: 0.365262\n",
      "[1200]\ttraining's l2: 0.290749\tvalid_1's l2: 0.365221\n",
      "Early stopping, best iteration is:\n",
      "[1082]\ttraining's l2: 0.294396\tvalid_1's l2: 0.365196\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.105614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.507727\tvalid_1's l2: 0.512308\n",
      "[100]\ttraining's l2: 0.388546\tvalid_1's l2: 0.404979\n",
      "[150]\ttraining's l2: 0.362163\tvalid_1's l2: 0.386612\n",
      "[200]\ttraining's l2: 0.350916\tvalid_1's l2: 0.381585\n",
      "[250]\ttraining's l2: 0.342858\tvalid_1's l2: 0.379173\n",
      "[300]\ttraining's l2: 0.336913\tvalid_1's l2: 0.377455\n",
      "[350]\ttraining's l2: 0.332117\tvalid_1's l2: 0.376348\n",
      "[400]\ttraining's l2: 0.328313\tvalid_1's l2: 0.375651\n",
      "[450]\ttraining's l2: 0.324954\tvalid_1's l2: 0.374983\n",
      "[500]\ttraining's l2: 0.321814\tvalid_1's l2: 0.374493\n",
      "[550]\ttraining's l2: 0.31906\tvalid_1's l2: 0.374197\n",
      "[600]\ttraining's l2: 0.316523\tvalid_1's l2: 0.374022\n",
      "[650]\ttraining's l2: 0.314101\tvalid_1's l2: 0.373634\n",
      "[700]\ttraining's l2: 0.311871\tvalid_1's l2: 0.373523\n",
      "[750]\ttraining's l2: 0.309699\tvalid_1's l2: 0.373448\n",
      "[800]\ttraining's l2: 0.307748\tvalid_1's l2: 0.373337\n",
      "[850]\ttraining's l2: 0.305794\tvalid_1's l2: 0.373262\n",
      "[900]\ttraining's l2: 0.303802\tvalid_1's l2: 0.373128\n",
      "[950]\ttraining's l2: 0.301882\tvalid_1's l2: 0.372939\n",
      "[1000]\ttraining's l2: 0.300159\tvalid_1's l2: 0.372882\n",
      "[1050]\ttraining's l2: 0.298493\tvalid_1's l2: 0.372836\n",
      "[1100]\ttraining's l2: 0.296808\tvalid_1's l2: 0.37278\n",
      "[1150]\ttraining's l2: 0.295197\tvalid_1's l2: 0.372698\n",
      "[1200]\ttraining's l2: 0.293612\tvalid_1's l2: 0.372701\n",
      "[1250]\ttraining's l2: 0.291953\tvalid_1's l2: 0.37261\n",
      "[1300]\ttraining's l2: 0.290387\tvalid_1's l2: 0.372598\n",
      "[1350]\ttraining's l2: 0.288815\tvalid_1's l2: 0.372548\n",
      "[1400]\ttraining's l2: 0.287364\tvalid_1's l2: 0.372511\n",
      "[1450]\ttraining's l2: 0.285937\tvalid_1's l2: 0.372487\n",
      "[1500]\ttraining's l2: 0.284483\tvalid_1's l2: 0.37254\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.284483\tvalid_1's l2: 0.37254\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.113381 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.469576\tvalid_1's l2: 0.4821\n",
      "[100]\ttraining's l2: 0.373717\tvalid_1's l2: 0.393068\n",
      "[150]\ttraining's l2: 0.353049\tvalid_1's l2: 0.378478\n",
      "[200]\ttraining's l2: 0.343792\tvalid_1's l2: 0.374932\n",
      "[250]\ttraining's l2: 0.337437\tvalid_1's l2: 0.373488\n",
      "[300]\ttraining's l2: 0.332784\tvalid_1's l2: 0.372549\n",
      "[350]\ttraining's l2: 0.329038\tvalid_1's l2: 0.371875\n",
      "[400]\ttraining's l2: 0.32577\tvalid_1's l2: 0.371512\n",
      "[450]\ttraining's l2: 0.322927\tvalid_1's l2: 0.371266\n",
      "[500]\ttraining's l2: 0.320303\tvalid_1's l2: 0.371048\n",
      "[550]\ttraining's l2: 0.317885\tvalid_1's l2: 0.37092\n",
      "[600]\ttraining's l2: 0.315609\tvalid_1's l2: 0.370906\n",
      "[650]\ttraining's l2: 0.313351\tvalid_1's l2: 0.370841\n",
      "[700]\ttraining's l2: 0.311271\tvalid_1's l2: 0.370836\n",
      "[750]\ttraining's l2: 0.309241\tvalid_1's l2: 0.370691\n",
      "[800]\ttraining's l2: 0.307273\tvalid_1's l2: 0.37062\n",
      "[850]\ttraining's l2: 0.30542\tvalid_1's l2: 0.370578\n",
      "[900]\ttraining's l2: 0.303617\tvalid_1's l2: 0.370627\n",
      "[950]\ttraining's l2: 0.301889\tvalid_1's l2: 0.370623\n",
      "Early stopping, best iteration is:\n",
      "[854]\ttraining's l2: 0.305288\tvalid_1's l2: 0.370543\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.113353 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.451623\tvalid_1's l2: 0.462244\n",
      "[100]\ttraining's l2: 0.36078\tvalid_1's l2: 0.378161\n",
      "[150]\ttraining's l2: 0.341004\tvalid_1's l2: 0.364429\n",
      "[200]\ttraining's l2: 0.332341\tvalid_1's l2: 0.361219\n",
      "[250]\ttraining's l2: 0.326072\tvalid_1's l2: 0.359434\n",
      "[300]\ttraining's l2: 0.321844\tvalid_1's l2: 0.3588\n",
      "[350]\ttraining's l2: 0.318372\tvalid_1's l2: 0.358417\n",
      "[400]\ttraining's l2: 0.315378\tvalid_1's l2: 0.358259\n",
      "[450]\ttraining's l2: 0.312695\tvalid_1's l2: 0.358104\n",
      "[500]\ttraining's l2: 0.3103\tvalid_1's l2: 0.357973\n",
      "[550]\ttraining's l2: 0.308061\tvalid_1's l2: 0.357864\n",
      "[600]\ttraining's l2: 0.305963\tvalid_1's l2: 0.357767\n",
      "[650]\ttraining's l2: 0.303933\tvalid_1's l2: 0.357769\n",
      "[700]\ttraining's l2: 0.302011\tvalid_1's l2: 0.357747\n",
      "[750]\ttraining's l2: 0.300127\tvalid_1's l2: 0.357722\n",
      "[800]\ttraining's l2: 0.298261\tvalid_1's l2: 0.357665\n",
      "[850]\ttraining's l2: 0.296469\tvalid_1's l2: 0.357651\n",
      "[900]\ttraining's l2: 0.294752\tvalid_1's l2: 0.35758\n",
      "[950]\ttraining's l2: 0.293049\tvalid_1's l2: 0.357602\n",
      "[1000]\ttraining's l2: 0.291429\tvalid_1's l2: 0.357642\n",
      "Early stopping, best iteration is:\n",
      "[897]\ttraining's l2: 0.294844\tvalid_1's l2: 0.357574\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.114350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.447855\tvalid_1's l2: 0.452529\n",
      "[100]\ttraining's l2: 0.351466\tvalid_1's l2: 0.364704\n",
      "[150]\ttraining's l2: 0.33081\tvalid_1's l2: 0.349575\n",
      "[200]\ttraining's l2: 0.32131\tvalid_1's l2: 0.345477\n",
      "[250]\ttraining's l2: 0.314659\tvalid_1's l2: 0.343637\n",
      "[300]\ttraining's l2: 0.31025\tvalid_1's l2: 0.342504\n",
      "[350]\ttraining's l2: 0.306876\tvalid_1's l2: 0.341887\n",
      "[400]\ttraining's l2: 0.303985\tvalid_1's l2: 0.341417\n",
      "[450]\ttraining's l2: 0.301476\tvalid_1's l2: 0.341207\n",
      "[500]\ttraining's l2: 0.299091\tvalid_1's l2: 0.34102\n",
      "[550]\ttraining's l2: 0.296853\tvalid_1's l2: 0.34068\n",
      "[600]\ttraining's l2: 0.294764\tvalid_1's l2: 0.340501\n",
      "[650]\ttraining's l2: 0.292777\tvalid_1's l2: 0.340284\n",
      "[700]\ttraining's l2: 0.290871\tvalid_1's l2: 0.340224\n",
      "[750]\ttraining's l2: 0.289078\tvalid_1's l2: 0.340154\n",
      "[800]\ttraining's l2: 0.287365\tvalid_1's l2: 0.340164\n",
      "[850]\ttraining's l2: 0.285686\tvalid_1's l2: 0.340153\n",
      "Early stopping, best iteration is:\n",
      "[762]\ttraining's l2: 0.288668\tvalid_1's l2: 0.340093\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.114676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.442881\tvalid_1's l2: 0.459741\n",
      "[100]\ttraining's l2: 0.361377\tvalid_1's l2: 0.384652\n",
      "[150]\ttraining's l2: 0.34292\tvalid_1's l2: 0.371676\n",
      "[200]\ttraining's l2: 0.334273\tvalid_1's l2: 0.368561\n",
      "[250]\ttraining's l2: 0.327948\tvalid_1's l2: 0.36695\n",
      "[300]\ttraining's l2: 0.323312\tvalid_1's l2: 0.366114\n",
      "[350]\ttraining's l2: 0.319824\tvalid_1's l2: 0.365531\n",
      "[400]\ttraining's l2: 0.316823\tvalid_1's l2: 0.365244\n",
      "[450]\ttraining's l2: 0.314167\tvalid_1's l2: 0.36493\n",
      "[500]\ttraining's l2: 0.311755\tvalid_1's l2: 0.364742\n",
      "[550]\ttraining's l2: 0.309468\tvalid_1's l2: 0.364518\n",
      "[600]\ttraining's l2: 0.307316\tvalid_1's l2: 0.36442\n",
      "[650]\ttraining's l2: 0.305271\tvalid_1's l2: 0.364278\n",
      "[700]\ttraining's l2: 0.303345\tvalid_1's l2: 0.36427\n",
      "[750]\ttraining's l2: 0.301516\tvalid_1's l2: 0.364189\n",
      "[800]\ttraining's l2: 0.299672\tvalid_1's l2: 0.36417\n",
      "[850]\ttraining's l2: 0.297904\tvalid_1's l2: 0.364105\n",
      "[900]\ttraining's l2: 0.296231\tvalid_1's l2: 0.36403\n",
      "[950]\ttraining's l2: 0.294539\tvalid_1's l2: 0.364042\n",
      "[1000]\ttraining's l2: 0.292938\tvalid_1's l2: 0.364046\n",
      "Early stopping, best iteration is:\n",
      "[912]\ttraining's l2: 0.295806\tvalid_1's l2: 0.363972\n",
      "==================================================\n",
      "Training Model No. 8 ...\n",
      "Parameters -->  {'learning_rate': 0.026436666247864463, 'num_leaves': 66, 'min_data_in_leaf': 136, 'feature_fraction': 0.8266084230952958, 'bagging_fraction': 0.6275467623473735, 'bagging_freq': 1}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.119206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.359477\tvalid_1's l2: 0.352298\n",
      "[100]\ttraining's l2: 0.295507\tvalid_1's l2: 0.296732\n",
      "[150]\ttraining's l2: 0.284349\tvalid_1's l2: 0.290197\n",
      "[200]\ttraining's l2: 0.278588\tvalid_1's l2: 0.287731\n",
      "[250]\ttraining's l2: 0.274747\tvalid_1's l2: 0.286925\n",
      "[300]\ttraining's l2: 0.271519\tvalid_1's l2: 0.286456\n",
      "[350]\ttraining's l2: 0.268677\tvalid_1's l2: 0.286121\n",
      "[400]\ttraining's l2: 0.266086\tvalid_1's l2: 0.286026\n",
      "[450]\ttraining's l2: 0.263585\tvalid_1's l2: 0.285825\n",
      "[500]\ttraining's l2: 0.261235\tvalid_1's l2: 0.285751\n",
      "[550]\ttraining's l2: 0.258963\tvalid_1's l2: 0.285685\n",
      "[600]\ttraining's l2: 0.256817\tvalid_1's l2: 0.285664\n",
      "[650]\ttraining's l2: 0.254734\tvalid_1's l2: 0.285583\n",
      "[700]\ttraining's l2: 0.252663\tvalid_1's l2: 0.285502\n",
      "[750]\ttraining's l2: 0.250652\tvalid_1's l2: 0.285563\n",
      "[800]\ttraining's l2: 0.248756\tvalid_1's l2: 0.285542\n",
      "Early stopping, best iteration is:\n",
      "[699]\ttraining's l2: 0.252705\tvalid_1's l2: 0.285499\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.114701 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.36581\tvalid_1's l2: 0.377585\n",
      "[100]\ttraining's l2: 0.312496\tvalid_1's l2: 0.329367\n",
      "[150]\ttraining's l2: 0.302293\tvalid_1's l2: 0.322285\n",
      "[200]\ttraining's l2: 0.296758\tvalid_1's l2: 0.319805\n",
      "[250]\ttraining's l2: 0.29266\tvalid_1's l2: 0.318578\n",
      "[300]\ttraining's l2: 0.289186\tvalid_1's l2: 0.318102\n",
      "[350]\ttraining's l2: 0.286128\tvalid_1's l2: 0.317685\n",
      "[400]\ttraining's l2: 0.283244\tvalid_1's l2: 0.317379\n",
      "[450]\ttraining's l2: 0.280545\tvalid_1's l2: 0.317091\n",
      "[500]\ttraining's l2: 0.277995\tvalid_1's l2: 0.31706\n",
      "[550]\ttraining's l2: 0.275574\tvalid_1's l2: 0.317016\n",
      "[600]\ttraining's l2: 0.273217\tvalid_1's l2: 0.316927\n",
      "[650]\ttraining's l2: 0.27093\tvalid_1's l2: 0.316831\n",
      "[700]\ttraining's l2: 0.268745\tvalid_1's l2: 0.316788\n",
      "[750]\ttraining's l2: 0.266674\tvalid_1's l2: 0.316819\n",
      "[800]\ttraining's l2: 0.264598\tvalid_1's l2: 0.316787\n",
      "[850]\ttraining's l2: 0.262536\tvalid_1's l2: 0.316756\n",
      "[900]\ttraining's l2: 0.260564\tvalid_1's l2: 0.316721\n",
      "[950]\ttraining's l2: 0.258632\tvalid_1's l2: 0.316684\n",
      "[1000]\ttraining's l2: 0.256701\tvalid_1's l2: 0.31668\n",
      "[1050]\ttraining's l2: 0.254868\tvalid_1's l2: 0.316664\n",
      "[1100]\ttraining's l2: 0.253055\tvalid_1's l2: 0.316645\n",
      "[1150]\ttraining's l2: 0.251256\tvalid_1's l2: 0.316614\n",
      "[1200]\ttraining's l2: 0.249483\tvalid_1's l2: 0.316622\n",
      "[1250]\ttraining's l2: 0.247754\tvalid_1's l2: 0.316675\n",
      "Early stopping, best iteration is:\n",
      "[1145]\ttraining's l2: 0.251423\tvalid_1's l2: 0.316594\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.114612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.377828\tvalid_1's l2: 0.40734\n",
      "[100]\ttraining's l2: 0.314268\tvalid_1's l2: 0.347017\n",
      "[150]\ttraining's l2: 0.30226\tvalid_1's l2: 0.338928\n",
      "[200]\ttraining's l2: 0.295934\tvalid_1's l2: 0.336323\n",
      "[250]\ttraining's l2: 0.291316\tvalid_1's l2: 0.335093\n",
      "[300]\ttraining's l2: 0.287622\tvalid_1's l2: 0.334389\n",
      "[350]\ttraining's l2: 0.284485\tvalid_1's l2: 0.33397\n",
      "[400]\ttraining's l2: 0.281642\tvalid_1's l2: 0.333623\n",
      "[450]\ttraining's l2: 0.279\tvalid_1's l2: 0.333401\n",
      "[500]\ttraining's l2: 0.276441\tvalid_1's l2: 0.333232\n",
      "[550]\ttraining's l2: 0.273991\tvalid_1's l2: 0.333091\n",
      "[600]\ttraining's l2: 0.271663\tvalid_1's l2: 0.332979\n",
      "[650]\ttraining's l2: 0.269395\tvalid_1's l2: 0.332962\n",
      "[700]\ttraining's l2: 0.267223\tvalid_1's l2: 0.33289\n",
      "[750]\ttraining's l2: 0.265057\tvalid_1's l2: 0.332918\n",
      "[800]\ttraining's l2: 0.263077\tvalid_1's l2: 0.332876\n",
      "[850]\ttraining's l2: 0.261062\tvalid_1's l2: 0.332797\n",
      "[900]\ttraining's l2: 0.259084\tvalid_1's l2: 0.332814\n",
      "[950]\ttraining's l2: 0.257227\tvalid_1's l2: 0.332828\n",
      "Early stopping, best iteration is:\n",
      "[852]\ttraining's l2: 0.260974\tvalid_1's l2: 0.332788\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.118223 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.415866\tvalid_1's l2: 0.42211\n",
      "[100]\ttraining's l2: 0.340119\tvalid_1's l2: 0.360696\n",
      "[150]\ttraining's l2: 0.32539\tvalid_1's l2: 0.353015\n",
      "[200]\ttraining's l2: 0.3176\tvalid_1's l2: 0.35037\n",
      "[250]\ttraining's l2: 0.31205\tvalid_1's l2: 0.348926\n",
      "[300]\ttraining's l2: 0.307468\tvalid_1's l2: 0.34806\n",
      "[350]\ttraining's l2: 0.30376\tvalid_1's l2: 0.347317\n",
      "[400]\ttraining's l2: 0.300456\tvalid_1's l2: 0.346961\n",
      "[450]\ttraining's l2: 0.297467\tvalid_1's l2: 0.346602\n",
      "[500]\ttraining's l2: 0.294712\tvalid_1's l2: 0.346554\n",
      "[550]\ttraining's l2: 0.292038\tvalid_1's l2: 0.346531\n",
      "[600]\ttraining's l2: 0.28953\tvalid_1's l2: 0.346488\n",
      "[650]\ttraining's l2: 0.287118\tvalid_1's l2: 0.346483\n",
      "[700]\ttraining's l2: 0.284731\tvalid_1's l2: 0.3464\n",
      "[750]\ttraining's l2: 0.282345\tvalid_1's l2: 0.346308\n",
      "[800]\ttraining's l2: 0.280133\tvalid_1's l2: 0.346286\n",
      "[850]\ttraining's l2: 0.278002\tvalid_1's l2: 0.346272\n",
      "[900]\ttraining's l2: 0.275909\tvalid_1's l2: 0.346177\n",
      "[950]\ttraining's l2: 0.273892\tvalid_1's l2: 0.346223\n",
      "[1000]\ttraining's l2: 0.271949\tvalid_1's l2: 0.346247\n",
      "Early stopping, best iteration is:\n",
      "[904]\ttraining's l2: 0.275727\tvalid_1's l2: 0.346158\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.113116 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.432947\tvalid_1's l2: 0.431542\n",
      "[100]\ttraining's l2: 0.350286\tvalid_1's l2: 0.364779\n",
      "[150]\ttraining's l2: 0.333542\tvalid_1's l2: 0.355861\n",
      "[200]\ttraining's l2: 0.324304\tvalid_1's l2: 0.351955\n",
      "[250]\ttraining's l2: 0.317577\tvalid_1's l2: 0.349691\n",
      "[300]\ttraining's l2: 0.312769\tvalid_1's l2: 0.348964\n",
      "[350]\ttraining's l2: 0.30864\tvalid_1's l2: 0.348428\n",
      "[400]\ttraining's l2: 0.305008\tvalid_1's l2: 0.348093\n",
      "[450]\ttraining's l2: 0.301757\tvalid_1's l2: 0.347959\n",
      "[500]\ttraining's l2: 0.298647\tvalid_1's l2: 0.347712\n",
      "[550]\ttraining's l2: 0.29584\tvalid_1's l2: 0.347664\n",
      "[600]\ttraining's l2: 0.293071\tvalid_1's l2: 0.347507\n",
      "[650]\ttraining's l2: 0.290481\tvalid_1's l2: 0.347292\n",
      "[700]\ttraining's l2: 0.287953\tvalid_1's l2: 0.347226\n",
      "[750]\ttraining's l2: 0.285565\tvalid_1's l2: 0.347291\n",
      "[800]\ttraining's l2: 0.283248\tvalid_1's l2: 0.347275\n",
      "Early stopping, best iteration is:\n",
      "[707]\ttraining's l2: 0.287622\tvalid_1's l2: 0.347203\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.122762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.415191\tvalid_1's l2: 0.429623\n",
      "[100]\ttraining's l2: 0.350022\tvalid_1's l2: 0.366997\n",
      "[150]\ttraining's l2: 0.336793\tvalid_1's l2: 0.357855\n",
      "[200]\ttraining's l2: 0.329058\tvalid_1's l2: 0.354205\n",
      "[250]\ttraining's l2: 0.323798\tvalid_1's l2: 0.352735\n",
      "[300]\ttraining's l2: 0.319638\tvalid_1's l2: 0.351855\n",
      "[350]\ttraining's l2: 0.315871\tvalid_1's l2: 0.351305\n",
      "[400]\ttraining's l2: 0.312525\tvalid_1's l2: 0.351114\n",
      "[450]\ttraining's l2: 0.309394\tvalid_1's l2: 0.350879\n",
      "[500]\ttraining's l2: 0.306474\tvalid_1's l2: 0.350819\n",
      "[550]\ttraining's l2: 0.303687\tvalid_1's l2: 0.350686\n",
      "[600]\ttraining's l2: 0.301027\tvalid_1's l2: 0.35062\n",
      "[650]\ttraining's l2: 0.29854\tvalid_1's l2: 0.35057\n",
      "[700]\ttraining's l2: 0.29602\tvalid_1's l2: 0.350554\n",
      "[750]\ttraining's l2: 0.293676\tvalid_1's l2: 0.350546\n",
      "[800]\ttraining's l2: 0.291303\tvalid_1's l2: 0.350447\n",
      "[850]\ttraining's l2: 0.289082\tvalid_1's l2: 0.35054\n",
      "[900]\ttraining's l2: 0.286891\tvalid_1's l2: 0.350528\n",
      "Early stopping, best iteration is:\n",
      "[788]\ttraining's l2: 0.291831\tvalid_1's l2: 0.350438\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.109848 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.404468\tvalid_1's l2: 0.49842\n",
      "[100]\ttraining's l2: 0.342124\tvalid_1's l2: 0.424516\n",
      "[150]\ttraining's l2: 0.329117\tvalid_1's l2: 0.411474\n",
      "[200]\ttraining's l2: 0.321411\tvalid_1's l2: 0.406716\n",
      "[250]\ttraining's l2: 0.31611\tvalid_1's l2: 0.404529\n",
      "[300]\ttraining's l2: 0.311963\tvalid_1's l2: 0.403433\n",
      "[350]\ttraining's l2: 0.308436\tvalid_1's l2: 0.402585\n",
      "[400]\ttraining's l2: 0.305169\tvalid_1's l2: 0.402027\n",
      "[450]\ttraining's l2: 0.302158\tvalid_1's l2: 0.401482\n",
      "[500]\ttraining's l2: 0.29924\tvalid_1's l2: 0.401072\n",
      "[550]\ttraining's l2: 0.296521\tvalid_1's l2: 0.400846\n",
      "[600]\ttraining's l2: 0.293927\tvalid_1's l2: 0.400497\n",
      "[650]\ttraining's l2: 0.291428\tvalid_1's l2: 0.400314\n",
      "[700]\ttraining's l2: 0.28901\tvalid_1's l2: 0.400009\n",
      "[750]\ttraining's l2: 0.286703\tvalid_1's l2: 0.399847\n",
      "[800]\ttraining's l2: 0.284469\tvalid_1's l2: 0.399628\n",
      "[850]\ttraining's l2: 0.282278\tvalid_1's l2: 0.399549\n",
      "[900]\ttraining's l2: 0.280115\tvalid_1's l2: 0.399397\n",
      "[950]\ttraining's l2: 0.277979\tvalid_1's l2: 0.39947\n",
      "[1000]\ttraining's l2: 0.275899\tvalid_1's l2: 0.399359\n",
      "[1050]\ttraining's l2: 0.273937\tvalid_1's l2: 0.399214\n",
      "[1100]\ttraining's l2: 0.272002\tvalid_1's l2: 0.399258\n",
      "[1150]\ttraining's l2: 0.27003\tvalid_1's l2: 0.399285\n",
      "[1200]\ttraining's l2: 0.268139\tvalid_1's l2: 0.399215\n",
      "[1250]\ttraining's l2: 0.266294\tvalid_1's l2: 0.399241\n",
      "[1300]\ttraining's l2: 0.264479\tvalid_1's l2: 0.399302\n",
      "Early stopping, best iteration is:\n",
      "[1187]\ttraining's l2: 0.268638\tvalid_1's l2: 0.399152\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.109069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.390394\tvalid_1's l2: 0.463668\n",
      "[100]\ttraining's l2: 0.325246\tvalid_1's l2: 0.39052\n",
      "[150]\ttraining's l2: 0.312381\tvalid_1's l2: 0.378833\n",
      "[200]\ttraining's l2: 0.305043\tvalid_1's l2: 0.374231\n",
      "[250]\ttraining's l2: 0.300213\tvalid_1's l2: 0.372305\n",
      "[300]\ttraining's l2: 0.296122\tvalid_1's l2: 0.371365\n",
      "[350]\ttraining's l2: 0.292688\tvalid_1's l2: 0.370815\n",
      "[400]\ttraining's l2: 0.289579\tvalid_1's l2: 0.370395\n",
      "[450]\ttraining's l2: 0.286733\tvalid_1's l2: 0.370242\n",
      "[500]\ttraining's l2: 0.284085\tvalid_1's l2: 0.369977\n",
      "[550]\ttraining's l2: 0.281528\tvalid_1's l2: 0.36996\n",
      "[600]\ttraining's l2: 0.279086\tvalid_1's l2: 0.369855\n",
      "[650]\ttraining's l2: 0.276722\tvalid_1's l2: 0.369817\n",
      "[700]\ttraining's l2: 0.274472\tvalid_1's l2: 0.36966\n",
      "[750]\ttraining's l2: 0.272332\tvalid_1's l2: 0.369603\n",
      "[800]\ttraining's l2: 0.270202\tvalid_1's l2: 0.369544\n",
      "[850]\ttraining's l2: 0.268172\tvalid_1's l2: 0.369474\n",
      "[900]\ttraining's l2: 0.266137\tvalid_1's l2: 0.369476\n",
      "[950]\ttraining's l2: 0.264196\tvalid_1's l2: 0.369446\n",
      "[1000]\ttraining's l2: 0.262299\tvalid_1's l2: 0.369391\n",
      "[1050]\ttraining's l2: 0.260472\tvalid_1's l2: 0.369271\n",
      "[1100]\ttraining's l2: 0.258638\tvalid_1's l2: 0.369217\n",
      "[1150]\ttraining's l2: 0.256829\tvalid_1's l2: 0.369127\n",
      "[1200]\ttraining's l2: 0.2551\tvalid_1's l2: 0.369129\n",
      "[1250]\ttraining's l2: 0.253378\tvalid_1's l2: 0.369041\n",
      "[1300]\ttraining's l2: 0.251712\tvalid_1's l2: 0.368978\n",
      "[1350]\ttraining's l2: 0.250045\tvalid_1's l2: 0.368964\n",
      "[1400]\ttraining's l2: 0.248377\tvalid_1's l2: 0.369018\n",
      "[1450]\ttraining's l2: 0.246732\tvalid_1's l2: 0.368938\n",
      "[1500]\ttraining's l2: 0.245121\tvalid_1's l2: 0.368967\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.245121\tvalid_1's l2: 0.368967\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.109126 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.392079\tvalid_1's l2: 0.438992\n",
      "[100]\ttraining's l2: 0.336763\tvalid_1's l2: 0.382577\n",
      "[150]\ttraining's l2: 0.32475\tvalid_1's l2: 0.374384\n",
      "[200]\ttraining's l2: 0.317595\tvalid_1's l2: 0.371478\n",
      "[250]\ttraining's l2: 0.312756\tvalid_1's l2: 0.370131\n",
      "[300]\ttraining's l2: 0.30883\tvalid_1's l2: 0.369578\n",
      "[350]\ttraining's l2: 0.305473\tvalid_1's l2: 0.36915\n",
      "[400]\ttraining's l2: 0.302324\tvalid_1's l2: 0.36896\n",
      "[450]\ttraining's l2: 0.299372\tvalid_1's l2: 0.368743\n",
      "[500]\ttraining's l2: 0.29664\tvalid_1's l2: 0.368546\n",
      "[550]\ttraining's l2: 0.294022\tvalid_1's l2: 0.368501\n",
      "[600]\ttraining's l2: 0.291479\tvalid_1's l2: 0.368361\n",
      "[650]\ttraining's l2: 0.289062\tvalid_1's l2: 0.368338\n",
      "[700]\ttraining's l2: 0.286769\tvalid_1's l2: 0.368314\n",
      "[750]\ttraining's l2: 0.28447\tvalid_1's l2: 0.36822\n",
      "[800]\ttraining's l2: 0.282328\tvalid_1's l2: 0.36813\n",
      "[850]\ttraining's l2: 0.280202\tvalid_1's l2: 0.368163\n",
      "[900]\ttraining's l2: 0.278126\tvalid_1's l2: 0.368196\n",
      "[950]\ttraining's l2: 0.276105\tvalid_1's l2: 0.368275\n",
      "Early stopping, best iteration is:\n",
      "[863]\ttraining's l2: 0.279669\tvalid_1's l2: 0.368078\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.103249 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.402852\tvalid_1's l2: 0.437426\n",
      "[100]\ttraining's l2: 0.338516\tvalid_1's l2: 0.375343\n",
      "[150]\ttraining's l2: 0.324211\tvalid_1's l2: 0.366299\n",
      "[200]\ttraining's l2: 0.315987\tvalid_1's l2: 0.363803\n",
      "[250]\ttraining's l2: 0.310292\tvalid_1's l2: 0.362469\n",
      "[300]\ttraining's l2: 0.306074\tvalid_1's l2: 0.361913\n",
      "[350]\ttraining's l2: 0.302301\tvalid_1's l2: 0.361448\n",
      "[400]\ttraining's l2: 0.29905\tvalid_1's l2: 0.361041\n",
      "[450]\ttraining's l2: 0.296022\tvalid_1's l2: 0.360712\n",
      "[500]\ttraining's l2: 0.293166\tvalid_1's l2: 0.360582\n",
      "[550]\ttraining's l2: 0.290514\tvalid_1's l2: 0.360499\n",
      "[600]\ttraining's l2: 0.28802\tvalid_1's l2: 0.360421\n",
      "[650]\ttraining's l2: 0.285583\tvalid_1's l2: 0.360286\n",
      "[700]\ttraining's l2: 0.283298\tvalid_1's l2: 0.36022\n",
      "[750]\ttraining's l2: 0.281082\tvalid_1's l2: 0.360155\n",
      "[800]\ttraining's l2: 0.278892\tvalid_1's l2: 0.360099\n",
      "[850]\ttraining's l2: 0.27678\tvalid_1's l2: 0.360161\n",
      "[900]\ttraining's l2: 0.27474\tvalid_1's l2: 0.360133\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's l2: 0.278508\tvalid_1's l2: 0.360046\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.109968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.427891\tvalid_1's l2: 0.443306\n",
      "[100]\ttraining's l2: 0.357423\tvalid_1's l2: 0.380658\n",
      "[150]\ttraining's l2: 0.34191\tvalid_1's l2: 0.37246\n",
      "[200]\ttraining's l2: 0.332976\tvalid_1's l2: 0.370097\n",
      "[250]\ttraining's l2: 0.32669\tvalid_1's l2: 0.368587\n",
      "[300]\ttraining's l2: 0.321591\tvalid_1's l2: 0.367671\n",
      "[350]\ttraining's l2: 0.317457\tvalid_1's l2: 0.367325\n",
      "[400]\ttraining's l2: 0.313786\tvalid_1's l2: 0.366873\n",
      "[450]\ttraining's l2: 0.310523\tvalid_1's l2: 0.366514\n",
      "[500]\ttraining's l2: 0.307469\tvalid_1's l2: 0.366322\n",
      "[550]\ttraining's l2: 0.304634\tvalid_1's l2: 0.366277\n",
      "[600]\ttraining's l2: 0.301908\tvalid_1's l2: 0.366227\n",
      "[650]\ttraining's l2: 0.299344\tvalid_1's l2: 0.36611\n",
      "[700]\ttraining's l2: 0.296873\tvalid_1's l2: 0.366042\n",
      "[750]\ttraining's l2: 0.294448\tvalid_1's l2: 0.366041\n",
      "[800]\ttraining's l2: 0.292083\tvalid_1's l2: 0.366062\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's l2: 0.296409\tvalid_1's l2: 0.366005\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.104363 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.447803\tvalid_1's l2: 0.457266\n",
      "[100]\ttraining's l2: 0.368025\tvalid_1's l2: 0.390366\n",
      "[150]\ttraining's l2: 0.350225\tvalid_1's l2: 0.381622\n",
      "[200]\ttraining's l2: 0.33931\tvalid_1's l2: 0.377946\n",
      "[250]\ttraining's l2: 0.331798\tvalid_1's l2: 0.376139\n",
      "[300]\ttraining's l2: 0.326392\tvalid_1's l2: 0.375094\n",
      "[350]\ttraining's l2: 0.321918\tvalid_1's l2: 0.374472\n",
      "[400]\ttraining's l2: 0.318036\tvalid_1's l2: 0.373938\n",
      "[450]\ttraining's l2: 0.314416\tvalid_1's l2: 0.373772\n",
      "[500]\ttraining's l2: 0.311108\tvalid_1's l2: 0.373704\n",
      "[550]\ttraining's l2: 0.308001\tvalid_1's l2: 0.373566\n",
      "[600]\ttraining's l2: 0.305113\tvalid_1's l2: 0.37332\n",
      "[650]\ttraining's l2: 0.302384\tvalid_1's l2: 0.373262\n",
      "[700]\ttraining's l2: 0.299788\tvalid_1's l2: 0.373137\n",
      "[750]\ttraining's l2: 0.297308\tvalid_1's l2: 0.373097\n",
      "[800]\ttraining's l2: 0.294824\tvalid_1's l2: 0.372958\n",
      "[850]\ttraining's l2: 0.292456\tvalid_1's l2: 0.372994\n",
      "[900]\ttraining's l2: 0.290217\tvalid_1's l2: 0.372986\n",
      "Early stopping, best iteration is:\n",
      "[811]\ttraining's l2: 0.294304\tvalid_1's l2: 0.372928\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.140780 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.421066\tvalid_1's l2: 0.436531\n",
      "[100]\ttraining's l2: 0.357248\tvalid_1's l2: 0.381463\n",
      "[150]\ttraining's l2: 0.343213\tvalid_1's l2: 0.374922\n",
      "[200]\ttraining's l2: 0.334617\tvalid_1's l2: 0.372754\n",
      "[250]\ttraining's l2: 0.328868\tvalid_1's l2: 0.371628\n",
      "[300]\ttraining's l2: 0.3243\tvalid_1's l2: 0.37128\n",
      "[350]\ttraining's l2: 0.320409\tvalid_1's l2: 0.371071\n",
      "[400]\ttraining's l2: 0.316902\tvalid_1's l2: 0.370939\n",
      "[450]\ttraining's l2: 0.313605\tvalid_1's l2: 0.370875\n",
      "[500]\ttraining's l2: 0.310462\tvalid_1's l2: 0.370764\n",
      "[550]\ttraining's l2: 0.307678\tvalid_1's l2: 0.370833\n",
      "[600]\ttraining's l2: 0.304869\tvalid_1's l2: 0.370968\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttraining's l2: 0.31052\tvalid_1's l2: 0.370745\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.106631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.40555\tvalid_1's l2: 0.419369\n",
      "[100]\ttraining's l2: 0.344987\tvalid_1's l2: 0.366977\n",
      "[150]\ttraining's l2: 0.331394\tvalid_1's l2: 0.360853\n",
      "[200]\ttraining's l2: 0.323548\tvalid_1's l2: 0.359222\n",
      "[250]\ttraining's l2: 0.318135\tvalid_1's l2: 0.358661\n",
      "[300]\ttraining's l2: 0.313873\tvalid_1's l2: 0.358208\n",
      "[350]\ttraining's l2: 0.310187\tvalid_1's l2: 0.358001\n",
      "[400]\ttraining's l2: 0.306793\tvalid_1's l2: 0.357891\n",
      "[450]\ttraining's l2: 0.303772\tvalid_1's l2: 0.357736\n",
      "[500]\ttraining's l2: 0.300972\tvalid_1's l2: 0.35771\n",
      "[550]\ttraining's l2: 0.298262\tvalid_1's l2: 0.357695\n",
      "[600]\ttraining's l2: 0.295638\tvalid_1's l2: 0.357877\n",
      "[650]\ttraining's l2: 0.293151\tvalid_1's l2: 0.357855\n",
      "Early stopping, best iteration is:\n",
      "[530]\ttraining's l2: 0.29933\tvalid_1's l2: 0.357651\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.105382 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.399266\tvalid_1's l2: 0.407371\n",
      "[100]\ttraining's l2: 0.33514\tvalid_1's l2: 0.352268\n",
      "[150]\ttraining's l2: 0.320313\tvalid_1's l2: 0.345014\n",
      "[200]\ttraining's l2: 0.312081\tvalid_1's l2: 0.342891\n",
      "[250]\ttraining's l2: 0.306778\tvalid_1's l2: 0.341772\n",
      "[300]\ttraining's l2: 0.302578\tvalid_1's l2: 0.341004\n",
      "[350]\ttraining's l2: 0.298959\tvalid_1's l2: 0.340692\n",
      "[400]\ttraining's l2: 0.295763\tvalid_1's l2: 0.340503\n",
      "[450]\ttraining's l2: 0.292868\tvalid_1's l2: 0.340294\n",
      "[500]\ttraining's l2: 0.29017\tvalid_1's l2: 0.340144\n",
      "[550]\ttraining's l2: 0.287623\tvalid_1's l2: 0.340093\n",
      "[600]\ttraining's l2: 0.285151\tvalid_1's l2: 0.340098\n",
      "[650]\ttraining's l2: 0.282801\tvalid_1's l2: 0.340067\n",
      "[700]\ttraining's l2: 0.280559\tvalid_1's l2: 0.339998\n",
      "[750]\ttraining's l2: 0.278414\tvalid_1's l2: 0.339998\n",
      "[800]\ttraining's l2: 0.276324\tvalid_1's l2: 0.33999\n",
      "[850]\ttraining's l2: 0.274301\tvalid_1's l2: 0.339959\n",
      "[900]\ttraining's l2: 0.272288\tvalid_1's l2: 0.339958\n",
      "[950]\ttraining's l2: 0.2704\tvalid_1's l2: 0.339925\n",
      "[1000]\ttraining's l2: 0.268492\tvalid_1's l2: 0.33981\n",
      "[1050]\ttraining's l2: 0.266669\tvalid_1's l2: 0.339913\n",
      "[1100]\ttraining's l2: 0.264834\tvalid_1's l2: 0.339953\n",
      "Early stopping, best iteration is:\n",
      "[1006]\ttraining's l2: 0.26828\tvalid_1's l2: 0.339803\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.117036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.401734\tvalid_1's l2: 0.421814\n",
      "[100]\ttraining's l2: 0.346822\tvalid_1's l2: 0.374498\n",
      "[150]\ttraining's l2: 0.333596\tvalid_1's l2: 0.368266\n",
      "[200]\ttraining's l2: 0.32527\tvalid_1's l2: 0.366587\n",
      "[250]\ttraining's l2: 0.319586\tvalid_1's l2: 0.365569\n",
      "[300]\ttraining's l2: 0.31537\tvalid_1's l2: 0.364998\n",
      "[350]\ttraining's l2: 0.311702\tvalid_1's l2: 0.364548\n",
      "[400]\ttraining's l2: 0.308422\tvalid_1's l2: 0.364401\n",
      "[450]\ttraining's l2: 0.305399\tvalid_1's l2: 0.364239\n",
      "[500]\ttraining's l2: 0.302476\tvalid_1's l2: 0.364121\n",
      "[550]\ttraining's l2: 0.299786\tvalid_1's l2: 0.364077\n",
      "[600]\ttraining's l2: 0.297258\tvalid_1's l2: 0.36411\n",
      "[650]\ttraining's l2: 0.294825\tvalid_1's l2: 0.364054\n",
      "[700]\ttraining's l2: 0.292456\tvalid_1's l2: 0.364033\n",
      "Early stopping, best iteration is:\n",
      "[575]\ttraining's l2: 0.298511\tvalid_1's l2: 0.364012\n",
      "==================================================\n",
      "Training Model No. 9 ...\n",
      "Parameters -->  {'learning_rate': 0.04986955538553427, 'num_leaves': 51, 'min_data_in_leaf': 268, 'feature_fraction': 0.7349262400109298, 'bagging_fraction': 0.6185450708005444, 'bagging_freq': 3}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.110246 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.301661\tvalid_1's l2: 0.301404\n",
      "[100]\ttraining's l2: 0.28405\tvalid_1's l2: 0.289637\n",
      "[150]\ttraining's l2: 0.278341\tvalid_1's l2: 0.288034\n",
      "[200]\ttraining's l2: 0.273932\tvalid_1's l2: 0.287081\n",
      "[250]\ttraining's l2: 0.27024\tvalid_1's l2: 0.286842\n",
      "[300]\ttraining's l2: 0.267013\tvalid_1's l2: 0.286705\n",
      "[350]\ttraining's l2: 0.263845\tvalid_1's l2: 0.286563\n",
      "[400]\ttraining's l2: 0.260855\tvalid_1's l2: 0.286466\n",
      "[450]\ttraining's l2: 0.258048\tvalid_1's l2: 0.286428\n",
      "[500]\ttraining's l2: 0.255221\tvalid_1's l2: 0.286417\n",
      "[550]\ttraining's l2: 0.252624\tvalid_1's l2: 0.286406\n",
      "[600]\ttraining's l2: 0.25019\tvalid_1's l2: 0.286457\n",
      "Early stopping, best iteration is:\n",
      "[514]\ttraining's l2: 0.254456\tvalid_1's l2: 0.286376\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.108932 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.318468\tvalid_1's l2: 0.333469\n",
      "[100]\ttraining's l2: 0.303001\tvalid_1's l2: 0.322767\n",
      "[150]\ttraining's l2: 0.296613\tvalid_1's l2: 0.320421\n",
      "[200]\ttraining's l2: 0.291916\tvalid_1's l2: 0.319384\n",
      "[250]\ttraining's l2: 0.288002\tvalid_1's l2: 0.31912\n",
      "[300]\ttraining's l2: 0.284339\tvalid_1's l2: 0.318821\n",
      "[350]\ttraining's l2: 0.280989\tvalid_1's l2: 0.318543\n",
      "[400]\ttraining's l2: 0.277726\tvalid_1's l2: 0.318458\n",
      "[450]\ttraining's l2: 0.27477\tvalid_1's l2: 0.318278\n",
      "[500]\ttraining's l2: 0.271759\tvalid_1's l2: 0.318201\n",
      "[550]\ttraining's l2: 0.268849\tvalid_1's l2: 0.318128\n",
      "[600]\ttraining's l2: 0.266082\tvalid_1's l2: 0.318044\n",
      "[650]\ttraining's l2: 0.26356\tvalid_1's l2: 0.318085\n",
      "[700]\ttraining's l2: 0.260988\tvalid_1's l2: 0.318109\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's l2: 0.265336\tvalid_1's l2: 0.318013\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.105678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.321403\tvalid_1's l2: 0.351245\n",
      "[100]\ttraining's l2: 0.302833\tvalid_1's l2: 0.338045\n",
      "[150]\ttraining's l2: 0.295606\tvalid_1's l2: 0.335875\n",
      "[200]\ttraining's l2: 0.290592\tvalid_1's l2: 0.334522\n",
      "[250]\ttraining's l2: 0.286536\tvalid_1's l2: 0.33417\n",
      "[300]\ttraining's l2: 0.282795\tvalid_1's l2: 0.333816\n",
      "[350]\ttraining's l2: 0.279395\tvalid_1's l2: 0.333645\n",
      "[400]\ttraining's l2: 0.276299\tvalid_1's l2: 0.333361\n",
      "[450]\ttraining's l2: 0.27336\tvalid_1's l2: 0.333389\n",
      "[500]\ttraining's l2: 0.27052\tvalid_1's l2: 0.333294\n",
      "[550]\ttraining's l2: 0.267706\tvalid_1's l2: 0.333412\n",
      "[600]\ttraining's l2: 0.265099\tvalid_1's l2: 0.333336\n",
      "Early stopping, best iteration is:\n",
      "[512]\ttraining's l2: 0.269822\tvalid_1's l2: 0.333164\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.108393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.348023\tvalid_1's l2: 0.365104\n",
      "[100]\ttraining's l2: 0.325528\tvalid_1's l2: 0.352925\n",
      "[150]\ttraining's l2: 0.316687\tvalid_1's l2: 0.3504\n",
      "[200]\ttraining's l2: 0.310545\tvalid_1's l2: 0.348888\n",
      "[250]\ttraining's l2: 0.30588\tvalid_1's l2: 0.348208\n",
      "[300]\ttraining's l2: 0.301677\tvalid_1's l2: 0.347966\n",
      "[350]\ttraining's l2: 0.297795\tvalid_1's l2: 0.347516\n",
      "[400]\ttraining's l2: 0.29431\tvalid_1's l2: 0.347512\n",
      "[450]\ttraining's l2: 0.291057\tvalid_1's l2: 0.347513\n",
      "[500]\ttraining's l2: 0.287838\tvalid_1's l2: 0.347452\n",
      "Early stopping, best iteration is:\n",
      "[380]\ttraining's l2: 0.295636\tvalid_1's l2: 0.347445\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.106327 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.35921\tvalid_1's l2: 0.3703\n",
      "[100]\ttraining's l2: 0.332773\tvalid_1's l2: 0.354588\n",
      "[150]\ttraining's l2: 0.322369\tvalid_1's l2: 0.351368\n",
      "[200]\ttraining's l2: 0.315874\tvalid_1's l2: 0.349943\n",
      "[250]\ttraining's l2: 0.310609\tvalid_1's l2: 0.349416\n",
      "[300]\ttraining's l2: 0.306152\tvalid_1's l2: 0.34889\n",
      "[350]\ttraining's l2: 0.302128\tvalid_1's l2: 0.348774\n",
      "[400]\ttraining's l2: 0.298552\tvalid_1's l2: 0.348789\n",
      "[450]\ttraining's l2: 0.295111\tvalid_1's l2: 0.348932\n",
      "[500]\ttraining's l2: 0.29175\tvalid_1's l2: 0.348747\n",
      "[550]\ttraining's l2: 0.288585\tvalid_1's l2: 0.348591\n",
      "[600]\ttraining's l2: 0.285516\tvalid_1's l2: 0.348632\n",
      "Early stopping, best iteration is:\n",
      "[484]\ttraining's l2: 0.292751\tvalid_1's l2: 0.348562\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.107239 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.357434\tvalid_1's l2: 0.371295\n",
      "[100]\ttraining's l2: 0.336718\tvalid_1's l2: 0.356514\n",
      "[150]\ttraining's l2: 0.328286\tvalid_1's l2: 0.353134\n",
      "[200]\ttraining's l2: 0.322598\tvalid_1's l2: 0.35244\n",
      "[250]\ttraining's l2: 0.317836\tvalid_1's l2: 0.352168\n",
      "[300]\ttraining's l2: 0.313419\tvalid_1's l2: 0.3519\n",
      "[350]\ttraining's l2: 0.309456\tvalid_1's l2: 0.35153\n",
      "[400]\ttraining's l2: 0.305898\tvalid_1's l2: 0.351448\n",
      "[450]\ttraining's l2: 0.302421\tvalid_1's l2: 0.351466\n",
      "[500]\ttraining's l2: 0.299182\tvalid_1's l2: 0.351335\n",
      "[550]\ttraining's l2: 0.296033\tvalid_1's l2: 0.351408\n",
      "[600]\ttraining's l2: 0.293067\tvalid_1's l2: 0.351333\n",
      "[650]\ttraining's l2: 0.290183\tvalid_1's l2: 0.351533\n",
      "[700]\ttraining's l2: 0.287308\tvalid_1's l2: 0.351616\n",
      "Early stopping, best iteration is:\n",
      "[599]\ttraining's l2: 0.293121\tvalid_1's l2: 0.351314\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.109045 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.349927\tvalid_1's l2: 0.428546\n",
      "[100]\ttraining's l2: 0.328792\tvalid_1's l2: 0.409241\n",
      "[150]\ttraining's l2: 0.320467\tvalid_1's l2: 0.404812\n",
      "[200]\ttraining's l2: 0.314879\tvalid_1's l2: 0.403574\n",
      "[250]\ttraining's l2: 0.310094\tvalid_1's l2: 0.402569\n",
      "[300]\ttraining's l2: 0.30605\tvalid_1's l2: 0.401656\n",
      "[350]\ttraining's l2: 0.302294\tvalid_1's l2: 0.401442\n",
      "[400]\ttraining's l2: 0.298804\tvalid_1's l2: 0.400946\n",
      "[450]\ttraining's l2: 0.295598\tvalid_1's l2: 0.400758\n",
      "[500]\ttraining's l2: 0.29229\tvalid_1's l2: 0.400711\n",
      "[550]\ttraining's l2: 0.289228\tvalid_1's l2: 0.40052\n",
      "[600]\ttraining's l2: 0.286362\tvalid_1's l2: 0.400411\n",
      "[650]\ttraining's l2: 0.283547\tvalid_1's l2: 0.400313\n",
      "[700]\ttraining's l2: 0.280754\tvalid_1's l2: 0.400707\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's l2: 0.285585\tvalid_1's l2: 0.400138\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.119744 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.333504\tvalid_1's l2: 0.39616\n",
      "[100]\ttraining's l2: 0.312143\tvalid_1's l2: 0.376589\n",
      "[150]\ttraining's l2: 0.304111\tvalid_1's l2: 0.37296\n",
      "[200]\ttraining's l2: 0.298673\tvalid_1's l2: 0.371776\n",
      "[250]\ttraining's l2: 0.294275\tvalid_1's l2: 0.371225\n",
      "[300]\ttraining's l2: 0.29026\tvalid_1's l2: 0.370801\n",
      "[350]\ttraining's l2: 0.286638\tvalid_1's l2: 0.370585\n",
      "[400]\ttraining's l2: 0.283349\tvalid_1's l2: 0.370525\n",
      "[450]\ttraining's l2: 0.280166\tvalid_1's l2: 0.370646\n",
      "[500]\ttraining's l2: 0.277303\tvalid_1's l2: 0.370624\n",
      "Early stopping, best iteration is:\n",
      "[417]\ttraining's l2: 0.282226\tvalid_1's l2: 0.370362\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.106751 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.343881\tvalid_1's l2: 0.386128\n",
      "[100]\ttraining's l2: 0.324986\tvalid_1's l2: 0.372977\n",
      "[150]\ttraining's l2: 0.317233\tvalid_1's l2: 0.370694\n",
      "[200]\ttraining's l2: 0.31178\tvalid_1's l2: 0.369974\n",
      "[250]\ttraining's l2: 0.307441\tvalid_1's l2: 0.36972\n",
      "[300]\ttraining's l2: 0.303481\tvalid_1's l2: 0.369413\n",
      "[350]\ttraining's l2: 0.299878\tvalid_1's l2: 0.369287\n",
      "[400]\ttraining's l2: 0.296488\tvalid_1's l2: 0.369236\n",
      "[450]\ttraining's l2: 0.293078\tvalid_1's l2: 0.369117\n",
      "[500]\ttraining's l2: 0.289958\tvalid_1's l2: 0.369101\n",
      "[550]\ttraining's l2: 0.286974\tvalid_1's l2: 0.368962\n",
      "[600]\ttraining's l2: 0.284133\tvalid_1's l2: 0.368882\n",
      "[650]\ttraining's l2: 0.281298\tvalid_1's l2: 0.368963\n",
      "[700]\ttraining's l2: 0.278647\tvalid_1's l2: 0.369062\n",
      "Early stopping, best iteration is:\n",
      "[606]\ttraining's l2: 0.283785\tvalid_1's l2: 0.36877\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.101688 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.346956\tvalid_1's l2: 0.379671\n",
      "[100]\ttraining's l2: 0.323878\tvalid_1's l2: 0.365974\n",
      "[150]\ttraining's l2: 0.314584\tvalid_1's l2: 0.362762\n",
      "[200]\ttraining's l2: 0.308781\tvalid_1's l2: 0.361817\n",
      "[250]\ttraining's l2: 0.304035\tvalid_1's l2: 0.361301\n",
      "[300]\ttraining's l2: 0.299867\tvalid_1's l2: 0.360962\n",
      "[350]\ttraining's l2: 0.296127\tvalid_1's l2: 0.360748\n",
      "[400]\ttraining's l2: 0.292608\tvalid_1's l2: 0.360531\n",
      "[450]\ttraining's l2: 0.289377\tvalid_1's l2: 0.360573\n",
      "[500]\ttraining's l2: 0.286306\tvalid_1's l2: 0.360658\n",
      "[550]\ttraining's l2: 0.283275\tvalid_1's l2: 0.360559\n",
      "Early stopping, best iteration is:\n",
      "[427]\ttraining's l2: 0.290841\tvalid_1's l2: 0.360378\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.111800 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.365707\tvalid_1's l2: 0.384154\n",
      "[100]\ttraining's l2: 0.341938\tvalid_1's l2: 0.371855\n",
      "[150]\ttraining's l2: 0.331623\tvalid_1's l2: 0.36917\n",
      "[200]\ttraining's l2: 0.324723\tvalid_1's l2: 0.36813\n",
      "[250]\ttraining's l2: 0.31933\tvalid_1's l2: 0.367748\n",
      "[300]\ttraining's l2: 0.31478\tvalid_1's l2: 0.367512\n",
      "[350]\ttraining's l2: 0.310655\tvalid_1's l2: 0.367298\n",
      "[400]\ttraining's l2: 0.306928\tvalid_1's l2: 0.367213\n",
      "[450]\ttraining's l2: 0.303407\tvalid_1's l2: 0.36722\n",
      "[500]\ttraining's l2: 0.300109\tvalid_1's l2: 0.367289\n",
      "[550]\ttraining's l2: 0.296984\tvalid_1's l2: 0.367288\n",
      "Early stopping, best iteration is:\n",
      "[441]\ttraining's l2: 0.303981\tvalid_1's l2: 0.367176\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.104150 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.377634\tvalid_1's l2: 0.394416\n",
      "[100]\ttraining's l2: 0.349491\tvalid_1's l2: 0.380148\n",
      "[150]\ttraining's l2: 0.337503\tvalid_1's l2: 0.3772\n",
      "[200]\ttraining's l2: 0.329918\tvalid_1's l2: 0.37603\n",
      "[250]\ttraining's l2: 0.324102\tvalid_1's l2: 0.375732\n",
      "[300]\ttraining's l2: 0.319158\tvalid_1's l2: 0.375244\n",
      "[350]\ttraining's l2: 0.314613\tvalid_1's l2: 0.37492\n",
      "[400]\ttraining's l2: 0.310625\tvalid_1's l2: 0.375025\n",
      "[450]\ttraining's l2: 0.306928\tvalid_1's l2: 0.374705\n",
      "[500]\ttraining's l2: 0.303286\tvalid_1's l2: 0.374593\n",
      "[550]\ttraining's l2: 0.299989\tvalid_1's l2: 0.374501\n",
      "[600]\ttraining's l2: 0.29691\tvalid_1's l2: 0.374467\n",
      "[650]\ttraining's l2: 0.293905\tvalid_1's l2: 0.374585\n",
      "[700]\ttraining's l2: 0.291039\tvalid_1's l2: 0.374626\n",
      "Early stopping, best iteration is:\n",
      "[604]\ttraining's l2: 0.296649\tvalid_1's l2: 0.374465\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.107251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.365593\tvalid_1's l2: 0.384157\n",
      "[100]\ttraining's l2: 0.343086\tvalid_1's l2: 0.374443\n",
      "[150]\ttraining's l2: 0.334087\tvalid_1's l2: 0.372806\n",
      "[200]\ttraining's l2: 0.327852\tvalid_1's l2: 0.372442\n",
      "[250]\ttraining's l2: 0.322656\tvalid_1's l2: 0.372257\n",
      "[300]\ttraining's l2: 0.318344\tvalid_1's l2: 0.372186\n",
      "[350]\ttraining's l2: 0.314107\tvalid_1's l2: 0.371934\n",
      "[400]\ttraining's l2: 0.31029\tvalid_1's l2: 0.371891\n",
      "[450]\ttraining's l2: 0.306786\tvalid_1's l2: 0.371966\n",
      "[500]\ttraining's l2: 0.303503\tvalid_1's l2: 0.371917\n",
      "[550]\ttraining's l2: 0.300242\tvalid_1's l2: 0.372096\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttraining's l2: 0.308481\tvalid_1's l2: 0.371793\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.104819 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.353603\tvalid_1's l2: 0.370436\n",
      "[100]\ttraining's l2: 0.331468\tvalid_1's l2: 0.361386\n",
      "[150]\ttraining's l2: 0.323182\tvalid_1's l2: 0.359778\n",
      "[200]\ttraining's l2: 0.317143\tvalid_1's l2: 0.359741\n",
      "[250]\ttraining's l2: 0.31236\tvalid_1's l2: 0.359567\n",
      "[300]\ttraining's l2: 0.308243\tvalid_1's l2: 0.359375\n",
      "[350]\ttraining's l2: 0.304443\tvalid_1's l2: 0.359337\n",
      "[400]\ttraining's l2: 0.300777\tvalid_1's l2: 0.359466\n",
      "[450]\ttraining's l2: 0.297437\tvalid_1's l2: 0.359626\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttraining's l2: 0.305005\tvalid_1's l2: 0.359265\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.102856 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.343939\tvalid_1's l2: 0.356583\n",
      "[100]\ttraining's l2: 0.319915\tvalid_1's l2: 0.344032\n",
      "[150]\ttraining's l2: 0.311318\tvalid_1's l2: 0.341753\n",
      "[200]\ttraining's l2: 0.305397\tvalid_1's l2: 0.341122\n",
      "[250]\ttraining's l2: 0.30047\tvalid_1's l2: 0.340487\n",
      "[300]\ttraining's l2: 0.296584\tvalid_1's l2: 0.340328\n",
      "[350]\ttraining's l2: 0.292987\tvalid_1's l2: 0.340147\n",
      "[400]\ttraining's l2: 0.289693\tvalid_1's l2: 0.340079\n",
      "[450]\ttraining's l2: 0.286604\tvalid_1's l2: 0.340131\n",
      "[500]\ttraining's l2: 0.283562\tvalid_1's l2: 0.340102\n",
      "[550]\ttraining's l2: 0.280694\tvalid_1's l2: 0.340209\n",
      "Early stopping, best iteration is:\n",
      "[464]\ttraining's l2: 0.285734\tvalid_1's l2: 0.340049\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.108489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.354123\tvalid_1's l2: 0.377238\n",
      "[100]\ttraining's l2: 0.333412\tvalid_1's l2: 0.367659\n",
      "[150]\ttraining's l2: 0.324552\tvalid_1's l2: 0.36575\n",
      "[200]\ttraining's l2: 0.318335\tvalid_1's l2: 0.365289\n",
      "[250]\ttraining's l2: 0.31349\tvalid_1's l2: 0.365143\n",
      "[300]\ttraining's l2: 0.309233\tvalid_1's l2: 0.364949\n",
      "[350]\ttraining's l2: 0.305398\tvalid_1's l2: 0.365125\n",
      "[400]\ttraining's l2: 0.301815\tvalid_1's l2: 0.365087\n",
      "Early stopping, best iteration is:\n",
      "[291]\ttraining's l2: 0.309955\tvalid_1's l2: 0.364889\n",
      "==================================================\n",
      "Training Model No. 10 ...\n",
      "Parameters -->  {'learning_rate': 0.02849138138132066, 'num_leaves': 50, 'min_data_in_leaf': 300, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 3}\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61309\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.112176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039999\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.352856\tvalid_1's l2: 0.345973\n",
      "[100]\ttraining's l2: 0.296789\tvalid_1's l2: 0.29748\n",
      "[150]\ttraining's l2: 0.286348\tvalid_1's l2: 0.290352\n",
      "[200]\ttraining's l2: 0.281338\tvalid_1's l2: 0.287774\n",
      "[250]\ttraining's l2: 0.278104\tvalid_1's l2: 0.286762\n",
      "[300]\ttraining's l2: 0.275539\tvalid_1's l2: 0.286299\n",
      "[350]\ttraining's l2: 0.273264\tvalid_1's l2: 0.285929\n",
      "[400]\ttraining's l2: 0.271121\tvalid_1's l2: 0.2857\n",
      "[450]\ttraining's l2: 0.269127\tvalid_1's l2: 0.285558\n",
      "[500]\ttraining's l2: 0.267254\tvalid_1's l2: 0.285408\n",
      "[550]\ttraining's l2: 0.26544\tvalid_1's l2: 0.285216\n",
      "[600]\ttraining's l2: 0.26372\tvalid_1's l2: 0.285092\n",
      "[650]\ttraining's l2: 0.262026\tvalid_1's l2: 0.285059\n",
      "[700]\ttraining's l2: 0.260457\tvalid_1's l2: 0.284977\n",
      "[750]\ttraining's l2: 0.258903\tvalid_1's l2: 0.284975\n",
      "[800]\ttraining's l2: 0.257364\tvalid_1's l2: 0.284944\n",
      "[850]\ttraining's l2: 0.255858\tvalid_1's l2: 0.284892\n",
      "[900]\ttraining's l2: 0.254458\tvalid_1's l2: 0.284888\n",
      "[950]\ttraining's l2: 0.253\tvalid_1's l2: 0.28487\n",
      "[1000]\ttraining's l2: 0.251549\tvalid_1's l2: 0.284848\n",
      "[1050]\ttraining's l2: 0.250201\tvalid_1's l2: 0.284876\n",
      "[1100]\ttraining's l2: 0.248836\tvalid_1's l2: 0.284872\n",
      "Early stopping, best iteration is:\n",
      "[991]\ttraining's l2: 0.251803\tvalid_1's l2: 0.284831\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61029\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (85.63 MB) transferred to GPU in 0.117524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.965855\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.359762\tvalid_1's l2: 0.371259\n",
      "[100]\ttraining's l2: 0.314196\tvalid_1's l2: 0.329702\n",
      "[150]\ttraining's l2: 0.305593\tvalid_1's l2: 0.323431\n",
      "[200]\ttraining's l2: 0.300811\tvalid_1's l2: 0.320848\n",
      "[250]\ttraining's l2: 0.297162\tvalid_1's l2: 0.319403\n",
      "[300]\ttraining's l2: 0.294313\tvalid_1's l2: 0.318823\n",
      "[350]\ttraining's l2: 0.291854\tvalid_1's l2: 0.318493\n",
      "[400]\ttraining's l2: 0.289487\tvalid_1's l2: 0.318035\n",
      "[450]\ttraining's l2: 0.287326\tvalid_1's l2: 0.317743\n",
      "[500]\ttraining's l2: 0.285181\tvalid_1's l2: 0.317494\n",
      "[550]\ttraining's l2: 0.283216\tvalid_1's l2: 0.317296\n",
      "[600]\ttraining's l2: 0.281375\tvalid_1's l2: 0.317085\n",
      "[650]\ttraining's l2: 0.279589\tvalid_1's l2: 0.31698\n",
      "[700]\ttraining's l2: 0.277812\tvalid_1's l2: 0.316895\n",
      "[750]\ttraining's l2: 0.276175\tvalid_1's l2: 0.316834\n",
      "[800]\ttraining's l2: 0.274494\tvalid_1's l2: 0.316867\n",
      "[850]\ttraining's l2: 0.272877\tvalid_1's l2: 0.316882\n",
      "[900]\ttraining's l2: 0.271323\tvalid_1's l2: 0.316787\n",
      "[950]\ttraining's l2: 0.26978\tvalid_1's l2: 0.316713\n",
      "[1000]\ttraining's l2: 0.268272\tvalid_1's l2: 0.316687\n",
      "[1050]\ttraining's l2: 0.266731\tvalid_1's l2: 0.316683\n",
      "[1100]\ttraining's l2: 0.265243\tvalid_1's l2: 0.316725\n",
      "Early stopping, best iteration is:\n",
      "[981]\ttraining's l2: 0.268832\tvalid_1's l2: 0.31665\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60174\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (83.07 MB) transferred to GPU in 0.104276 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.053484\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.37218\tvalid_1's l2: 0.400161\n",
      "[100]\ttraining's l2: 0.315747\tvalid_1's l2: 0.346122\n",
      "[150]\ttraining's l2: 0.305257\tvalid_1's l2: 0.338673\n",
      "[200]\ttraining's l2: 0.299482\tvalid_1's l2: 0.336201\n",
      "[250]\ttraining's l2: 0.29575\tvalid_1's l2: 0.335138\n",
      "[300]\ttraining's l2: 0.292695\tvalid_1's l2: 0.334448\n",
      "[350]\ttraining's l2: 0.290007\tvalid_1's l2: 0.333929\n",
      "[400]\ttraining's l2: 0.287659\tvalid_1's l2: 0.333609\n",
      "[450]\ttraining's l2: 0.28541\tvalid_1's l2: 0.333369\n",
      "[500]\ttraining's l2: 0.283325\tvalid_1's l2: 0.333234\n",
      "[550]\ttraining's l2: 0.281337\tvalid_1's l2: 0.333086\n",
      "[600]\ttraining's l2: 0.279523\tvalid_1's l2: 0.332961\n",
      "[650]\ttraining's l2: 0.277724\tvalid_1's l2: 0.332926\n",
      "[700]\ttraining's l2: 0.275968\tvalid_1's l2: 0.332882\n",
      "[750]\ttraining's l2: 0.274326\tvalid_1's l2: 0.332784\n",
      "[800]\ttraining's l2: 0.272703\tvalid_1's l2: 0.332814\n",
      "[850]\ttraining's l2: 0.271178\tvalid_1's l2: 0.33273\n",
      "[900]\ttraining's l2: 0.269634\tvalid_1's l2: 0.332615\n",
      "[950]\ttraining's l2: 0.268075\tvalid_1's l2: 0.332559\n",
      "[1000]\ttraining's l2: 0.266606\tvalid_1's l2: 0.332535\n",
      "[1050]\ttraining's l2: 0.265156\tvalid_1's l2: 0.332516\n",
      "[1100]\ttraining's l2: 0.263706\tvalid_1's l2: 0.332504\n",
      "[1150]\ttraining's l2: 0.262333\tvalid_1's l2: 0.332497\n",
      "[1200]\ttraining's l2: 0.261015\tvalid_1's l2: 0.332451\n",
      "[1250]\ttraining's l2: 0.259688\tvalid_1's l2: 0.332438\n",
      "[1300]\ttraining's l2: 0.258371\tvalid_1's l2: 0.332483\n",
      "[1350]\ttraining's l2: 0.257059\tvalid_1's l2: 0.332445\n",
      "Early stopping, best iteration is:\n",
      "[1229]\ttraining's l2: 0.260248\tvalid_1's l2: 0.332427\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60102\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.107412 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.272343\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.408098\tvalid_1's l2: 0.414165\n",
      "[100]\ttraining's l2: 0.341579\tvalid_1's l2: 0.360245\n",
      "[150]\ttraining's l2: 0.329136\tvalid_1's l2: 0.353917\n",
      "[200]\ttraining's l2: 0.32218\tvalid_1's l2: 0.351241\n",
      "[250]\ttraining's l2: 0.317231\tvalid_1's l2: 0.349802\n",
      "[300]\ttraining's l2: 0.313355\tvalid_1's l2: 0.349054\n",
      "[350]\ttraining's l2: 0.310068\tvalid_1's l2: 0.348215\n",
      "[400]\ttraining's l2: 0.307318\tvalid_1's l2: 0.347762\n",
      "[450]\ttraining's l2: 0.304777\tvalid_1's l2: 0.347474\n",
      "[500]\ttraining's l2: 0.30238\tvalid_1's l2: 0.347199\n",
      "[550]\ttraining's l2: 0.300161\tvalid_1's l2: 0.346952\n",
      "[600]\ttraining's l2: 0.298105\tvalid_1's l2: 0.346752\n",
      "[650]\ttraining's l2: 0.296107\tvalid_1's l2: 0.346592\n",
      "[700]\ttraining's l2: 0.294228\tvalid_1's l2: 0.346469\n",
      "[750]\ttraining's l2: 0.292429\tvalid_1's l2: 0.346387\n",
      "[800]\ttraining's l2: 0.290561\tvalid_1's l2: 0.346217\n",
      "[850]\ttraining's l2: 0.288816\tvalid_1's l2: 0.346072\n",
      "[900]\ttraining's l2: 0.287114\tvalid_1's l2: 0.346015\n",
      "[950]\ttraining's l2: 0.285481\tvalid_1's l2: 0.345933\n",
      "[1000]\ttraining's l2: 0.283871\tvalid_1's l2: 0.345936\n",
      "[1050]\ttraining's l2: 0.28224\tvalid_1's l2: 0.345816\n",
      "[1100]\ttraining's l2: 0.280644\tvalid_1's l2: 0.34587\n",
      "[1150]\ttraining's l2: 0.279071\tvalid_1's l2: 0.345821\n",
      "[1200]\ttraining's l2: 0.277497\tvalid_1's l2: 0.345759\n",
      "[1250]\ttraining's l2: 0.276032\tvalid_1's l2: 0.345818\n",
      "Early stopping, best iteration is:\n",
      "[1169]\ttraining's l2: 0.278477\tvalid_1's l2: 0.345705\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61659\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (83.07 MB) transferred to GPU in 0.106499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.302156\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.423719\tvalid_1's l2: 0.422022\n",
      "[100]\ttraining's l2: 0.351965\tvalid_1's l2: 0.364665\n",
      "[150]\ttraining's l2: 0.337544\tvalid_1's l2: 0.35681\n",
      "[200]\ttraining's l2: 0.328899\tvalid_1's l2: 0.352311\n",
      "[250]\ttraining's l2: 0.323135\tvalid_1's l2: 0.350291\n",
      "[300]\ttraining's l2: 0.318826\tvalid_1's l2: 0.349191\n",
      "[350]\ttraining's l2: 0.315319\tvalid_1's l2: 0.34846\n",
      "[400]\ttraining's l2: 0.312147\tvalid_1's l2: 0.347762\n",
      "[450]\ttraining's l2: 0.309409\tvalid_1's l2: 0.347551\n",
      "[500]\ttraining's l2: 0.306851\tvalid_1's l2: 0.347327\n",
      "[550]\ttraining's l2: 0.304472\tvalid_1's l2: 0.347018\n",
      "[600]\ttraining's l2: 0.302222\tvalid_1's l2: 0.346787\n",
      "[650]\ttraining's l2: 0.300061\tvalid_1's l2: 0.346673\n",
      "[700]\ttraining's l2: 0.298042\tvalid_1's l2: 0.346607\n",
      "[750]\ttraining's l2: 0.296072\tvalid_1's l2: 0.346495\n",
      "[800]\ttraining's l2: 0.294232\tvalid_1's l2: 0.346432\n",
      "[850]\ttraining's l2: 0.292427\tvalid_1's l2: 0.346355\n",
      "[900]\ttraining's l2: 0.29062\tvalid_1's l2: 0.346265\n",
      "[950]\ttraining's l2: 0.288891\tvalid_1's l2: 0.346202\n",
      "[1000]\ttraining's l2: 0.28717\tvalid_1's l2: 0.346127\n",
      "[1050]\ttraining's l2: 0.285504\tvalid_1's l2: 0.346091\n",
      "[1100]\ttraining's l2: 0.283838\tvalid_1's l2: 0.346077\n",
      "[1150]\ttraining's l2: 0.282234\tvalid_1's l2: 0.346075\n",
      "Early stopping, best iteration is:\n",
      "[1060]\ttraining's l2: 0.285136\tvalid_1's l2: 0.346\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62243\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (84.35 MB) transferred to GPU in 0.107066 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.104509\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.409214\tvalid_1's l2: 0.421885\n",
      "[100]\ttraining's l2: 0.352018\tvalid_1's l2: 0.366516\n",
      "[150]\ttraining's l2: 0.340591\tvalid_1's l2: 0.358369\n",
      "[200]\ttraining's l2: 0.333602\tvalid_1's l2: 0.354307\n",
      "[250]\ttraining's l2: 0.329194\tvalid_1's l2: 0.353119\n",
      "[300]\ttraining's l2: 0.325644\tvalid_1's l2: 0.352485\n",
      "[350]\ttraining's l2: 0.322458\tvalid_1's l2: 0.352093\n",
      "[400]\ttraining's l2: 0.319564\tvalid_1's l2: 0.351579\n",
      "[450]\ttraining's l2: 0.317042\tvalid_1's l2: 0.351177\n",
      "[500]\ttraining's l2: 0.31466\tvalid_1's l2: 0.350943\n",
      "[550]\ttraining's l2: 0.312358\tvalid_1's l2: 0.350653\n",
      "[600]\ttraining's l2: 0.31016\tvalid_1's l2: 0.350445\n",
      "[650]\ttraining's l2: 0.308175\tvalid_1's l2: 0.350431\n",
      "[700]\ttraining's l2: 0.306189\tvalid_1's l2: 0.350428\n",
      "[750]\ttraining's l2: 0.304291\tvalid_1's l2: 0.35028\n",
      "[800]\ttraining's l2: 0.302482\tvalid_1's l2: 0.350208\n",
      "[850]\ttraining's l2: 0.300645\tvalid_1's l2: 0.350244\n",
      "[900]\ttraining's l2: 0.298914\tvalid_1's l2: 0.350225\n",
      "[950]\ttraining's l2: 0.297072\tvalid_1's l2: 0.350175\n",
      "[1000]\ttraining's l2: 0.295386\tvalid_1's l2: 0.350258\n",
      "[1050]\ttraining's l2: 0.29367\tvalid_1's l2: 0.350273\n",
      "Early stopping, best iteration is:\n",
      "[946]\ttraining's l2: 0.297208\tvalid_1's l2: 0.35015\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61552\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 267 dense feature groups (85.63 MB) transferred to GPU in 0.110048 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.048491\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.399599\tvalid_1's l2: 0.487959\n",
      "[100]\ttraining's l2: 0.343853\tvalid_1's l2: 0.422053\n",
      "[150]\ttraining's l2: 0.332211\tvalid_1's l2: 0.411082\n",
      "[200]\ttraining's l2: 0.325486\tvalid_1's l2: 0.40704\n",
      "[250]\ttraining's l2: 0.32104\tvalid_1's l2: 0.404792\n",
      "[300]\ttraining's l2: 0.317587\tvalid_1's l2: 0.403475\n",
      "[350]\ttraining's l2: 0.314542\tvalid_1's l2: 0.402527\n",
      "[400]\ttraining's l2: 0.311864\tvalid_1's l2: 0.401694\n",
      "[450]\ttraining's l2: 0.309394\tvalid_1's l2: 0.401149\n",
      "[500]\ttraining's l2: 0.307096\tvalid_1's l2: 0.400671\n",
      "[550]\ttraining's l2: 0.304894\tvalid_1's l2: 0.400412\n",
      "[600]\ttraining's l2: 0.30279\tvalid_1's l2: 0.400328\n",
      "[650]\ttraining's l2: 0.300809\tvalid_1's l2: 0.400057\n",
      "[700]\ttraining's l2: 0.29888\tvalid_1's l2: 0.399885\n",
      "[750]\ttraining's l2: 0.297019\tvalid_1's l2: 0.399968\n",
      "[800]\ttraining's l2: 0.295228\tvalid_1's l2: 0.399733\n",
      "[850]\ttraining's l2: 0.293399\tvalid_1's l2: 0.39972\n",
      "[900]\ttraining's l2: 0.291669\tvalid_1's l2: 0.399571\n",
      "[950]\ttraining's l2: 0.290034\tvalid_1's l2: 0.399392\n",
      "[1000]\ttraining's l2: 0.288371\tvalid_1's l2: 0.399299\n",
      "[1050]\ttraining's l2: 0.286764\tvalid_1's l2: 0.399138\n",
      "[1100]\ttraining's l2: 0.285165\tvalid_1's l2: 0.399131\n",
      "[1150]\ttraining's l2: 0.283607\tvalid_1's l2: 0.399059\n",
      "[1200]\ttraining's l2: 0.282034\tvalid_1's l2: 0.399007\n",
      "[1250]\ttraining's l2: 0.280505\tvalid_1's l2: 0.398999\n",
      "[1300]\ttraining's l2: 0.279042\tvalid_1's l2: 0.398914\n",
      "[1350]\ttraining's l2: 0.277576\tvalid_1's l2: 0.398899\n",
      "[1400]\ttraining's l2: 0.276045\tvalid_1's l2: 0.398949\n",
      "[1450]\ttraining's l2: 0.274615\tvalid_1's l2: 0.398916\n",
      "Early stopping, best iteration is:\n",
      "[1327]\ttraining's l2: 0.278225\tvalid_1's l2: 0.398827\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 57851\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (81.79 MB) transferred to GPU in 0.105520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.043414\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.386148\tvalid_1's l2: 0.455133\n",
      "[100]\ttraining's l2: 0.32705\tvalid_1's l2: 0.389716\n",
      "[150]\ttraining's l2: 0.315319\tvalid_1's l2: 0.378802\n",
      "[200]\ttraining's l2: 0.309001\tvalid_1's l2: 0.375043\n",
      "[250]\ttraining's l2: 0.304694\tvalid_1's l2: 0.373186\n",
      "[300]\ttraining's l2: 0.30129\tvalid_1's l2: 0.372386\n",
      "[350]\ttraining's l2: 0.298338\tvalid_1's l2: 0.371824\n",
      "[400]\ttraining's l2: 0.29569\tvalid_1's l2: 0.371485\n",
      "[450]\ttraining's l2: 0.293376\tvalid_1's l2: 0.371248\n",
      "[500]\ttraining's l2: 0.291183\tvalid_1's l2: 0.371018\n",
      "[550]\ttraining's l2: 0.289036\tvalid_1's l2: 0.37066\n",
      "[600]\ttraining's l2: 0.287107\tvalid_1's l2: 0.370484\n",
      "[650]\ttraining's l2: 0.28522\tvalid_1's l2: 0.370177\n",
      "[700]\ttraining's l2: 0.283377\tvalid_1's l2: 0.370139\n",
      "[750]\ttraining's l2: 0.281619\tvalid_1's l2: 0.370077\n",
      "[800]\ttraining's l2: 0.279924\tvalid_1's l2: 0.369856\n",
      "[850]\ttraining's l2: 0.278233\tvalid_1's l2: 0.36982\n",
      "[900]\ttraining's l2: 0.276619\tvalid_1's l2: 0.369802\n",
      "[950]\ttraining's l2: 0.275024\tvalid_1's l2: 0.369637\n",
      "[1000]\ttraining's l2: 0.273496\tvalid_1's l2: 0.369478\n",
      "[1050]\ttraining's l2: 0.272045\tvalid_1's l2: 0.369477\n",
      "[1100]\ttraining's l2: 0.270557\tvalid_1's l2: 0.369538\n",
      "[1150]\ttraining's l2: 0.269082\tvalid_1's l2: 0.369628\n",
      "Early stopping, best iteration is:\n",
      "[1074]\ttraining's l2: 0.271345\tvalid_1's l2: 0.369444\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60885\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (84.35 MB) transferred to GPU in 0.110938 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.956082\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.388646\tvalid_1's l2: 0.431403\n",
      "[100]\ttraining's l2: 0.339261\tvalid_1's l2: 0.382049\n",
      "[150]\ttraining's l2: 0.328242\tvalid_1's l2: 0.374431\n",
      "[200]\ttraining's l2: 0.321773\tvalid_1's l2: 0.372161\n",
      "[250]\ttraining's l2: 0.317643\tvalid_1's l2: 0.370923\n",
      "[300]\ttraining's l2: 0.314401\tvalid_1's l2: 0.370134\n",
      "[350]\ttraining's l2: 0.311595\tvalid_1's l2: 0.369665\n",
      "[400]\ttraining's l2: 0.309036\tvalid_1's l2: 0.369248\n",
      "[450]\ttraining's l2: 0.306718\tvalid_1's l2: 0.368925\n",
      "[500]\ttraining's l2: 0.304404\tvalid_1's l2: 0.36877\n",
      "[550]\ttraining's l2: 0.302296\tvalid_1's l2: 0.368648\n",
      "[600]\ttraining's l2: 0.300289\tvalid_1's l2: 0.368514\n",
      "[650]\ttraining's l2: 0.298328\tvalid_1's l2: 0.368544\n",
      "[700]\ttraining's l2: 0.296471\tvalid_1's l2: 0.368545\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's l2: 0.299696\tvalid_1's l2: 0.368472\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59823\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (80.52 MB) transferred to GPU in 0.102350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.031055\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.398239\tvalid_1's l2: 0.430276\n",
      "[100]\ttraining's l2: 0.341491\tvalid_1's l2: 0.375027\n",
      "[150]\ttraining's l2: 0.327881\tvalid_1's l2: 0.366427\n",
      "[200]\ttraining's l2: 0.320193\tvalid_1's l2: 0.36379\n",
      "[250]\ttraining's l2: 0.315363\tvalid_1's l2: 0.362324\n",
      "[300]\ttraining's l2: 0.311615\tvalid_1's l2: 0.361467\n",
      "[350]\ttraining's l2: 0.308333\tvalid_1's l2: 0.360779\n",
      "[400]\ttraining's l2: 0.305538\tvalid_1's l2: 0.36044\n",
      "[450]\ttraining's l2: 0.302999\tvalid_1's l2: 0.360062\n",
      "[500]\ttraining's l2: 0.300681\tvalid_1's l2: 0.360009\n",
      "[550]\ttraining's l2: 0.298445\tvalid_1's l2: 0.359821\n",
      "[600]\ttraining's l2: 0.296385\tvalid_1's l2: 0.359725\n",
      "[650]\ttraining's l2: 0.294397\tvalid_1's l2: 0.359671\n",
      "[700]\ttraining's l2: 0.292478\tvalid_1's l2: 0.359483\n",
      "[750]\ttraining's l2: 0.290664\tvalid_1's l2: 0.359458\n",
      "[800]\ttraining's l2: 0.288934\tvalid_1's l2: 0.359352\n",
      "[850]\ttraining's l2: 0.287219\tvalid_1's l2: 0.359297\n",
      "[900]\ttraining's l2: 0.285566\tvalid_1's l2: 0.359316\n",
      "[950]\ttraining's l2: 0.283965\tvalid_1's l2: 0.359311\n",
      "Early stopping, best iteration is:\n",
      "[853]\ttraining's l2: 0.287125\tvalid_1's l2: 0.359266\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62069\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 269 dense feature groups (86.91 MB) transferred to GPU in 0.117337 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.190869\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.42146\tvalid_1's l2: 0.434621\n",
      "[100]\ttraining's l2: 0.359915\tvalid_1's l2: 0.380132\n",
      "[150]\ttraining's l2: 0.346199\tvalid_1's l2: 0.372667\n",
      "[200]\ttraining's l2: 0.337908\tvalid_1's l2: 0.370018\n",
      "[250]\ttraining's l2: 0.33233\tvalid_1's l2: 0.368601\n",
      "[300]\ttraining's l2: 0.327899\tvalid_1's l2: 0.367694\n",
      "[350]\ttraining's l2: 0.324201\tvalid_1's l2: 0.36717\n",
      "[400]\ttraining's l2: 0.321042\tvalid_1's l2: 0.366684\n",
      "[450]\ttraining's l2: 0.31818\tvalid_1's l2: 0.366521\n",
      "[500]\ttraining's l2: 0.315602\tvalid_1's l2: 0.366237\n",
      "[550]\ttraining's l2: 0.313201\tvalid_1's l2: 0.365965\n",
      "[600]\ttraining's l2: 0.310929\tvalid_1's l2: 0.365837\n",
      "[650]\ttraining's l2: 0.308792\tvalid_1's l2: 0.36573\n",
      "[700]\ttraining's l2: 0.306837\tvalid_1's l2: 0.365523\n",
      "[750]\ttraining's l2: 0.304829\tvalid_1's l2: 0.365413\n",
      "[800]\ttraining's l2: 0.302925\tvalid_1's l2: 0.365391\n",
      "[850]\ttraining's l2: 0.301087\tvalid_1's l2: 0.365311\n",
      "[900]\ttraining's l2: 0.299308\tvalid_1's l2: 0.365221\n",
      "[950]\ttraining's l2: 0.29762\tvalid_1's l2: 0.36526\n",
      "[1000]\ttraining's l2: 0.295865\tvalid_1's l2: 0.365284\n",
      "Early stopping, best iteration is:\n",
      "[902]\ttraining's l2: 0.299241\tvalid_1's l2: 0.365215\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60763\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (80.52 MB) transferred to GPU in 0.111455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.237895\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.440812\tvalid_1's l2: 0.448876\n",
      "[100]\ttraining's l2: 0.370165\tvalid_1's l2: 0.38997\n",
      "[150]\ttraining's l2: 0.354264\tvalid_1's l2: 0.38215\n",
      "[200]\ttraining's l2: 0.34444\tvalid_1's l2: 0.378881\n",
      "[250]\ttraining's l2: 0.338166\tvalid_1's l2: 0.377429\n",
      "[300]\ttraining's l2: 0.33331\tvalid_1's l2: 0.37634\n",
      "[350]\ttraining's l2: 0.329134\tvalid_1's l2: 0.375507\n",
      "[400]\ttraining's l2: 0.325672\tvalid_1's l2: 0.375234\n",
      "[450]\ttraining's l2: 0.32261\tvalid_1's l2: 0.374908\n",
      "[500]\ttraining's l2: 0.319741\tvalid_1's l2: 0.374642\n",
      "[550]\ttraining's l2: 0.317059\tvalid_1's l2: 0.374406\n",
      "[600]\ttraining's l2: 0.314675\tvalid_1's l2: 0.374274\n",
      "[650]\ttraining's l2: 0.312364\tvalid_1's l2: 0.374005\n",
      "[700]\ttraining's l2: 0.310177\tvalid_1's l2: 0.373847\n",
      "[750]\ttraining's l2: 0.308031\tvalid_1's l2: 0.373714\n",
      "[800]\ttraining's l2: 0.305987\tvalid_1's l2: 0.37374\n",
      "[850]\ttraining's l2: 0.304029\tvalid_1's l2: 0.373712\n",
      "[900]\ttraining's l2: 0.302142\tvalid_1's l2: 0.373547\n",
      "[950]\ttraining's l2: 0.300241\tvalid_1's l2: 0.373483\n",
      "[1000]\ttraining's l2: 0.298488\tvalid_1's l2: 0.373422\n",
      "[1050]\ttraining's l2: 0.29675\tvalid_1's l2: 0.373382\n",
      "[1100]\ttraining's l2: 0.295055\tvalid_1's l2: 0.373356\n",
      "[1150]\ttraining's l2: 0.293468\tvalid_1's l2: 0.373354\n",
      "[1200]\ttraining's l2: 0.291838\tvalid_1's l2: 0.373279\n",
      "[1250]\ttraining's l2: 0.290237\tvalid_1's l2: 0.373217\n",
      "[1300]\ttraining's l2: 0.288652\tvalid_1's l2: 0.373233\n",
      "[1350]\ttraining's l2: 0.287073\tvalid_1's l2: 0.373186\n",
      "[1400]\ttraining's l2: 0.285544\tvalid_1's l2: 0.373162\n",
      "[1450]\ttraining's l2: 0.28409\tvalid_1's l2: 0.373113\n",
      "[1500]\ttraining's l2: 0.282596\tvalid_1's l2: 0.373063\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1500]\ttraining's l2: 0.282596\tvalid_1's l2: 0.373063\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62722\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 265 dense feature groups (85.63 MB) transferred to GPU in 0.107252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057702\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.416242\tvalid_1's l2: 0.429015\n",
      "[100]\ttraining's l2: 0.359684\tvalid_1's l2: 0.380807\n",
      "[150]\ttraining's l2: 0.346991\tvalid_1's l2: 0.375151\n",
      "[200]\ttraining's l2: 0.339497\tvalid_1's l2: 0.3731\n",
      "[250]\ttraining's l2: 0.334768\tvalid_1's l2: 0.37229\n",
      "[300]\ttraining's l2: 0.3308\tvalid_1's l2: 0.371784\n",
      "[350]\ttraining's l2: 0.327471\tvalid_1's l2: 0.371411\n",
      "[400]\ttraining's l2: 0.324462\tvalid_1's l2: 0.371307\n",
      "[450]\ttraining's l2: 0.321682\tvalid_1's l2: 0.371202\n",
      "[500]\ttraining's l2: 0.319148\tvalid_1's l2: 0.371026\n",
      "[550]\ttraining's l2: 0.316706\tvalid_1's l2: 0.370963\n",
      "[600]\ttraining's l2: 0.314415\tvalid_1's l2: 0.370944\n",
      "[650]\ttraining's l2: 0.312174\tvalid_1's l2: 0.370987\n",
      "[700]\ttraining's l2: 0.310061\tvalid_1's l2: 0.371039\n",
      "[750]\ttraining's l2: 0.308058\tvalid_1's l2: 0.370917\n",
      "[800]\ttraining's l2: 0.306135\tvalid_1's l2: 0.370893\n",
      "[850]\ttraining's l2: 0.304242\tvalid_1's l2: 0.370861\n",
      "[900]\ttraining's l2: 0.30242\tvalid_1's l2: 0.370744\n",
      "[950]\ttraining's l2: 0.300608\tvalid_1's l2: 0.370718\n",
      "[1000]\ttraining's l2: 0.298899\tvalid_1's l2: 0.370773\n",
      "[1050]\ttraining's l2: 0.297214\tvalid_1's l2: 0.370754\n",
      "Early stopping, best iteration is:\n",
      "[958]\ttraining's l2: 0.300335\tvalid_1's l2: 0.370711\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 253 dense feature groups (81.79 MB) transferred to GPU in 0.104771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.000112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.401696\tvalid_1's l2: 0.412611\n",
      "[100]\ttraining's l2: 0.347562\tvalid_1's l2: 0.366596\n",
      "[150]\ttraining's l2: 0.335461\tvalid_1's l2: 0.361262\n",
      "[200]\ttraining's l2: 0.328218\tvalid_1's l2: 0.359201\n",
      "[250]\ttraining's l2: 0.323586\tvalid_1's l2: 0.358414\n",
      "[300]\ttraining's l2: 0.319848\tvalid_1's l2: 0.357935\n",
      "[350]\ttraining's l2: 0.316767\tvalid_1's l2: 0.357847\n",
      "[400]\ttraining's l2: 0.314054\tvalid_1's l2: 0.357627\n",
      "[450]\ttraining's l2: 0.311497\tvalid_1's l2: 0.357374\n",
      "[500]\ttraining's l2: 0.30915\tvalid_1's l2: 0.357239\n",
      "[550]\ttraining's l2: 0.306966\tvalid_1's l2: 0.357246\n",
      "[600]\ttraining's l2: 0.30483\tvalid_1's l2: 0.357286\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttraining's l2: 0.308663\tvalid_1's l2: 0.357172\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59538\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (80.52 MB) transferred to GPU in 0.105250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.005805\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.395172\tvalid_1's l2: 0.401119\n",
      "[100]\ttraining's l2: 0.337663\tvalid_1's l2: 0.352043\n",
      "[150]\ttraining's l2: 0.324302\tvalid_1's l2: 0.345209\n",
      "[200]\ttraining's l2: 0.316859\tvalid_1's l2: 0.342921\n",
      "[250]\ttraining's l2: 0.312079\tvalid_1's l2: 0.34192\n",
      "[300]\ttraining's l2: 0.308286\tvalid_1's l2: 0.341265\n",
      "[350]\ttraining's l2: 0.305155\tvalid_1's l2: 0.340866\n",
      "[400]\ttraining's l2: 0.302365\tvalid_1's l2: 0.340513\n",
      "[450]\ttraining's l2: 0.299923\tvalid_1's l2: 0.340298\n",
      "[500]\ttraining's l2: 0.297648\tvalid_1's l2: 0.34016\n",
      "[550]\ttraining's l2: 0.295554\tvalid_1's l2: 0.340033\n",
      "[600]\ttraining's l2: 0.293508\tvalid_1's l2: 0.339846\n",
      "[650]\ttraining's l2: 0.29164\tvalid_1's l2: 0.339643\n",
      "[700]\ttraining's l2: 0.289845\tvalid_1's l2: 0.339662\n",
      "[750]\ttraining's l2: 0.28807\tvalid_1's l2: 0.339661\n",
      "[800]\ttraining's l2: 0.286378\tvalid_1's l2: 0.33962\n",
      "[850]\ttraining's l2: 0.284773\tvalid_1's l2: 0.339597\n",
      "[900]\ttraining's l2: 0.283187\tvalid_1's l2: 0.339548\n",
      "[950]\ttraining's l2: 0.281619\tvalid_1's l2: 0.33956\n",
      "[1000]\ttraining's l2: 0.280139\tvalid_1's l2: 0.339584\n",
      "Early stopping, best iteration is:\n",
      "[901]\ttraining's l2: 0.283155\tvalid_1's l2: 0.339544\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61588\n",
      "[LightGBM] [Info] Number of data points in the train set: 335030, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (84.35 MB) transferred to GPU in 0.106216 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.944954\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.397321\tvalid_1's l2: 0.4151\n",
      "[100]\ttraining's l2: 0.34928\tvalid_1's l2: 0.373986\n",
      "[150]\ttraining's l2: 0.337358\tvalid_1's l2: 0.368549\n",
      "[200]\ttraining's l2: 0.329801\tvalid_1's l2: 0.367038\n",
      "[250]\ttraining's l2: 0.325099\tvalid_1's l2: 0.365888\n",
      "[300]\ttraining's l2: 0.321209\tvalid_1's l2: 0.365319\n",
      "[350]\ttraining's l2: 0.318002\tvalid_1's l2: 0.365003\n",
      "[400]\ttraining's l2: 0.315212\tvalid_1's l2: 0.364743\n",
      "[450]\ttraining's l2: 0.312722\tvalid_1's l2: 0.36461\n",
      "[500]\ttraining's l2: 0.310321\tvalid_1's l2: 0.36452\n",
      "[550]\ttraining's l2: 0.308047\tvalid_1's l2: 0.364516\n",
      "[600]\ttraining's l2: 0.306003\tvalid_1's l2: 0.364474\n",
      "[650]\ttraining's l2: 0.304006\tvalid_1's l2: 0.364412\n",
      "[700]\ttraining's l2: 0.302088\tvalid_1's l2: 0.364414\n",
      "[750]\ttraining's l2: 0.300295\tvalid_1's l2: 0.364329\n",
      "[800]\ttraining's l2: 0.298539\tvalid_1's l2: 0.364253\n",
      "[850]\ttraining's l2: 0.296787\tvalid_1's l2: 0.364249\n",
      "[900]\ttraining's l2: 0.295074\tvalid_1's l2: 0.364135\n",
      "[950]\ttraining's l2: 0.293393\tvalid_1's l2: 0.364215\n",
      "[1000]\ttraining's l2: 0.291756\tvalid_1's l2: 0.364245\n",
      "Early stopping, best iteration is:\n",
      "[897]\ttraining's l2: 0.295178\tvalid_1's l2: 0.364114\n",
      "CPU times: user 9h 21min 15s, sys: 1h 26min 4s, total: 10h 47min 20s\n",
      "Wall time: 6h 8min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# defining space for searching optimal parameters\n",
    "space = [\n",
    "  \n",
    "    Real(0.02, 0.1,\"log-uniform\", name=\"learning_rate\"),\n",
    "    Integer(50, 90, name=\"num_leaves\"),\n",
    "    Integer(100, 300, name=\"min_data_in_leaf\"),\n",
    "    Real(0.6, 0.9, name=\"feature_fraction\"),\n",
    "    Real(0.5, 0.8, name=\"bagging_fraction\"),\n",
    "    Integer(1, 3, name=\"bagging_freq\"),\n",
    "    ]\n",
    "\n",
    "# Using medium no. of trees (i.e. 1500) to maintain balance between model performance and time complexity.\n",
    "boost_rounds = 1500\n",
    "\n",
    "\n",
    "count=0\n",
    "model_hyper_params = ['learning_rate', 'num_leaves', 'min_data_in_leaf', \n",
    "                           'feature_fraction','bagging_fraction', 'bagging_freq']\n",
    "                           \n",
    "# Objective function which will return nwrmsle .\n",
    "objective_function = partial(return_model_assessment,\n",
    "                             X_train=X_train, y_train=y_train, X_val = X_val,y_val= y_val ,\n",
    "                             model='lgb', n_days=2, items=items , \n",
    "                             features= filtered_features,num_boost_rounds= boost_rounds)\n",
    "\n",
    "\n",
    "# Running the algorithm\n",
    "n_calls = 10 # number of times to train model\n",
    "results = gp_minimize(objective_function, space, base_estimator=None, n_calls=n_calls, n_random_starts=n_calls-1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "gYw_bamdKXtT",
    "outputId": "5cfe4bb6-d4de-4c7a-c223-e1d4c906e8d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "- learning_rate=0.020756\n",
      "- num_leaves=71\n",
      "- min_data_in_leaf=180\n",
      "- feature_fraction=0.614000\n",
      "- bagging_fraction=0.792127\n",
      "- bagging_freq=1 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\"\"Best parameters:\n",
    "- learning_rate=%.6f\n",
    "- num_leaves=%d\n",
    "- min_data_in_leaf=%d\n",
    "- feature_fraction=%.6f\n",
    "- bagging_fraction=%.6f\n",
    "- bagging_freq=%d \"\"\" % (results.x[0], results.x[1],\n",
    "                            results.x[2], results.x[3],\n",
    "                            results.x[4],results.x[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxUu-ePsxezn",
    "outputId": "841653ef-a47e-4d13-fea8-bfd2419ac678"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best score=0.59345'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Best score=%.6f\" % results.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TeJEO-dN7PI9"
   },
   "outputs": [],
   "source": [
    "#Saving best model parameters\n",
    "\n",
    "params={}\n",
    "params ['learning_rate'] = results.x[0]\n",
    "params ['num_leaves'] = results.x[1]\n",
    "params ['min_data_in_leaf'] = results.x[2]\n",
    "params ['feature_fraction'] = results.x[3]\n",
    "params ['bagging_fraction'] = results.x[4]\n",
    "params ['bagging_freq'] = results.x[5] \n",
    "\n",
    "import pickle\n",
    "with open('lgbm_params.pkl','wb') as file:\n",
    "    pickle.dump(params, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNll5Bwju6Q_"
   },
   "source": [
    "### Observations :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJj4c6QDu9_R"
   },
   "source": [
    "* Model --> **LGBM**\n",
    "* Best Parameters :\n",
    "    * *learning_rate* = **0.020756**\n",
    "    * *num_leaves* = **71**\n",
    "    * *min_data_in_leaf* = **180**\n",
    "    * *feature_fraction* = **0.614000**\n",
    "    * *bagging_fraction* = **0.792127**\n",
    "    * *bagging_freq* = **1** \n",
    "* Best Score (NWRMSLE) --> **0.5934**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "gNVpaWaSi_dC",
    "edpKYGBbjG50",
    "PAYxORCE5tBg",
    "JYs6IsHakahn",
    "yGHCj5TN6MV1",
    "cGg0O77VR1_U",
    "vF4KojL_cAa7",
    "KOGcPWZW6nwj",
    "Qat_PqlZ6vZA",
    "onWea9r8r6lA"
   ],
   "name": "LGBM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03a9672ab27f47e899c737900756b585": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8496f74321884397aa0db3c4709e3217",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0768261a84146a29984957bd41bd6d1",
      "value": 2
     }
    },
    "0496eb5618cd48a7ad284323fc60f3ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b29e8485ff3f42edae8be9562ab7da1e",
      "placeholder": "​",
      "style": "IPY_MODEL_4557042016a2411d8c1b65a778b41f7d",
      "value": " 633/633 [00:53&lt;00:00, 11.88it/s]"
     }
    },
    "0f309844c96344e3972e1181ce0e0648": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a3b628d33a7466699d6c0438ad554f0",
      "placeholder": "​",
      "style": "IPY_MODEL_f736a229b5f4477287abadf01510e4cb",
      "value": " 23808261/23808261 [00:47&lt;00:00, 500234.60it/s]"
     }
    },
    "0fe082c65717473583c27e9d895f4448": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1abe5e69185840b5ad1eea0ea1b0e564": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd394492a25f4d33851f30a27050fe9a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_476aa9a41c014519ba2bc5368beb2a94",
      "value": 1
     }
    },
    "1c25fbf929cf4b50af7eb500065d8bdb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d30f29da7ed4a849d0623a0e5f08039": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f7b5147e4b846578f40ffc2c23137d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_03a9672ab27f47e899c737900756b585",
       "IPY_MODEL_851dbc4edf184d078174ed9c8502deee"
      ],
      "layout": "IPY_MODEL_da6d96db5917448d902d68e60bd2b9f2"
     }
    },
    "246a2ab922f646619e0a2f35f94d7753": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26092c056a844726a8b46055799e1ed2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26b16fb978ba4a5284504d222775dc4b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28217aa7bba24e519441b217db3ee471": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d8f30afcd174b09a1029d8cc0aebf9c",
       "IPY_MODEL_9b1c5437dcf64a598ee09d18d3e9e1ec"
      ],
      "layout": "IPY_MODEL_1c25fbf929cf4b50af7eb500065d8bdb"
     }
    },
    "2abc95643ca84593bfaf23e271b95765": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4ab930c3add4e55a7d39531fcfec24a",
       "IPY_MODEL_0496eb5618cd48a7ad284323fc60f3ef"
      ],
      "layout": "IPY_MODEL_246a2ab922f646619e0a2f35f94d7753"
     }
    },
    "311d372836c340de95f95e6fa5d3007a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_38ed41334ad8430796eeaf2bd8bbef52",
       "IPY_MODEL_3ca3b32df5af443e838d6999f0810bac"
      ],
      "layout": "IPY_MODEL_1d30f29da7ed4a849d0623a0e5f08039"
     }
    },
    "316edb9187d442bf83bf107d04d42d72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32aa608c889644f7bef875eac96defa8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38ed41334ad8430796eeaf2bd8bbef52": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_609a7b0141434111802590cdaff121cc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f0f1b43e1666492288c8c9858c18c30c",
      "value": 1
     }
    },
    "3ca3b32df5af443e838d6999f0810bac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c91e3bf65926457ead45ac8ea00b584a",
      "placeholder": "​",
      "style": "IPY_MODEL_f173048d22f549769265f279d0d13067",
      "value": " 1/1 [03:01&lt;00:00, 181.26s/it]"
     }
    },
    "3f48860e077844a98ea1a1692fbf5e92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db9d9e0698ea4d399cdbb4ee387fc957",
       "IPY_MODEL_6b0aa5e781b6416f89e7c3515a898289"
      ],
      "layout": "IPY_MODEL_637f38687bc8464dabefabfc1060aa9b"
     }
    },
    "4557042016a2411d8c1b65a778b41f7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "476aa9a41c014519ba2bc5368beb2a94": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5365746658844988a18d323de36ad518": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f53dc2a3f120451ab4be106efde54a61",
      "max": 23808261,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf9f7a10af77430ba8e5ffde6e3d9312",
      "value": 23808261
     }
    },
    "5576247931de47558c0722f123080da5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5f2e08c857f7417a9149766623a164b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1f22ff5a0404aada1f7d920b589cca3",
       "IPY_MODEL_b04c16ae093a400d8c7948828ab8c94e"
      ],
      "layout": "IPY_MODEL_8c459c2a0c014805a13e00643c0786c1"
     }
    },
    "609a7b0141434111802590cdaff121cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "637f38687bc8464dabefabfc1060aa9b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "663019abb6a0488482a709d568c0903a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b0aa5e781b6416f89e7c3515a898289": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32aa608c889644f7bef875eac96defa8",
      "placeholder": "​",
      "style": "IPY_MODEL_8ac6163e6efd4bfda75065b5d279d905",
      "value": " 633/633 [01:36&lt;00:00,  6.53it/s]"
     }
    },
    "716bbd11133442ab8419fc50daf8de21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "769174068b91435aa1d5fb74ece7e40d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d8f30afcd174b09a1029d8cc0aebf9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a144c3885474f44bcedb6377b05d54d",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3955ed976ea474da28461162b214e7c",
      "value": 3
     }
    },
    "81aac40f4e0d4a04a79ec3e964e394a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8496f74321884397aa0db3c4709e3217": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "851dbc4edf184d078174ed9c8502deee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_663019abb6a0488482a709d568c0903a",
      "placeholder": "​",
      "style": "IPY_MODEL_dae649ece067447f9175edb5ea360ba8",
      "value": " 2/2 [00:43&lt;00:00, 21.87s/it]"
     }
    },
    "8937d13f8ee642188b986a4f6a04c1bf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a3b628d33a7466699d6c0438ad554f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ac6163e6efd4bfda75065b5d279d905": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c459c2a0c014805a13e00643c0786c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a144c3885474f44bcedb6377b05d54d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b1c5437dcf64a598ee09d18d3e9e1ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81aac40f4e0d4a04a79ec3e964e394a8",
      "placeholder": "​",
      "style": "IPY_MODEL_716bbd11133442ab8419fc50daf8de21",
      "value": " 3/3 [00:00&lt;00:00, 71.57it/s]"
     }
    },
    "9e9a2924c1084937bc3e7cc02b8e4268": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0768261a84146a29984957bd41bd6d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a36d161761ea4d1fb00e390344c803cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b04c16ae093a400d8c7948828ab8c94e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26b16fb978ba4a5284504d222775dc4b",
      "placeholder": "​",
      "style": "IPY_MODEL_ebb0b5e7561249789be6fd900a3374b6",
      "value": " 633/633 [09:35&lt;00:00,  1.10it/s]"
     }
    },
    "b29e8485ff3f42edae8be9562ab7da1e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf9f7a10af77430ba8e5ffde6e3d9312": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c91e3bf65926457ead45ac8ea00b584a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9c504d797fa4e07a6534d2687765e66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cd394492a25f4d33851f30a27050fe9a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4ab930c3add4e55a7d39531fcfec24a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_769174068b91435aa1d5fb74ece7e40d",
      "max": 633,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9c504d797fa4e07a6534d2687765e66",
      "value": 633
     }
    },
    "da6d96db5917448d902d68e60bd2b9f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dae649ece067447f9175edb5ea360ba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db8a0702c7104de18ec198b3e563c7a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5365746658844988a18d323de36ad518",
       "IPY_MODEL_0f309844c96344e3972e1181ce0e0648"
      ],
      "layout": "IPY_MODEL_0fe082c65717473583c27e9d895f4448"
     }
    },
    "db9d9e0698ea4d399cdbb4ee387fc957": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ede94b80fabc4ee9ad4e03f62d3aeeaa",
      "max": 633,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a36d161761ea4d1fb00e390344c803cb",
      "value": 633
     }
    },
    "e3955ed976ea474da28461162b214e7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ebb0b5e7561249789be6fd900a3374b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec7279d173844345a8e62f4e1e6d41db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1abe5e69185840b5ad1eea0ea1b0e564",
       "IPY_MODEL_f6c0192fe8a144fabd9b5bd21a0f88f6"
      ],
      "layout": "IPY_MODEL_8937d13f8ee642188b986a4f6a04c1bf"
     }
    },
    "ede94b80fabc4ee9ad4e03f62d3aeeaa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0f1b43e1666492288c8c9858c18c30c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f173048d22f549769265f279d0d13067": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1f22ff5a0404aada1f7d920b589cca3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26092c056a844726a8b46055799e1ed2",
      "max": 633,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5576247931de47558c0722f123080da5",
      "value": 633
     }
    },
    "f53dc2a3f120451ab4be106efde54a61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6c0192fe8a144fabd9b5bd21a0f88f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_316edb9187d442bf83bf107d04d42d72",
      "placeholder": "​",
      "style": "IPY_MODEL_9e9a2924c1084937bc3e7cc02b8e4268",
      "value": " 1/1 [08:37&lt;00:00, 517.62s/it]"
     }
    },
    "f736a229b5f4477287abadf01510e4cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
