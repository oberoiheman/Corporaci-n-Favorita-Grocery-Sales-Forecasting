{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNVpaWaSi_dC"
   },
   "source": [
    "### Enable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yBBegewm6ZOl",
    "outputId": "9389a596-b292-40b3-cdc3-85d0e6ee56c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LightGBM'...\n",
      "remote: Enumerating objects: 41, done.\u001b[K\n",
      "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
      "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
      "remote: Total 18303 (delta 13), reused 5 (delta 1), pack-reused 18262\u001b[K\n",
      "Receiving objects: 100% (18303/18303), 12.34 MiB | 9.62 MiB/s, done.\n",
      "Resolving deltas: 100% (13356/13356), done.\n",
      "/content/LightGBM\n",
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
      "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
      "-- Looking for CL_VERSION_2_2\n",
      "-- Looking for CL_VERSION_2_2 - found\n",
      "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
      "-- OpenCL include directory: /usr/include\n",
      "-- Boost version: 1.65.1\n",
      "-- Found the following Boost libraries:\n",
      "--   filesystem\n",
      "--   system\n",
      "-- Performing Test MM_PREFETCH\n",
      "-- Performing Test MM_PREFETCH - Success\n",
      "-- Using _mm_prefetch\n",
      "-- Performing Test MM_MALLOC\n",
      "-- Performing Test MM_MALLOC - Success\n",
      "-- Using _mm_malloc\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/LightGBM\n",
      "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
      "[  1%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
      "[  3%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
      "[  9%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
      "[ 51%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
      "[ 54%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
      "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
      "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
      "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
      "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
      "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
      "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
      "[ 96%] \u001b[32m\u001b[1mLinking CXX executable lightgbm\u001b[0m\n",
      "[ 98%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
      "[ 98%] Built target lightgbm\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library lib_lightgbm.so\u001b[0m\n",
      "[100%] Built target _lightgbm\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
      "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
      "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
      "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
      "  python-setuptools python-six python-wheel python-xdg\n",
      "Suggested packages:\n",
      "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
      "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
      "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
      "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
      "The following NEW packages will be installed:\n",
      "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
      "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
      "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
      "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
      "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
      "0 upgraded, 22 newly installed, 0 to remove and 33 not upgraded.\n",
      "Need to get 3,376 kB of archives.\n",
      "After this operation, 10.5 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.3 [221 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.1 [1,653 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1.18.04.1 [151 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-xdg all 0.25-4ubuntu1 [31.3 kB]\n",
      "Fetched 3,376 kB in 0s (21.1 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 22.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package libpython-all-dev:amd64.\n",
      "(Reading database ... 144379 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package python-all.\n",
      "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking python-all (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package python-all-dev.\n",
      "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
      "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
      "Selecting previously unselected package python-asn1crypto.\n",
      "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
      "Unpacking python-asn1crypto (0.24.0-1) ...\n",
      "Selecting previously unselected package python-cffi-backend.\n",
      "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
      "Unpacking python-cffi-backend (1.11.5-1) ...\n",
      "Selecting previously unselected package python-crypto.\n",
      "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
      "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
      "Selecting previously unselected package python-enum34.\n",
      "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
      "Unpacking python-enum34 (1.1.6-2) ...\n",
      "Selecting previously unselected package python-idna.\n",
      "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
      "Unpacking python-idna (2.6-1) ...\n",
      "Selecting previously unselected package python-ipaddress.\n",
      "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
      "Unpacking python-ipaddress (1.0.17-1) ...\n",
      "Selecting previously unselected package python-six.\n",
      "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
      "Unpacking python-six (1.11.0-2) ...\n",
      "Selecting previously unselected package python-cryptography.\n",
      "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.3_amd64.deb ...\n",
      "Unpacking python-cryptography (2.1.4-1ubuntu1.3) ...\n",
      "Selecting previously unselected package python-dbus.\n",
      "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
      "Unpacking python-dbus (1.2.6-1) ...\n",
      "Selecting previously unselected package python-gi.\n",
      "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
      "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
      "Selecting previously unselected package python-secretstorage.\n",
      "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
      "Unpacking python-secretstorage (2.3.1-2) ...\n",
      "Selecting previously unselected package python-keyring.\n",
      "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
      "Unpacking python-keyring (10.6.0-1) ...\n",
      "Selecting previously unselected package python-keyrings.alt.\n",
      "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
      "Unpacking python-keyrings.alt (3.0-1) ...\n",
      "Selecting previously unselected package python-pip-whl.\n",
      "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
      "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
      "Selecting previously unselected package python-pip.\n",
      "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
      "Unpacking python-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
      "Selecting previously unselected package python-pkg-resources.\n",
      "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
      "Unpacking python-pkg-resources (39.0.1-2) ...\n",
      "Selecting previously unselected package python-setuptools.\n",
      "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
      "Unpacking python-setuptools (39.0.1-2) ...\n",
      "Selecting previously unselected package python-wheel.\n",
      "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
      "Unpacking python-wheel (0.30.0-0.2) ...\n",
      "Selecting previously unselected package python-xdg.\n",
      "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1_all.deb ...\n",
      "Unpacking python-xdg (0.25-4ubuntu1) ...\n",
      "Setting up python-idna (2.6-1) ...\n",
      "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
      "Setting up python-asn1crypto (0.24.0-1) ...\n",
      "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
      "Setting up python-wheel (0.30.0-0.2) ...\n",
      "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
      "Setting up python-pkg-resources (39.0.1-2) ...\n",
      "Setting up python-cffi-backend (1.11.5-1) ...\n",
      "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
      "Setting up python-six (1.11.0-2) ...\n",
      "Setting up python-enum34 (1.1.6-2) ...\n",
      "Setting up python-dbus (1.2.6-1) ...\n",
      "Setting up python-ipaddress (1.0.17-1) ...\n",
      "Setting up python-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
      "Setting up python-all (2.7.15~rc1-1) ...\n",
      "Setting up python-xdg (0.25-4ubuntu1) ...\n",
      "Setting up python-setuptools (39.0.1-2) ...\n",
      "Setting up python-keyrings.alt (3.0-1) ...\n",
      "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
      "Setting up python-cryptography (2.1.4-1ubuntu1.3) ...\n",
      "Setting up python-secretstorage (2.3.1-2) ...\n",
      "Setting up python-keyring (10.6.0-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Collecting setuptools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/fa/60888a1d591db07bc9c17dce2bcfb9f00ac507c0a23ecb827e76feb8f816/setuptools-49.1.0-py3-none-any.whl (789kB)\n",
      "\u001b[K     |████████████████████████████████| 798kB 8.2MB/s \n",
      "\u001b[?25hRequirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/0b/71ae818646c1a80fbe6776d41f480649523ed31243f1f34d9d7e41d70195/numpy-1.19.0-cp36-cp36m-manylinux2010_x86_64.whl (14.6MB)\n",
      "\u001b[K     |████████████████████████████████| 14.6MB 208kB/s \n",
      "\u001b[?25hCollecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/20/d4410683e4d416a11ebc60138f6d925f571ffcfcc3794baf78fff982c98d/scipy-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9MB 1.3MB/s \n",
      "\u001b[?25hCollecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9MB 55.5MB/s \n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.15.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: setuptools, numpy, scipy, threadpoolctl, scikit-learn\n",
      "  Found existing installation: setuptools 47.3.1\n",
      "    Uninstalling setuptools-47.3.1:\n",
      "      Successfully uninstalled setuptools-47.3.1\n",
      "  Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed numpy-1.19.0 scikit-learn-0.23.1 scipy-1.5.0 setuptools-49.1.0 threadpoolctl-2.1.0\n",
      "/content/LightGBM/python-package\n",
      "running install\n",
      "running build\n",
      "running build_py\n",
      "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
      "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
      "creating build\n",
      "creating build/lib\n",
      "creating build/lib/lightgbm\n",
      "copying lightgbm/callback.py -> build/lib/lightgbm\n",
      "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
      "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
      "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
      "copying lightgbm/compat.py -> build/lib/lightgbm\n",
      "copying lightgbm/basic.py -> build/lib/lightgbm\n",
      "copying lightgbm/engine.py -> build/lib/lightgbm\n",
      "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
      "running egg_info\n",
      "creating lightgbm.egg-info\n",
      "writing lightgbm.egg-info/PKG-INFO\n",
      "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
      "writing requirements to lightgbm.egg-info/requires.txt\n",
      "writing top-level names to lightgbm.egg-info/top_level.txt\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "no previously-included directories found matching 'build'\n",
      "warning: no files found matching 'LICENSE'\n",
      "warning: no files found matching '*.txt'\n",
      "warning: no files found matching '*.so' under directory 'lightgbm'\n",
      "warning: no files found matching '*.txt' under directory 'compile'\n",
      "warning: no files found matching '*.so' under directory 'compile'\n",
      "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
      "warning: no files found matching '*' under directory 'compile/compute'\n",
      "warning: no files found matching '*' under directory 'compile/include'\n",
      "warning: no files found matching '*' under directory 'compile/src'\n",
      "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
      "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
      "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
      "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
      "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
      "running install_lib\n",
      "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
      "copying ../lib_lightgbm.so -> /usr/local/lib/python3.6/dist-packages/lightgbm\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/callback.py to callback.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/plotting.py to plotting.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/__init__.py to __init__.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py to sklearn.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/compat.py to compat.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/basic.py to basic.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/engine.py to engine.cpython-36.pyc\n",
      "byte-compiling /usr/local/lib/python3.6/dist-packages/lightgbm/libpath.py to libpath.cpython-36.pyc\n",
      "running install_egg_info\n",
      "Copying lightgbm.egg-info to /usr/local/lib/python3.6/dist-packages/lightgbm-2.3.2-py3.6.egg-info\n",
      "running install_scripts\n"
     ]
    }
   ],
   "source": [
    "!git clone -- https://github.com/microsoft/LightGBM.git\n",
    "%cd /content/LightGBM\n",
    "!mkdir build\n",
    "!cmake -DUSE_GPU=1 #avoid ..\n",
    "!make -j$(nproc)\n",
    "!sudo apt-get -y install python-pip\n",
    "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n",
    "%cd /content/LightGBM/python-package\n",
    "!sudo python setup.py install --precompile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "edpKYGBbjG50"
   },
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-mMNgYLNu0K"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2-DbPcQ50Gl"
   },
   "outputs": [],
   "source": [
    "# Reference: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of Dataframe is {:.3f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in tqdm(df.columns):\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object and col_type.name != 'category' and 'datetime' not in col_type.name:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        elif 'datetime' not in col_type.name:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.3f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PAYxORCE5tBg"
   },
   "source": [
    "### Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "H1YnRHGCxyDw",
    "outputId": "9f2e96ef-2d98-48e2-ef62-438e1954db7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-04 17:57:38--  https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/7391/44328/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1593984946&Signature=TZ8WhKQzNyAp%2B8IRIjBE3f9IPhSdR%2B8izTu2DDZLt1ZJS9M5q5pZsNpMGYYOCFwROdvxHPUf%2FIVoPslSOiRMcBdkBhumDs6xiOt9A5dzgUh6QqH3%2BzX%2F%2Be2FVjW2dg3a%2B%2FmqIwQLD7y%2B8gfRP82VlEMdGcxLLbRliMfy2ZK0BlMZgRZJ7%2BNmsdbm3V6Y%2Fk7YnIiDGH3bBopFwLN02mOhiqb96GC4gD813iLV5DRoSzegViOZjddjSBtKeNlFu86bo9oj2cjI%2BQrxQV%2F2I6IU1lKqXxkkdAl0oFzzfNUwlLForPg0nd8GMaYgdlM6Ga1liBl2QFahMYkwJUM6Hvv%2F6w%3D%3D&response-content-disposition=attachment%3B+filename%3Dfavorita-grocery-sales-forecasting.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 108.177.126.128, 172.217.218.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 480014675 (458M) [application/zip]\n",
      "Saving to: ‘favorita-grocery-sales-forecasting.zip’\n",
      "\n",
      "favorita-grocery-sa 100%[===================>] 457.78M  72.6MB/s    in 6.7s    \n",
      "\n",
      "2020-07-04 17:57:45 (68.7 MB/s) - ‘favorita-grocery-sales-forecasting.zip’ saved [480014675/480014675]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Downloading data (using wget)\n",
    "\n",
    "file_path=\"favorita-grocery-sales-forecasting.zip\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    !wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/7391/44328/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1593984946&Signature=TZ8WhKQzNyAp%2B8IRIjBE3f9IPhSdR%2B8izTu2DDZLt1ZJS9M5q5pZsNpMGYYOCFwROdvxHPUf%2FIVoPslSOiRMcBdkBhumDs6xiOt9A5dzgUh6QqH3%2BzX%2F%2Be2FVjW2dg3a%2B%2FmqIwQLD7y%2B8gfRP82VlEMdGcxLLbRliMfy2ZK0BlMZgRZJ7%2BNmsdbm3V6Y%2Fk7YnIiDGH3bBopFwLN02mOhiqb96GC4gD813iLV5DRoSzegViOZjddjSBtKeNlFu86bo9oj2cjI%2BQrxQV%2F2I6IU1lKqXxkkdAl0oFzzfNUwlLForPg0nd8GMaYgdlM6Ga1liBl2QFahMYkwJUM6Hvv%2F6w%3D%3D&response-content-disposition=attachment%3B+filename%3Dfavorita-grocery-sales-forecasting.zip\" -c -O 'favorita-grocery-sales-forecasting.zip'\n",
    "else:\n",
    "    print(\"File Already Present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "FSyBdZCz0V68",
    "outputId": "d6525d56-321a-4600-b0a1-9568cff3b9ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  favorita-grocery-sales-forecasting.zip\n",
      "  inflating: holidays_events.csv.7z  \n",
      "  inflating: items.csv.7z            \n",
      "  inflating: oil.csv.7z              \n",
      "  inflating: sample_submission.csv.7z  \n",
      "  inflating: stores.csv.7z           \n",
      "  inflating: test.csv.7z             \n",
      "  inflating: train.csv.7z            \n",
      "  inflating: transactions.csv.7z     \n",
      "File unzipped Successfully\n"
     ]
    }
   ],
   "source": [
    "# unzipping favorita-grocery-sales-forecasting.zip\n",
    "\n",
    "if os.path.exists('favorita-grocery-sales-forecasting.zip'):\n",
    "    !unzip 'favorita-grocery-sales-forecasting.zip'\n",
    "    print(\"File unzipped Successfully\")\n",
    "else:\n",
    "    print(\"File Not Present to unzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "7kkS4sXr0bxq",
    "outputId": "e8857079-8a87-49e5-d304-1e5884a7c75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 0%\r",
      "\r",
      "Reading package lists... 6%\r",
      "\r",
      "Reading package lists... 6%\r",
      "\r",
      "Reading package lists... 6%\r",
      "\r",
      "Reading package lists... 6%\r",
      "\r",
      "Reading package lists... 62%\r",
      "\r",
      "Reading package lists... 62%\r",
      "\r",
      "Reading package lists... 63%\r",
      "\r",
      "Reading package lists... 63%\r",
      "\r",
      "Reading package lists... 70%\r",
      "\r",
      "Reading package lists... 70%\r",
      "\r",
      "Reading package lists... 71%\r",
      "\r",
      "Reading package lists... 71%\r",
      "\r",
      "Reading package lists... 77%\r",
      "\r",
      "Reading package lists... 80%\r",
      "\r",
      "Reading package lists... 80%\r",
      "\r",
      "Reading package lists... 80%\r",
      "\r",
      "Reading package lists... 80%\r",
      "\r",
      "Reading package lists... 80%\r",
      "\r",
      "Reading package lists... 80%\r",
      "\r",
      "Reading package lists... 80%\r",
      "\r",
      "Reading package lists... 80%\r",
      "\r",
      "Reading package lists... 86%\r",
      "\r",
      "Reading package lists... 86%\r",
      "\r",
      "Reading package lists... 87%\r",
      "\r",
      "Reading package lists... 87%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 93%\r",
      "\r",
      "Reading package lists... 94%\r",
      "\r",
      "Reading package lists... 94%\r",
      "\r",
      "Reading package lists... 95%\r",
      "\r",
      "Reading package lists... 95%\r",
      "\r",
      "Reading package lists... 98%\r",
      "\r",
      "Reading package lists... 98%\r",
      "\r",
      "Reading package lists... 98%\r",
      "\r",
      "Reading package lists... 98%\r",
      "\r",
      "Reading package lists... Done\r\n",
      "\r",
      "Building dependency tree... 0%\r",
      "\r",
      "Building dependency tree... 0%\r",
      "\r",
      "Building dependency tree... 50%\r",
      "\r",
      "Building dependency tree... 50%\r",
      "\r",
      "Building dependency tree       \r\n",
      "\r",
      "Reading state information... 0%\r",
      "\r",
      "Reading state information... 0%\r",
      "\r",
      "Reading state information... Done\r\n",
      "p7zip-full is already the newest version (16.02+dfsg-6).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "#installing 7zip for extracting .7z files\n",
    "!apt-get install p7zip-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "8ix7xDWx0e1j",
    "outputId": "b58d2006-04ce-495f-c2df-162d5a572514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 666528 bytes (651 KiB)\n",
      "\n",
      "Extracting archive: sample_submission.csv.7z\n",
      "--\n",
      "Path = sample_submission.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 666528\n",
      "Headers Size = 146\n",
      "Method = LZMA2:24\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b 93% - sample_submission.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       40445582\n",
      "Compressed: 666528\n",
      "==================================================\n",
      "'sample_submission.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 474092593 bytes (453 MiB)\n",
      "\n",
      "Extracting archive: train.csv.7z\n",
      "--\n",
      "Path = train.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 474092593\n",
      "Headers Size = 122\n",
      "Method = LZMA2:24\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b  0% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - train.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b100% 1\b\b\b\b\b\b      \b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       4997452288\n",
      "Compressed: 474092593\n",
      "==================================================\n",
      "'train.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 3762 bytes (4 KiB)\n",
      "\n",
      "Extracting archive: oil.csv.7z\n",
      "--\n",
      "Path = oil.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 3762\n",
      "Headers Size = 122\n",
      "Method = LZMA2:24k\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       20580\n",
      "Compressed: 3762\n",
      "==================================================\n",
      "'oil.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 648 bytes (1 KiB)\n",
      "\n",
      "Extracting archive: stores.csv.7z\n",
      "--\n",
      "Path = stores.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 648\n",
      "Headers Size = 130\n",
      "Method = LZMA2:12\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       1387\n",
      "Compressed: 648\n",
      "==================================================\n",
      "'stores.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 14315 bytes (14 KiB)\n",
      "\n",
      "Extracting archive: items.csv.7z\n",
      "--\n",
      "Path = items.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 14315\n",
      "Headers Size = 122\n",
      "Method = LZMA2:17\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       101841\n",
      "Compressed: 14315\n",
      "==================================================\n",
      "'items.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 1898 bytes (2 KiB)\n",
      "\n",
      "Extracting archive: holidays_events.csv.7z\n",
      "--\n",
      "Path = holidays_events.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 1898\n",
      "Headers Size = 146\n",
      "Method = LZMA2:24k\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       22309\n",
      "Compressed: 1898\n",
      "==================================================\n",
      "'holidays_events.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 219499 bytes (215 KiB)\n",
      "\n",
      "Extracting archive: transactions.csv.7z\n",
      "--\n",
      "Path = transactions.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 219499\n",
      "Headers Size = 138\n",
      "Method = LZMA2:1536k\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       1552637\n",
      "Compressed: 219499\n",
      "==================================================\n",
      "'transactions.csv.7z' File Extracted Successfully\n",
      "==================================================\n",
      "\n",
      "7-Zip (a) [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
      "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
      "\n",
      "Scanning the drive for archives:\n",
      "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 4885065 bytes (4771 KiB)\n",
      "\n",
      "Extracting archive: test.csv.7z\n",
      "--\n",
      "Path = test.csv.7z\n",
      "Type = 7z\n",
      "Physical Size = 4885065\n",
      "Headers Size = 122\n",
      "Method = LZMA2:24\n",
      "Solid = -\n",
      "Blocks = 1\n",
      "\n",
      "  0%\b\b\b\b    \b\b\b\b 26% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% - test.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b               \b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
      "\n",
      "Size:       126163026\n",
      "Compressed: 4885065\n",
      "==================================================\n",
      "'test.csv.7z' File Extracted Successfully\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#Extracting .7z files if they are not already extracted.\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file[-3:]=='.7z':\n",
    "        if os.path.exists(file[:-3]):\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}'Extracted File is Already Present\".format(file[:-3]))\n",
    "        elif file=='oil.csv.7z':\n",
    "            !p7zip -d 'oil.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='train.csv.7z':\n",
    "            !p7zip -d 'train.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='stores.csv.7z':\n",
    "            !p7zip -d 'stores.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='transactions.csv.7z':\n",
    "            !p7zip -d 'transactions.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='items.csv.7z':\n",
    "            !p7zip -d 'items.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='holidays_events.csv.7z':\n",
    "            !p7zip -d 'holidays_events.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='test.csv.7z':\n",
    "            !p7zip -d 'test.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        elif file=='sample_submission.csv.7z':\n",
    "            !p7zip -d 'sample_submission.csv.7z'\n",
    "            print(\"=\"*50)\n",
    "            print(\"'{}' File Extracted Successfully\".format(file))\n",
    "\n",
    "        print(\"=\"*50)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757,
     "referenced_widgets": [
      "dbe4c42659f6494bba5a3942c6a2036e",
      "f1f3f0a5e7c0413e9d68edde10d5211a",
      "4a6c4f9a68e9499f8e0665348dd2a4bc",
      "181061f7c9474cf98d97b9eea9a91b4a",
      "aece3190486745a9b65e8f149c109399",
      "8d6f5831c9e14a468b308d629aa258ef",
      "1324f19f71f6421a9aaababad060e076",
      "ef0bbbe48d1f4b39b1143cf7bebca019",
      "03627738e52340aabd715f02ee73d4ca",
      "411226fa036c48f3bc7049f7d8b76c4c",
      "2804f23dc2874f71a2655dcba9ae7649",
      "c45b1d5db9a549e1b094aa986654f205",
      "c14ac1246a17454bb973356897c84a1d",
      "36a266d9fed14ecf8abdc5daf162d155",
      "25e04ea4e04d43f7909923c190f9d6fd",
      "03fbeb6469454a319e97bf111c5900e3",
      "e120464726c54dab87cbda59abf98831",
      "1a079d52f9354ec39c3f8de76e673ecb",
      "5b118e2a48ba421c97673296c7f36cb5",
      "a919e10078684258821db5608b8b2c2a",
      "41648c09cd7b4d919e7410452e2e0a30",
      "6182ad151f3341ef844ab423b18f2dfa",
      "cb9a96461b6145049b4aeaaf72e6c959",
      "bb447b61bc20479d8487dd621a28ee08",
      "03772aa258cf4be591d212abcc9d8aab",
      "2dc5aa5e515343a9bafd3a9a9d31b31e",
      "25c5fd2969b24e2eb421a4e8ceddd945",
      "7fd483d30177402ab4ac99adc4b8f0f7",
      "5dc2349f861546e880ca84d1db9c686a",
      "3499603b01014c14987a8f56cb8dee52",
      "90150e4582ed454d911c26515c71f8c7",
      "21f2f1812d7e454b98f6f01fc8872327"
     ]
    },
    "colab_type": "code",
    "id": "fobux-QYv68E",
    "outputId": "6cd16ed9-e889-4972-d21b-f722104fda6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pre-Processing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe4c42659f6494bba5a3942c6a2036e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23808261.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the following for Train Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 31/5/2017\n",
      "No. of weeks --> 6\n",
      "\n",
      "Creating Features for data between Dates --> 2017-05-31 - 2017-07-12 (i.e. 6 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03627738e52340aabd715f02ee73d4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_train.csv' File ...\n",
      "Saving 'y_train.csv' File ...\n",
      "\n",
      "Enter the following for Validation Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 26/7/2017\n",
      "No. of weeks --> 1\n",
      "\n",
      "Creating Features for data between Dates --> 2017-07-26 - 2017-08-02 (i.e. 1 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e120464726c54dab87cbda59abf98831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_val.csv' File ...\n",
      "Saving 'y_val.csv' File ...\n",
      "\n",
      "Enter the following for Test Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 16/8/2017\n",
      "No. of weeks --> 1\n",
      "\n",
      "Creating Features for data between Dates --> 2017-08-16 - 2017-08-23 (i.e. 1 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03772aa258cf4be591d212abcc9d8aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_test.csv' File ...\n",
      "\n",
      "Saving 'sales_2017.csv' File ...\n",
      "Saving 'stores_items.csv' File ...\n"
     ]
    }
   ],
   "source": [
    "#Creating features by excecuting Pre_Processing Feature_engineering.py\n",
    "\n",
    "exec(open('Pre_Processing Feature_engineering.py').read())\n",
    "\n",
    "\n",
    "# Train Dataset Initial Date 31/5/2017\n",
    "# 6 weeks\n",
    "\n",
    "# Validation Dataset Initial Date 26/7/2017\n",
    "# 1 week\n",
    "\n",
    "# Test Dataset Initial Date 16/8/2017\n",
    "# 1 week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYs6IsHakahn"
   },
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "bf4983d9aa894a3cab7bb604d1d6612a",
      "d5d18016a0c74e54a7b96e6c428130c8",
      "c077db0b048f4460a5bfdfc650587e4c",
      "f10211f0b4a94605b272f439fc2c8e0a",
      "7b99a7de81e94732888fdaa5dc9585f6",
      "d7868103552c4d2bbbb32a990e34904c",
      "6f606c7dc1054a8b91d7bbe5709fdba9",
      "7feec5900101408da50dffba13863c06"
     ]
    },
    "colab_type": "code",
    "id": "PiDmzIxm92He",
    "outputId": "9a571467-10d3-4857-ca12-64758c98da4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of Dataframe is 5662.987 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4983d9aa894a3cab7bb604d1d6612a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=633.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 1337.467 MB\n",
      "Decreased by 76.4%\n"
     ]
    }
   ],
   "source": [
    "# Reading X_train.csv and reducing memory usage\n",
    "X_train=pd.read_csv(\"X_train.csv\")\n",
    "X_train=reduce_mem_usage(X_train)\n",
    "\n",
    "# Reading y_train.csv and converting into numpy array\n",
    "y_train = np.array(pd.read_csv( 'y_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w31IYrzO-HQ3"
   },
   "outputs": [],
   "source": [
    "# Reading X_val.csv and reducing memory usage\n",
    "X_val=pd.read_csv(\"X_val.csv\")\n",
    "X_val=reduce_mem_usage(X_val)\n",
    "\n",
    "# Reading y_val.csv and converting into numpy array\n",
    "y_val = np.array(pd.read_csv( 'y_val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "417c09e0afb14d979ecb3021100c2393",
      "f5de498a722046a3bb0bbe834e5cd23b",
      "f6b523cf2ae2461cb49961d55ad76296",
      "bc22aca106674e9c824708a4c9e31fa2",
      "5759388fb12b4189a105c68a21d27805",
      "78bfc6454fbe42b389c185cfac704ca2",
      "11b30308521b463597c88c64f84e0887",
      "91a12ec0de7b42aaab050e26001d6005"
     ]
    },
    "colab_type": "code",
    "id": "Owd_QrIGztxP",
    "outputId": "25d62c19-5f7b-41a0-f51f-6db614e8bed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of Dataframe is 808.998 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417c09e0afb14d979ecb3021100c2393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=633.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 191.067 MB\n",
      "Decreased by 76.4%\n"
     ]
    }
   ],
   "source": [
    "# Reading X_test.csv and reducing memory usage\n",
    "X_test=pd.read_csv(\"X_test.csv\")\n",
    "X_test=reduce_mem_usage(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "4a48fa242d284b3c9483862ff711f44c",
      "8d387c52c729472c8f416c4793e04790",
      "712acd616c954244802e252377e7bb79",
      "fd07bdebd10046b394e08bf6eccde2a2",
      "de9581fff5814dd99dc9149b63d30f64",
      "a5409acbb7324b40b4cd2e4e50ab0db1",
      "8eca55bb8cc84f92b074a791f526b871",
      "6e5577953e7a414a9758725241445970"
     ]
    },
    "colab_type": "code",
    "id": "DE0eO23Q9zJP",
    "outputId": "01ab3a4c-891c-44cc-a60d-5ef4dbf94b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of Dataframe is 5.112 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a48fa242d284b3c9483862ff711f44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage after optimization is: 1.919 MB\n",
      "Decreased by 62.5%\n"
     ]
    }
   ],
   "source": [
    "# Reading stores_items.csv\n",
    "stores_items = pd.read_csv('stores_items.csv', index_col=['store_nbr','item_nbr'])\n",
    "\n",
    "# Reading items.csv and setting index as item_nbr\n",
    "items = pd.read_csv( 'items.csv' ).set_index(\"item_nbr\")\n",
    "\n",
    "items = items.reindex( stores_items.index.get_level_values(1) )\n",
    "items=reduce_mem_usage(items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGHCj5TN6MV1"
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGJnLvW6SDil"
   },
   "outputs": [],
   "source": [
    "# Loading Top 300 Feature Names (got by training random forest)\n",
    "import pickle\n",
    "with open('300_filtered_features.pkl','rb') as file:\n",
    "    filtered_features = pickle.load( file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGg0O77VR1_U"
   },
   "source": [
    "### Defining LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urr_AmQoZ7wA"
   },
   "outputs": [],
   "source": [
    "def train_lgb_model(X_train,y_train,X_val,y_val,params,num_boost_rounds,n_days,items,features,verbose,X_test=None):\n",
    "    '''\n",
    "    Filter features from the Dataset and then\n",
    "    Trains 16 different lgb models for predicting next 16 days sales . \n",
    "    and Stores all the models into a list.\n",
    "    Returns --> * val_pred i.e.predicted values of validation data\n",
    "                * test_pred i.e.predicted values of test data if present\n",
    "                * boost_rounds i.e List of best no. of trees for every model\n",
    "    '''\n",
    "    global models\n",
    "\n",
    "    params['device_type']= 'gpu'\n",
    "    params['objective'] = 'regression'\n",
    "    params['metric'] = 'l2'\n",
    "    params ['num_threads']= 16\n",
    "\n",
    "    # num_boost_rounds parameter should be given for every model seperately as a list.\n",
    "    # but if it is given as an inetger then a list is made  having same value 16 times.\n",
    "    if not type(num_boost_rounds) == list:\n",
    "        temp=num_boost_rounds\n",
    "        num_boost_rounds=[]\n",
    "        for i in range(16):\n",
    "            num_boost_rounds.append(temp)\n",
    "\n",
    "    val_pred = []\n",
    "    test_pred = []\n",
    "    boost_rounds=[]\n",
    "\n",
    "    #Training 16 different models for predicting next 16 days sales.\n",
    "    for i in range(16):\n",
    "        print(\"=\" * 50)\n",
    "        print(\"Step %d\" % (i+1))\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # Filtering features\n",
    "        x_train = X_train[features[i]]\n",
    "\n",
    "        #Filtering Features from test dataset if it exists or Validation data.\n",
    "        try:\n",
    "            x_val = X_val[features[i]]\n",
    "        except:\n",
    "            x_test = X_test[features[i]]\n",
    "\n",
    "\n",
    "        #Creating Train lightgbm Dataset\n",
    "        dtrain = lgb.Dataset( x_train, label=y_train[:, i],\n",
    "                              weight=pd.concat([items[\"perishable\"]] * n_days) * 0.25 + 1  )#As described on kaggle  Items marked as perishable have a score weight of 1.25; otherwise, the weight is 1.0.\n",
    "        valid_sets=[dtrain]\n",
    "\n",
    "        #Creating Val lightgbm Dataset if it exists\n",
    "        try:\n",
    "            dval = lgb.Dataset(  x_val, label=y_val[:, i], reference=dtrain,\n",
    "                                weight=items[\"perishable\"] * 0.25 + 1 )\n",
    "            valid_sets=[dtrain,dval]\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        #Training Lgbm\n",
    "        model = lgb.train( params, dtrain, num_boost_rounds[i],\n",
    "                        valid_sets=valid_sets, verbose_eval=verbose )\n",
    "        \n",
    "        #Storing each model\n",
    "        models.append(model)\n",
    "\n",
    "        # appending results of prediction on val set if it exists\n",
    "        try:\n",
    "            val_pred.append(model.predict(x_val, num_iteration=model.best_iteration or num_boost_rounds[i]))\n",
    "        except:\n",
    "            pass\n",
    "        # appending results of prediction on test set if it exists\n",
    "        try:\n",
    "            test_pred.append(model.predict(x_test, num_iteration = model.best_iteration  or num_boost_rounds[i]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #Appending best no. of trees for every model \n",
    "        boost_rounds.append(model.best_iteration  or num_boost_rounds[i])\n",
    "\n",
    "        # Deleting unneccessary variables\n",
    "        try:\n",
    "            del model,dtrain,x_train,x_val,dval\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if type(X_test) != type(None):\n",
    "        return test_pred\n",
    "    else:\n",
    "        return val_pred,boost_rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vF4KojL_cAa7"
   },
   "source": [
    "### Performance Metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdWFg3dfb_yv"
   },
   "source": [
    "**NWRMSLE** (Normalized Weighted Root Mean Squared Logarithmic Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cmjGQnsdIu0p"
   },
   "outputs": [],
   "source": [
    "def calculate_nwrmsle(true,pred,weight):\n",
    "    ''' \n",
    "    Calculates Normalized Weighted Root Mean Squared Logarithmic Error (nwrmsle)\n",
    "\n",
    "    true = true labels\n",
    "    pred =  predicted labels\n",
    "    weight = weights of datapoints\n",
    "\n",
    "    returns nwrmsle '''\n",
    "\n",
    "    temp = (true - np.array(pred).transpose())**2\n",
    "    temp = temp.sum(axis=1) * weight\n",
    "    nwrmsle = np.sqrt(temp.sum() / weight.sum() / 16)\n",
    "    return nwrmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOGcPWZW6nwj"
   },
   "source": [
    "### LGBM Tuned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "oGmTWmWYrOmR",
    "outputId": "0a5b8470-26d4-4f4a-81a2-5ccba7e8ada8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.792127,\n",
       " 'bagging_freq': 1,\n",
       " 'feature_fraction': 0.614,\n",
       " 'learning_rate': 0.020756,\n",
       " 'min_data_in_leaf': 180,\n",
       " 'num_leaves': 71}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading best model parameters\n",
    "import pickle\n",
    "with open('lgbm_params.pkl','rb') as file:\n",
    "    params = pickle.load(file)\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8TWHI04p2BIs"
   },
   "source": [
    "### Training Model for 6 weeks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bk6rBC79cwXV"
   },
   "source": [
    " Now using more previous data i.e (6 weeks) to train the model with best parameters and incresing  boosting rounds to further improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AmXO7mkJreqr",
    "outputId": "8e650b82-0a46-4040-95b9-8377614643ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61412\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (253.05 MB) transferred to GPU in 0.379920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.039801\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.415821\tvalid_1's l2: 0.397041\n",
      "[100]\ttraining's l2: 0.317249\tvalid_1's l2: 0.306564\n",
      "[150]\ttraining's l2: 0.298967\tvalid_1's l2: 0.291667\n",
      "[200]\ttraining's l2: 0.292422\tvalid_1's l2: 0.2872\n",
      "[250]\ttraining's l2: 0.288919\tvalid_1's l2: 0.285149\n",
      "[300]\ttraining's l2: 0.286851\tvalid_1's l2: 0.28428\n",
      "[350]\ttraining's l2: 0.285129\tvalid_1's l2: 0.283715\n",
      "[400]\ttraining's l2: 0.283656\tvalid_1's l2: 0.283255\n",
      "[450]\ttraining's l2: 0.282287\tvalid_1's l2: 0.282861\n",
      "[500]\ttraining's l2: 0.281083\tvalid_1's l2: 0.282609\n",
      "[550]\ttraining's l2: 0.279981\tvalid_1's l2: 0.282456\n",
      "[600]\ttraining's l2: 0.278909\tvalid_1's l2: 0.28224\n",
      "[650]\ttraining's l2: 0.277917\tvalid_1's l2: 0.28209\n",
      "[700]\ttraining's l2: 0.276954\tvalid_1's l2: 0.281932\n",
      "[750]\ttraining's l2: 0.276077\tvalid_1's l2: 0.281852\n",
      "[800]\ttraining's l2: 0.275216\tvalid_1's l2: 0.281763\n",
      "[850]\ttraining's l2: 0.274355\tvalid_1's l2: 0.281671\n",
      "[900]\ttraining's l2: 0.273522\tvalid_1's l2: 0.281603\n",
      "[950]\ttraining's l2: 0.272714\tvalid_1's l2: 0.281541\n",
      "[1000]\ttraining's l2: 0.27196\tvalid_1's l2: 0.281485\n",
      "[1050]\ttraining's l2: 0.271191\tvalid_1's l2: 0.281444\n",
      "[1100]\ttraining's l2: 0.270438\tvalid_1's l2: 0.281413\n",
      "[1150]\ttraining's l2: 0.269691\tvalid_1's l2: 0.281387\n",
      "[1200]\ttraining's l2: 0.268966\tvalid_1's l2: 0.281366\n",
      "[1250]\ttraining's l2: 0.268281\tvalid_1's l2: 0.281319\n",
      "[1300]\ttraining's l2: 0.26759\tvalid_1's l2: 0.28128\n",
      "[1350]\ttraining's l2: 0.266916\tvalid_1's l2: 0.281237\n",
      "[1400]\ttraining's l2: 0.266235\tvalid_1's l2: 0.281233\n",
      "[1450]\ttraining's l2: 0.265553\tvalid_1's l2: 0.281201\n",
      "[1500]\ttraining's l2: 0.264892\tvalid_1's l2: 0.281184\n",
      "[1550]\ttraining's l2: 0.264243\tvalid_1's l2: 0.28116\n",
      "[1600]\ttraining's l2: 0.263615\tvalid_1's l2: 0.281128\n",
      "[1650]\ttraining's l2: 0.262964\tvalid_1's l2: 0.281097\n",
      "[1700]\ttraining's l2: 0.262343\tvalid_1's l2: 0.28108\n",
      "[1750]\ttraining's l2: 0.261714\tvalid_1's l2: 0.281077\n",
      "[1800]\ttraining's l2: 0.261096\tvalid_1's l2: 0.281056\n",
      "[1850]\ttraining's l2: 0.260463\tvalid_1's l2: 0.281042\n",
      "[1900]\ttraining's l2: 0.259862\tvalid_1's l2: 0.281021\n",
      "[1950]\ttraining's l2: 0.259269\tvalid_1's l2: 0.281003\n",
      "[2000]\ttraining's l2: 0.258675\tvalid_1's l2: 0.280997\n",
      "[2050]\ttraining's l2: 0.258069\tvalid_1's l2: 0.28097\n",
      "[2100]\ttraining's l2: 0.257483\tvalid_1's l2: 0.280971\n",
      "[2150]\ttraining's l2: 0.256897\tvalid_1's l2: 0.280956\n",
      "[2200]\ttraining's l2: 0.25632\tvalid_1's l2: 0.280963\n",
      "[2250]\ttraining's l2: 0.255731\tvalid_1's l2: 0.280964\n",
      "Early stopping, best iteration is:\n",
      "[2152]\ttraining's l2: 0.256877\tvalid_1's l2: 0.280954\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61194\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (253.05 MB) transferred to GPU in 0.388740 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.970001\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.418642\tvalid_1's l2: 0.414244\n",
      "[100]\ttraining's l2: 0.337904\tvalid_1's l2: 0.339094\n",
      "[150]\ttraining's l2: 0.322545\tvalid_1's l2: 0.326366\n",
      "[200]\ttraining's l2: 0.316834\tvalid_1's l2: 0.322319\n",
      "[250]\ttraining's l2: 0.3132\tvalid_1's l2: 0.31995\n",
      "[300]\ttraining's l2: 0.310559\tvalid_1's l2: 0.318291\n",
      "[350]\ttraining's l2: 0.308497\tvalid_1's l2: 0.317235\n",
      "[400]\ttraining's l2: 0.306757\tvalid_1's l2: 0.316527\n",
      "[450]\ttraining's l2: 0.305202\tvalid_1's l2: 0.315836\n",
      "[500]\ttraining's l2: 0.303838\tvalid_1's l2: 0.315449\n",
      "[550]\ttraining's l2: 0.302544\tvalid_1's l2: 0.315115\n",
      "[600]\ttraining's l2: 0.301339\tvalid_1's l2: 0.314826\n",
      "[650]\ttraining's l2: 0.300197\tvalid_1's l2: 0.31462\n",
      "[700]\ttraining's l2: 0.29915\tvalid_1's l2: 0.314508\n",
      "[750]\ttraining's l2: 0.298134\tvalid_1's l2: 0.314399\n",
      "[800]\ttraining's l2: 0.297174\tvalid_1's l2: 0.314262\n",
      "[850]\ttraining's l2: 0.296226\tvalid_1's l2: 0.314139\n",
      "[900]\ttraining's l2: 0.295286\tvalid_1's l2: 0.31402\n",
      "[950]\ttraining's l2: 0.294411\tvalid_1's l2: 0.313932\n",
      "[1000]\ttraining's l2: 0.293541\tvalid_1's l2: 0.313891\n",
      "[1050]\ttraining's l2: 0.292678\tvalid_1's l2: 0.313821\n",
      "[1100]\ttraining's l2: 0.291868\tvalid_1's l2: 0.313773\n",
      "[1150]\ttraining's l2: 0.291082\tvalid_1's l2: 0.313704\n",
      "[1200]\ttraining's l2: 0.290271\tvalid_1's l2: 0.313653\n",
      "[1250]\ttraining's l2: 0.289481\tvalid_1's l2: 0.313616\n",
      "[1300]\ttraining's l2: 0.288706\tvalid_1's l2: 0.313543\n",
      "[1350]\ttraining's l2: 0.287952\tvalid_1's l2: 0.313523\n",
      "[1400]\ttraining's l2: 0.28719\tvalid_1's l2: 0.313499\n",
      "[1450]\ttraining's l2: 0.286432\tvalid_1's l2: 0.313485\n",
      "[1500]\ttraining's l2: 0.285712\tvalid_1's l2: 0.313469\n",
      "[1550]\ttraining's l2: 0.284982\tvalid_1's l2: 0.31342\n",
      "[1600]\ttraining's l2: 0.284298\tvalid_1's l2: 0.313414\n",
      "[1650]\ttraining's l2: 0.283621\tvalid_1's l2: 0.313422\n",
      "[1700]\ttraining's l2: 0.282906\tvalid_1's l2: 0.313387\n",
      "[1750]\ttraining's l2: 0.282189\tvalid_1's l2: 0.313369\n",
      "[1800]\ttraining's l2: 0.281515\tvalid_1's l2: 0.31332\n",
      "[1850]\ttraining's l2: 0.280846\tvalid_1's l2: 0.313315\n",
      "[1900]\ttraining's l2: 0.280195\tvalid_1's l2: 0.313298\n",
      "[1950]\ttraining's l2: 0.279499\tvalid_1's l2: 0.313273\n",
      "[2000]\ttraining's l2: 0.278853\tvalid_1's l2: 0.313268\n",
      "[2050]\ttraining's l2: 0.278212\tvalid_1's l2: 0.313249\n",
      "[2100]\ttraining's l2: 0.277568\tvalid_1's l2: 0.313205\n",
      "[2150]\ttraining's l2: 0.276919\tvalid_1's l2: 0.313179\n",
      "[2200]\ttraining's l2: 0.276299\tvalid_1's l2: 0.313157\n",
      "[2250]\ttraining's l2: 0.275661\tvalid_1's l2: 0.313135\n",
      "[2300]\ttraining's l2: 0.275026\tvalid_1's l2: 0.313093\n",
      "[2350]\ttraining's l2: 0.274398\tvalid_1's l2: 0.313098\n",
      "[2400]\ttraining's l2: 0.273788\tvalid_1's l2: 0.313071\n",
      "[2450]\ttraining's l2: 0.273163\tvalid_1's l2: 0.313061\n",
      "[2500]\ttraining's l2: 0.272541\tvalid_1's l2: 0.313032\n",
      "[2550]\ttraining's l2: 0.271934\tvalid_1's l2: 0.313024\n",
      "[2600]\ttraining's l2: 0.271359\tvalid_1's l2: 0.313032\n",
      "[2650]\ttraining's l2: 0.27078\tvalid_1's l2: 0.313019\n",
      "Early stopping, best iteration is:\n",
      "[2545]\ttraining's l2: 0.271994\tvalid_1's l2: 0.313017\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60317\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (245.38 MB) transferred to GPU in 0.386984 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.057661\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.442386\tvalid_1's l2: 0.449604\n",
      "[100]\ttraining's l2: 0.344295\tvalid_1's l2: 0.355339\n",
      "[150]\ttraining's l2: 0.325479\tvalid_1's l2: 0.339455\n",
      "[200]\ttraining's l2: 0.318451\tvalid_1's l2: 0.335076\n",
      "[250]\ttraining's l2: 0.314019\tvalid_1's l2: 0.332957\n",
      "[300]\ttraining's l2: 0.311032\tvalid_1's l2: 0.331733\n",
      "[350]\ttraining's l2: 0.308595\tvalid_1's l2: 0.330869\n",
      "[400]\ttraining's l2: 0.306621\tvalid_1's l2: 0.330112\n",
      "[450]\ttraining's l2: 0.304828\tvalid_1's l2: 0.329549\n",
      "[500]\ttraining's l2: 0.303203\tvalid_1's l2: 0.329101\n",
      "[550]\ttraining's l2: 0.301774\tvalid_1's l2: 0.328794\n",
      "[600]\ttraining's l2: 0.300438\tvalid_1's l2: 0.328473\n",
      "[650]\ttraining's l2: 0.29918\tvalid_1's l2: 0.328207\n",
      "[700]\ttraining's l2: 0.29803\tvalid_1's l2: 0.327961\n",
      "[750]\ttraining's l2: 0.296929\tvalid_1's l2: 0.327757\n",
      "[800]\ttraining's l2: 0.295891\tvalid_1's l2: 0.32758\n",
      "[850]\ttraining's l2: 0.294906\tvalid_1's l2: 0.327476\n",
      "[900]\ttraining's l2: 0.293973\tvalid_1's l2: 0.327395\n",
      "[950]\ttraining's l2: 0.29306\tvalid_1's l2: 0.327315\n",
      "[1000]\ttraining's l2: 0.292153\tvalid_1's l2: 0.327204\n",
      "[1050]\ttraining's l2: 0.291295\tvalid_1's l2: 0.327117\n",
      "[1100]\ttraining's l2: 0.29042\tvalid_1's l2: 0.327036\n",
      "[1150]\ttraining's l2: 0.289592\tvalid_1's l2: 0.327031\n",
      "[1200]\ttraining's l2: 0.288789\tvalid_1's l2: 0.32696\n",
      "[1250]\ttraining's l2: 0.287953\tvalid_1's l2: 0.326908\n",
      "[1300]\ttraining's l2: 0.287158\tvalid_1's l2: 0.326834\n",
      "[1350]\ttraining's l2: 0.286363\tvalid_1's l2: 0.326719\n",
      "[1400]\ttraining's l2: 0.285599\tvalid_1's l2: 0.326673\n",
      "[1450]\ttraining's l2: 0.284851\tvalid_1's l2: 0.326618\n",
      "[1500]\ttraining's l2: 0.284133\tvalid_1's l2: 0.326574\n",
      "[1550]\ttraining's l2: 0.283408\tvalid_1's l2: 0.326538\n",
      "[1600]\ttraining's l2: 0.282675\tvalid_1's l2: 0.326522\n",
      "[1650]\ttraining's l2: 0.281976\tvalid_1's l2: 0.326498\n",
      "[1700]\ttraining's l2: 0.281266\tvalid_1's l2: 0.326409\n",
      "[1750]\ttraining's l2: 0.28057\tvalid_1's l2: 0.326373\n",
      "[1800]\ttraining's l2: 0.27989\tvalid_1's l2: 0.326335\n",
      "[1850]\ttraining's l2: 0.279199\tvalid_1's l2: 0.3263\n",
      "[1900]\ttraining's l2: 0.278529\tvalid_1's l2: 0.32628\n",
      "[1950]\ttraining's l2: 0.277851\tvalid_1's l2: 0.326287\n",
      "[2000]\ttraining's l2: 0.277171\tvalid_1's l2: 0.326284\n",
      "[2050]\ttraining's l2: 0.276533\tvalid_1's l2: 0.326261\n",
      "[2100]\ttraining's l2: 0.275887\tvalid_1's l2: 0.326221\n",
      "[2150]\ttraining's l2: 0.275271\tvalid_1's l2: 0.326223\n",
      "[2200]\ttraining's l2: 0.274669\tvalid_1's l2: 0.326229\n",
      "[2250]\ttraining's l2: 0.274025\tvalid_1's l2: 0.3262\n",
      "[2300]\ttraining's l2: 0.273429\tvalid_1's l2: 0.32618\n",
      "[2350]\ttraining's l2: 0.272821\tvalid_1's l2: 0.326166\n",
      "[2400]\ttraining's l2: 0.272224\tvalid_1's l2: 0.326195\n",
      "[2450]\ttraining's l2: 0.271628\tvalid_1's l2: 0.326194\n",
      "Early stopping, best iteration is:\n",
      "[2356]\ttraining's l2: 0.272749\tvalid_1's l2: 0.32616\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60339\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (249.22 MB) transferred to GPU in 0.377668 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.247589\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.479118\tvalid_1's l2: 0.468467\n",
      "[100]\ttraining's l2: 0.367152\tvalid_1's l2: 0.367908\n",
      "[150]\ttraining's l2: 0.345871\tvalid_1's l2: 0.353002\n",
      "[200]\ttraining's l2: 0.338308\tvalid_1's l2: 0.348989\n",
      "[250]\ttraining's l2: 0.333537\tvalid_1's l2: 0.346919\n",
      "[300]\ttraining's l2: 0.329923\tvalid_1's l2: 0.345295\n",
      "[350]\ttraining's l2: 0.327195\tvalid_1's l2: 0.344602\n",
      "[400]\ttraining's l2: 0.324693\tvalid_1's l2: 0.343552\n",
      "[450]\ttraining's l2: 0.322682\tvalid_1's l2: 0.343084\n",
      "[500]\ttraining's l2: 0.320848\tvalid_1's l2: 0.342668\n",
      "[550]\ttraining's l2: 0.31914\tvalid_1's l2: 0.342285\n",
      "[600]\ttraining's l2: 0.317634\tvalid_1's l2: 0.341954\n",
      "[650]\ttraining's l2: 0.316264\tvalid_1's l2: 0.341696\n",
      "[700]\ttraining's l2: 0.314929\tvalid_1's l2: 0.341408\n",
      "[750]\ttraining's l2: 0.313721\tvalid_1's l2: 0.341197\n",
      "[800]\ttraining's l2: 0.312576\tvalid_1's l2: 0.34107\n",
      "[850]\ttraining's l2: 0.3115\tvalid_1's l2: 0.340912\n",
      "[900]\ttraining's l2: 0.310456\tvalid_1's l2: 0.340798\n",
      "[950]\ttraining's l2: 0.309428\tvalid_1's l2: 0.340648\n",
      "[1000]\ttraining's l2: 0.308438\tvalid_1's l2: 0.340515\n",
      "[1050]\ttraining's l2: 0.307483\tvalid_1's l2: 0.340374\n",
      "[1100]\ttraining's l2: 0.306515\tvalid_1's l2: 0.340279\n",
      "[1150]\ttraining's l2: 0.305623\tvalid_1's l2: 0.340205\n",
      "[1200]\ttraining's l2: 0.304728\tvalid_1's l2: 0.340145\n",
      "[1250]\ttraining's l2: 0.303868\tvalid_1's l2: 0.34007\n",
      "[1300]\ttraining's l2: 0.303027\tvalid_1's l2: 0.339976\n",
      "[1350]\ttraining's l2: 0.302219\tvalid_1's l2: 0.339978\n",
      "[1400]\ttraining's l2: 0.301407\tvalid_1's l2: 0.339965\n",
      "[1450]\ttraining's l2: 0.300622\tvalid_1's l2: 0.33992\n",
      "[1500]\ttraining's l2: 0.299838\tvalid_1's l2: 0.339871\n",
      "[1550]\ttraining's l2: 0.299053\tvalid_1's l2: 0.339789\n",
      "[1600]\ttraining's l2: 0.298299\tvalid_1's l2: 0.339776\n",
      "[1650]\ttraining's l2: 0.297581\tvalid_1's l2: 0.339777\n",
      "[1700]\ttraining's l2: 0.296814\tvalid_1's l2: 0.339737\n",
      "[1750]\ttraining's l2: 0.296084\tvalid_1's l2: 0.339701\n",
      "[1800]\ttraining's l2: 0.29537\tvalid_1's l2: 0.339703\n",
      "[1850]\ttraining's l2: 0.294624\tvalid_1's l2: 0.339652\n",
      "[1900]\ttraining's l2: 0.293923\tvalid_1's l2: 0.339618\n",
      "[1950]\ttraining's l2: 0.293219\tvalid_1's l2: 0.339608\n",
      "[2000]\ttraining's l2: 0.292539\tvalid_1's l2: 0.339593\n",
      "[2050]\ttraining's l2: 0.291841\tvalid_1's l2: 0.339595\n",
      "[2100]\ttraining's l2: 0.291156\tvalid_1's l2: 0.339564\n",
      "[2150]\ttraining's l2: 0.290492\tvalid_1's l2: 0.339578\n",
      "[2200]\ttraining's l2: 0.289835\tvalid_1's l2: 0.339531\n",
      "[2250]\ttraining's l2: 0.289171\tvalid_1's l2: 0.33949\n",
      "[2300]\ttraining's l2: 0.288529\tvalid_1's l2: 0.339476\n",
      "[2350]\ttraining's l2: 0.287902\tvalid_1's l2: 0.339464\n",
      "[2400]\ttraining's l2: 0.287257\tvalid_1's l2: 0.339448\n",
      "[2450]\ttraining's l2: 0.286635\tvalid_1's l2: 0.339458\n",
      "[2500]\ttraining's l2: 0.286001\tvalid_1's l2: 0.339486\n",
      "Early stopping, best iteration is:\n",
      "[2411]\ttraining's l2: 0.287123\tvalid_1's l2: 0.339442\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61847\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 256 dense feature groups (245.38 MB) transferred to GPU in 0.374274 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.278463\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.499933\tvalid_1's l2: 0.481708\n",
      "[100]\ttraining's l2: 0.379198\tvalid_1's l2: 0.37276\n",
      "[150]\ttraining's l2: 0.355516\tvalid_1's l2: 0.35598\n",
      "[200]\ttraining's l2: 0.346266\tvalid_1's l2: 0.351438\n",
      "[250]\ttraining's l2: 0.340291\tvalid_1's l2: 0.348776\n",
      "[300]\ttraining's l2: 0.335921\tvalid_1's l2: 0.347103\n",
      "[350]\ttraining's l2: 0.332405\tvalid_1's l2: 0.345768\n",
      "[400]\ttraining's l2: 0.329641\tvalid_1's l2: 0.344962\n",
      "[450]\ttraining's l2: 0.327286\tvalid_1's l2: 0.344337\n",
      "[500]\ttraining's l2: 0.325134\tvalid_1's l2: 0.34387\n",
      "[550]\ttraining's l2: 0.323195\tvalid_1's l2: 0.343319\n",
      "[600]\ttraining's l2: 0.321496\tvalid_1's l2: 0.34296\n",
      "[650]\ttraining's l2: 0.319905\tvalid_1's l2: 0.342669\n",
      "[700]\ttraining's l2: 0.318406\tvalid_1's l2: 0.342318\n",
      "[750]\ttraining's l2: 0.317056\tvalid_1's l2: 0.342107\n",
      "[800]\ttraining's l2: 0.315767\tvalid_1's l2: 0.341871\n",
      "[850]\ttraining's l2: 0.314541\tvalid_1's l2: 0.341725\n",
      "[900]\ttraining's l2: 0.3134\tvalid_1's l2: 0.34163\n",
      "[950]\ttraining's l2: 0.312273\tvalid_1's l2: 0.341476\n",
      "[1000]\ttraining's l2: 0.311213\tvalid_1's l2: 0.341369\n",
      "[1050]\ttraining's l2: 0.31015\tvalid_1's l2: 0.34127\n",
      "[1100]\ttraining's l2: 0.309157\tvalid_1's l2: 0.341203\n",
      "[1150]\ttraining's l2: 0.308161\tvalid_1's l2: 0.341092\n",
      "[1200]\ttraining's l2: 0.307202\tvalid_1's l2: 0.340968\n",
      "[1250]\ttraining's l2: 0.306261\tvalid_1's l2: 0.34093\n",
      "[1300]\ttraining's l2: 0.30531\tvalid_1's l2: 0.340853\n",
      "[1350]\ttraining's l2: 0.304411\tvalid_1's l2: 0.340744\n",
      "[1400]\ttraining's l2: 0.303555\tvalid_1's l2: 0.340672\n",
      "[1450]\ttraining's l2: 0.30273\tvalid_1's l2: 0.340601\n",
      "[1500]\ttraining's l2: 0.301893\tvalid_1's l2: 0.340574\n",
      "[1550]\ttraining's l2: 0.30105\tvalid_1's l2: 0.340517\n",
      "[1600]\ttraining's l2: 0.300202\tvalid_1's l2: 0.340483\n",
      "[1650]\ttraining's l2: 0.299391\tvalid_1's l2: 0.340472\n",
      "[1700]\ttraining's l2: 0.298616\tvalid_1's l2: 0.340406\n",
      "[1750]\ttraining's l2: 0.297856\tvalid_1's l2: 0.340356\n",
      "[1800]\ttraining's l2: 0.297096\tvalid_1's l2: 0.340331\n",
      "[1850]\ttraining's l2: 0.296309\tvalid_1's l2: 0.340316\n",
      "[1900]\ttraining's l2: 0.295548\tvalid_1's l2: 0.340293\n",
      "[1950]\ttraining's l2: 0.294791\tvalid_1's l2: 0.34028\n",
      "[2000]\ttraining's l2: 0.294043\tvalid_1's l2: 0.340255\n",
      "[2050]\ttraining's l2: 0.293333\tvalid_1's l2: 0.340245\n",
      "[2100]\ttraining's l2: 0.29261\tvalid_1's l2: 0.340215\n",
      "[2150]\ttraining's l2: 0.291906\tvalid_1's l2: 0.340182\n",
      "[2200]\ttraining's l2: 0.291204\tvalid_1's l2: 0.340126\n",
      "[2250]\ttraining's l2: 0.29051\tvalid_1's l2: 0.340108\n",
      "[2300]\ttraining's l2: 0.289835\tvalid_1's l2: 0.340105\n",
      "[2350]\ttraining's l2: 0.289165\tvalid_1's l2: 0.340075\n",
      "[2400]\ttraining's l2: 0.288463\tvalid_1's l2: 0.340095\n",
      "[2450]\ttraining's l2: 0.2878\tvalid_1's l2: 0.340059\n",
      "[2500]\ttraining's l2: 0.287183\tvalid_1's l2: 0.340039\n",
      "[2550]\ttraining's l2: 0.286522\tvalid_1's l2: 0.340033\n",
      "[2600]\ttraining's l2: 0.285874\tvalid_1's l2: 0.340008\n",
      "[2650]\ttraining's l2: 0.285228\tvalid_1's l2: 0.339986\n",
      "[2700]\ttraining's l2: 0.284597\tvalid_1's l2: 0.34002\n",
      "[2750]\ttraining's l2: 0.283959\tvalid_1's l2: 0.339986\n",
      "[2800]\ttraining's l2: 0.283316\tvalid_1's l2: 0.339959\n",
      "[2850]\ttraining's l2: 0.282685\tvalid_1's l2: 0.339933\n",
      "[2900]\ttraining's l2: 0.282043\tvalid_1's l2: 0.339927\n",
      "[2950]\ttraining's l2: 0.281414\tvalid_1's l2: 0.339944\n",
      "[3000]\ttraining's l2: 0.280799\tvalid_1's l2: 0.33992\n",
      "[3050]\ttraining's l2: 0.280218\tvalid_1's l2: 0.339909\n",
      "[3100]\ttraining's l2: 0.279635\tvalid_1's l2: 0.339896\n",
      "[3150]\ttraining's l2: 0.279045\tvalid_1's l2: 0.339906\n",
      "[3200]\ttraining's l2: 0.278451\tvalid_1's l2: 0.339897\n",
      "[3250]\ttraining's l2: 0.277847\tvalid_1's l2: 0.339873\n",
      "[3300]\ttraining's l2: 0.277268\tvalid_1's l2: 0.33985\n",
      "[3350]\ttraining's l2: 0.276686\tvalid_1's l2: 0.339819\n",
      "[3400]\ttraining's l2: 0.276101\tvalid_1's l2: 0.339825\n",
      "[3450]\ttraining's l2: 0.275511\tvalid_1's l2: 0.339851\n",
      "[3500]\ttraining's l2: 0.274926\tvalid_1's l2: 0.339854\n",
      "Early stopping, best iteration is:\n",
      "[3394]\ttraining's l2: 0.276175\tvalid_1's l2: 0.339818\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62406\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (249.22 MB) transferred to GPU in 0.352792 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.068941\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.463051\tvalid_1's l2: 0.479799\n",
      "[100]\ttraining's l2: 0.368481\tvalid_1's l2: 0.37952\n",
      "[150]\ttraining's l2: 0.350457\tvalid_1's l2: 0.361257\n",
      "[200]\ttraining's l2: 0.34342\tvalid_1's l2: 0.355527\n",
      "[250]\ttraining's l2: 0.338807\tvalid_1's l2: 0.352419\n",
      "[300]\ttraining's l2: 0.335639\tvalid_1's l2: 0.350866\n",
      "[350]\ttraining's l2: 0.333118\tvalid_1's l2: 0.349993\n",
      "[400]\ttraining's l2: 0.330994\tvalid_1's l2: 0.349171\n",
      "[450]\ttraining's l2: 0.329028\tvalid_1's l2: 0.348763\n",
      "[500]\ttraining's l2: 0.327286\tvalid_1's l2: 0.348304\n",
      "[550]\ttraining's l2: 0.325706\tvalid_1's l2: 0.348\n",
      "[600]\ttraining's l2: 0.324283\tvalid_1's l2: 0.347774\n",
      "[650]\ttraining's l2: 0.322932\tvalid_1's l2: 0.347562\n",
      "[700]\ttraining's l2: 0.321665\tvalid_1's l2: 0.347358\n",
      "[750]\ttraining's l2: 0.320473\tvalid_1's l2: 0.347286\n",
      "[800]\ttraining's l2: 0.319335\tvalid_1's l2: 0.347127\n",
      "[850]\ttraining's l2: 0.318244\tvalid_1's l2: 0.347001\n",
      "[900]\ttraining's l2: 0.317168\tvalid_1's l2: 0.346899\n",
      "[950]\ttraining's l2: 0.31616\tvalid_1's l2: 0.346864\n",
      "[1000]\ttraining's l2: 0.315161\tvalid_1's l2: 0.346789\n",
      "[1050]\ttraining's l2: 0.314208\tvalid_1's l2: 0.346684\n",
      "[1100]\ttraining's l2: 0.31329\tvalid_1's l2: 0.346615\n",
      "[1150]\ttraining's l2: 0.312362\tvalid_1's l2: 0.346572\n",
      "[1200]\ttraining's l2: 0.311469\tvalid_1's l2: 0.346497\n",
      "[1250]\ttraining's l2: 0.31059\tvalid_1's l2: 0.346464\n",
      "[1300]\ttraining's l2: 0.309702\tvalid_1's l2: 0.346432\n",
      "[1350]\ttraining's l2: 0.308854\tvalid_1's l2: 0.346396\n",
      "[1400]\ttraining's l2: 0.308026\tvalid_1's l2: 0.346379\n",
      "[1450]\ttraining's l2: 0.307209\tvalid_1's l2: 0.346309\n",
      "[1500]\ttraining's l2: 0.306406\tvalid_1's l2: 0.346312\n",
      "[1550]\ttraining's l2: 0.305601\tvalid_1's l2: 0.346306\n",
      "[1600]\ttraining's l2: 0.30481\tvalid_1's l2: 0.346299\n",
      "Early stopping, best iteration is:\n",
      "[1483]\ttraining's l2: 0.306677\tvalid_1's l2: 0.346288\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61746\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (253.05 MB) transferred to GPU in 0.385053 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.025676\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.449647\tvalid_1's l2: 0.554662\n",
      "[100]\ttraining's l2: 0.358074\tvalid_1's l2: 0.443447\n",
      "[150]\ttraining's l2: 0.340279\tvalid_1's l2: 0.420103\n",
      "[200]\ttraining's l2: 0.33326\tvalid_1's l2: 0.413333\n",
      "[250]\ttraining's l2: 0.328652\tvalid_1's l2: 0.410223\n",
      "[300]\ttraining's l2: 0.3255\tvalid_1's l2: 0.408395\n",
      "[350]\ttraining's l2: 0.322899\tvalid_1's l2: 0.407302\n",
      "[400]\ttraining's l2: 0.320754\tvalid_1's l2: 0.406254\n",
      "[450]\ttraining's l2: 0.318981\tvalid_1's l2: 0.405624\n",
      "[500]\ttraining's l2: 0.317387\tvalid_1's l2: 0.405228\n",
      "[550]\ttraining's l2: 0.315938\tvalid_1's l2: 0.404875\n",
      "[600]\ttraining's l2: 0.314607\tvalid_1's l2: 0.404675\n",
      "[650]\ttraining's l2: 0.31333\tvalid_1's l2: 0.404545\n",
      "[700]\ttraining's l2: 0.312169\tvalid_1's l2: 0.404298\n",
      "[750]\ttraining's l2: 0.311041\tvalid_1's l2: 0.404264\n",
      "[800]\ttraining's l2: 0.309972\tvalid_1's l2: 0.404054\n",
      "[850]\ttraining's l2: 0.308952\tvalid_1's l2: 0.403989\n",
      "[900]\ttraining's l2: 0.307981\tvalid_1's l2: 0.403933\n",
      "[950]\ttraining's l2: 0.307003\tvalid_1's l2: 0.403917\n",
      "[1000]\ttraining's l2: 0.306071\tvalid_1's l2: 0.403759\n",
      "[1050]\ttraining's l2: 0.305136\tvalid_1's l2: 0.40377\n",
      "[1100]\ttraining's l2: 0.304254\tvalid_1's l2: 0.403728\n",
      "[1150]\ttraining's l2: 0.30337\tvalid_1's l2: 0.403662\n",
      "[1200]\ttraining's l2: 0.302512\tvalid_1's l2: 0.403627\n",
      "[1250]\ttraining's l2: 0.301681\tvalid_1's l2: 0.403587\n",
      "[1300]\ttraining's l2: 0.300874\tvalid_1's l2: 0.403591\n",
      "[1350]\ttraining's l2: 0.300079\tvalid_1's l2: 0.40357\n",
      "[1400]\ttraining's l2: 0.299258\tvalid_1's l2: 0.403593\n",
      "[1450]\ttraining's l2: 0.298486\tvalid_1's l2: 0.403435\n",
      "[1500]\ttraining's l2: 0.2977\tvalid_1's l2: 0.403461\n",
      "[1550]\ttraining's l2: 0.296928\tvalid_1's l2: 0.403399\n",
      "[1600]\ttraining's l2: 0.296192\tvalid_1's l2: 0.403362\n",
      "[1650]\ttraining's l2: 0.295453\tvalid_1's l2: 0.403365\n",
      "[1700]\ttraining's l2: 0.294711\tvalid_1's l2: 0.40331\n",
      "[1750]\ttraining's l2: 0.293974\tvalid_1's l2: 0.403217\n",
      "[1800]\ttraining's l2: 0.293252\tvalid_1's l2: 0.403181\n",
      "[1850]\ttraining's l2: 0.292549\tvalid_1's l2: 0.403147\n",
      "[1900]\ttraining's l2: 0.291857\tvalid_1's l2: 0.403089\n",
      "[1950]\ttraining's l2: 0.29115\tvalid_1's l2: 0.403047\n",
      "[2000]\ttraining's l2: 0.290462\tvalid_1's l2: 0.402994\n",
      "[2050]\ttraining's l2: 0.289767\tvalid_1's l2: 0.402958\n",
      "[2100]\ttraining's l2: 0.289094\tvalid_1's l2: 0.402978\n",
      "[2150]\ttraining's l2: 0.288426\tvalid_1's l2: 0.402955\n",
      "[2200]\ttraining's l2: 0.28775\tvalid_1's l2: 0.402948\n",
      "Early stopping, best iteration is:\n",
      "[2078]\ttraining's l2: 0.289396\tvalid_1's l2: 0.402924\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 58023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (241.55 MB) transferred to GPU in 0.390157 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.026112\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.442232\tvalid_1's l2: 0.521091\n",
      "[100]\ttraining's l2: 0.344915\tvalid_1's l2: 0.407558\n",
      "[150]\ttraining's l2: 0.326594\tvalid_1's l2: 0.383866\n",
      "[200]\ttraining's l2: 0.319927\tvalid_1's l2: 0.376072\n",
      "[250]\ttraining's l2: 0.315495\tvalid_1's l2: 0.371863\n",
      "[300]\ttraining's l2: 0.312439\tvalid_1's l2: 0.370116\n",
      "[350]\ttraining's l2: 0.310025\tvalid_1's l2: 0.369015\n",
      "[400]\ttraining's l2: 0.307921\tvalid_1's l2: 0.368345\n",
      "[450]\ttraining's l2: 0.306088\tvalid_1's l2: 0.367899\n",
      "[500]\ttraining's l2: 0.304489\tvalid_1's l2: 0.367474\n",
      "[550]\ttraining's l2: 0.303036\tvalid_1's l2: 0.367072\n",
      "[600]\ttraining's l2: 0.301691\tvalid_1's l2: 0.366877\n",
      "[650]\ttraining's l2: 0.300447\tvalid_1's l2: 0.366626\n",
      "[700]\ttraining's l2: 0.299308\tvalid_1's l2: 0.36652\n",
      "[750]\ttraining's l2: 0.298191\tvalid_1's l2: 0.366345\n",
      "[800]\ttraining's l2: 0.29711\tvalid_1's l2: 0.366234\n",
      "[850]\ttraining's l2: 0.29607\tvalid_1's l2: 0.366108\n",
      "[900]\ttraining's l2: 0.295091\tvalid_1's l2: 0.36604\n",
      "[950]\ttraining's l2: 0.294171\tvalid_1's l2: 0.366035\n",
      "[1000]\ttraining's l2: 0.293264\tvalid_1's l2: 0.366036\n",
      "[1050]\ttraining's l2: 0.292342\tvalid_1's l2: 0.365909\n",
      "[1100]\ttraining's l2: 0.291511\tvalid_1's l2: 0.365898\n",
      "[1150]\ttraining's l2: 0.290691\tvalid_1's l2: 0.365817\n",
      "[1200]\ttraining's l2: 0.28989\tvalid_1's l2: 0.365784\n",
      "[1250]\ttraining's l2: 0.289123\tvalid_1's l2: 0.365707\n",
      "[1300]\ttraining's l2: 0.288337\tvalid_1's l2: 0.36568\n",
      "[1350]\ttraining's l2: 0.287581\tvalid_1's l2: 0.365595\n",
      "[1400]\ttraining's l2: 0.286821\tvalid_1's l2: 0.36556\n",
      "[1450]\ttraining's l2: 0.286084\tvalid_1's l2: 0.36561\n",
      "[1500]\ttraining's l2: 0.285363\tvalid_1's l2: 0.365531\n",
      "[1550]\ttraining's l2: 0.284668\tvalid_1's l2: 0.365488\n",
      "[1600]\ttraining's l2: 0.283957\tvalid_1's l2: 0.365439\n",
      "[1650]\ttraining's l2: 0.283269\tvalid_1's l2: 0.36538\n",
      "[1700]\ttraining's l2: 0.28258\tvalid_1's l2: 0.365395\n",
      "[1750]\ttraining's l2: 0.281916\tvalid_1's l2: 0.365357\n",
      "[1800]\ttraining's l2: 0.281255\tvalid_1's l2: 0.365313\n",
      "[1850]\ttraining's l2: 0.280592\tvalid_1's l2: 0.365271\n",
      "[1900]\ttraining's l2: 0.279956\tvalid_1's l2: 0.365269\n",
      "[1950]\ttraining's l2: 0.279291\tvalid_1's l2: 0.365304\n",
      "[2000]\ttraining's l2: 0.278637\tvalid_1's l2: 0.365314\n",
      "Early stopping, best iteration is:\n",
      "[1896]\ttraining's l2: 0.280001\tvalid_1's l2: 0.365261\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61052\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 261 dense feature groups (253.05 MB) transferred to GPU in 0.361289 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.946872\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.432807\tvalid_1's l2: 0.481919\n",
      "[100]\ttraining's l2: 0.352956\tvalid_1's l2: 0.393153\n",
      "[150]\ttraining's l2: 0.336543\tvalid_1's l2: 0.375036\n",
      "[200]\ttraining's l2: 0.329933\tvalid_1's l2: 0.3695\n",
      "[250]\ttraining's l2: 0.32565\tvalid_1's l2: 0.36732\n",
      "[300]\ttraining's l2: 0.322544\tvalid_1's l2: 0.366053\n",
      "[350]\ttraining's l2: 0.320226\tvalid_1's l2: 0.365352\n",
      "[400]\ttraining's l2: 0.318316\tvalid_1's l2: 0.364857\n",
      "[450]\ttraining's l2: 0.316685\tvalid_1's l2: 0.364598\n",
      "[500]\ttraining's l2: 0.31515\tvalid_1's l2: 0.364294\n",
      "[550]\ttraining's l2: 0.313762\tvalid_1's l2: 0.364097\n",
      "[600]\ttraining's l2: 0.312459\tvalid_1's l2: 0.363965\n",
      "[650]\ttraining's l2: 0.311232\tvalid_1's l2: 0.363787\n",
      "[700]\ttraining's l2: 0.310095\tvalid_1's l2: 0.363715\n",
      "[750]\ttraining's l2: 0.309016\tvalid_1's l2: 0.363638\n",
      "[800]\ttraining's l2: 0.307966\tvalid_1's l2: 0.363518\n",
      "[850]\ttraining's l2: 0.306976\tvalid_1's l2: 0.363478\n",
      "[900]\ttraining's l2: 0.306004\tvalid_1's l2: 0.363406\n",
      "[950]\ttraining's l2: 0.305063\tvalid_1's l2: 0.363369\n",
      "[1000]\ttraining's l2: 0.304155\tvalid_1's l2: 0.363344\n",
      "[1050]\ttraining's l2: 0.303273\tvalid_1's l2: 0.363283\n",
      "[1100]\ttraining's l2: 0.302426\tvalid_1's l2: 0.363264\n",
      "[1150]\ttraining's l2: 0.30155\tvalid_1's l2: 0.363254\n",
      "[1200]\ttraining's l2: 0.300707\tvalid_1's l2: 0.363253\n",
      "[1250]\ttraining's l2: 0.299884\tvalid_1's l2: 0.363205\n",
      "[1300]\ttraining's l2: 0.299066\tvalid_1's l2: 0.363176\n",
      "[1350]\ttraining's l2: 0.298278\tvalid_1's l2: 0.363189\n",
      "[1400]\ttraining's l2: 0.297514\tvalid_1's l2: 0.363203\n",
      "Early stopping, best iteration is:\n",
      "[1282]\ttraining's l2: 0.299364\tvalid_1's l2: 0.363169\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59958\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (241.55 MB) transferred to GPU in 0.364050 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.038625\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.454629\tvalid_1's l2: 0.479445\n",
      "[100]\ttraining's l2: 0.359809\tvalid_1's l2: 0.382813\n",
      "[150]\ttraining's l2: 0.340286\tvalid_1's l2: 0.364415\n",
      "[200]\ttraining's l2: 0.332277\tvalid_1's l2: 0.358879\n",
      "[250]\ttraining's l2: 0.326865\tvalid_1's l2: 0.356442\n",
      "[300]\ttraining's l2: 0.323336\tvalid_1's l2: 0.355085\n",
      "[350]\ttraining's l2: 0.320459\tvalid_1's l2: 0.354121\n",
      "[400]\ttraining's l2: 0.318113\tvalid_1's l2: 0.353494\n",
      "[450]\ttraining's l2: 0.316056\tvalid_1's l2: 0.353103\n",
      "[500]\ttraining's l2: 0.314323\tvalid_1's l2: 0.352748\n",
      "[550]\ttraining's l2: 0.31269\tvalid_1's l2: 0.352352\n",
      "[600]\ttraining's l2: 0.311174\tvalid_1's l2: 0.352079\n",
      "[650]\ttraining's l2: 0.309729\tvalid_1's l2: 0.351788\n",
      "[700]\ttraining's l2: 0.308439\tvalid_1's l2: 0.351612\n",
      "[750]\ttraining's l2: 0.307216\tvalid_1's l2: 0.351435\n",
      "[800]\ttraining's l2: 0.306074\tvalid_1's l2: 0.351306\n",
      "[850]\ttraining's l2: 0.304978\tvalid_1's l2: 0.351185\n",
      "[900]\ttraining's l2: 0.303937\tvalid_1's l2: 0.351044\n",
      "[950]\ttraining's l2: 0.30294\tvalid_1's l2: 0.350916\n",
      "[1000]\ttraining's l2: 0.301953\tvalid_1's l2: 0.350838\n",
      "[1050]\ttraining's l2: 0.301029\tvalid_1's l2: 0.350747\n",
      "[1100]\ttraining's l2: 0.300109\tvalid_1's l2: 0.350659\n",
      "[1150]\ttraining's l2: 0.299219\tvalid_1's l2: 0.350631\n",
      "[1200]\ttraining's l2: 0.298332\tvalid_1's l2: 0.350541\n",
      "[1250]\ttraining's l2: 0.297465\tvalid_1's l2: 0.350487\n",
      "[1300]\ttraining's l2: 0.29665\tvalid_1's l2: 0.350452\n",
      "[1350]\ttraining's l2: 0.295818\tvalid_1's l2: 0.350403\n",
      "[1400]\ttraining's l2: 0.295005\tvalid_1's l2: 0.350334\n",
      "[1450]\ttraining's l2: 0.294224\tvalid_1's l2: 0.350289\n",
      "[1500]\ttraining's l2: 0.293458\tvalid_1's l2: 0.350277\n",
      "[1550]\ttraining's l2: 0.292699\tvalid_1's l2: 0.35023\n",
      "[1600]\ttraining's l2: 0.291956\tvalid_1's l2: 0.350193\n",
      "[1650]\ttraining's l2: 0.291195\tvalid_1's l2: 0.350166\n",
      "[1700]\ttraining's l2: 0.290511\tvalid_1's l2: 0.350116\n",
      "[1750]\ttraining's l2: 0.2898\tvalid_1's l2: 0.3501\n",
      "[1800]\ttraining's l2: 0.28909\tvalid_1's l2: 0.350063\n",
      "[1850]\ttraining's l2: 0.288396\tvalid_1's l2: 0.35006\n",
      "[1900]\ttraining's l2: 0.287712\tvalid_1's l2: 0.350044\n",
      "[1950]\ttraining's l2: 0.287039\tvalid_1's l2: 0.350056\n",
      "[2000]\ttraining's l2: 0.28637\tvalid_1's l2: 0.35002\n",
      "[2050]\ttraining's l2: 0.285716\tvalid_1's l2: 0.350004\n",
      "[2100]\ttraining's l2: 0.28509\tvalid_1's l2: 0.34999\n",
      "[2150]\ttraining's l2: 0.284437\tvalid_1's l2: 0.349968\n",
      "[2200]\ttraining's l2: 0.28377\tvalid_1's l2: 0.349981\n",
      "[2250]\ttraining's l2: 0.283144\tvalid_1's l2: 0.34997\n",
      "[2300]\ttraining's l2: 0.28253\tvalid_1's l2: 0.34998\n",
      "[2350]\ttraining's l2: 0.281907\tvalid_1's l2: 0.349967\n",
      "Early stopping, best iteration is:\n",
      "[2232]\ttraining's l2: 0.283368\tvalid_1's l2: 0.349955\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62289\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (256.89 MB) transferred to GPU in 0.349455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.226725\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.49536\tvalid_1's l2: 0.483557\n",
      "[100]\ttraining's l2: 0.388074\tvalid_1's l2: 0.386233\n",
      "[150]\ttraining's l2: 0.36621\tvalid_1's l2: 0.370279\n",
      "[200]\ttraining's l2: 0.357444\tvalid_1's l2: 0.365853\n",
      "[250]\ttraining's l2: 0.351796\tvalid_1's l2: 0.363692\n",
      "[300]\ttraining's l2: 0.347117\tvalid_1's l2: 0.362127\n",
      "[350]\ttraining's l2: 0.343535\tvalid_1's l2: 0.361232\n",
      "[400]\ttraining's l2: 0.340334\tvalid_1's l2: 0.360282\n",
      "[450]\ttraining's l2: 0.337656\tvalid_1's l2: 0.359752\n",
      "[500]\ttraining's l2: 0.335343\tvalid_1's l2: 0.359186\n",
      "[550]\ttraining's l2: 0.333253\tvalid_1's l2: 0.358917\n",
      "[600]\ttraining's l2: 0.331337\tvalid_1's l2: 0.358635\n",
      "[650]\ttraining's l2: 0.329617\tvalid_1's l2: 0.358348\n",
      "[700]\ttraining's l2: 0.328017\tvalid_1's l2: 0.358187\n",
      "[750]\ttraining's l2: 0.326504\tvalid_1's l2: 0.357965\n",
      "[800]\ttraining's l2: 0.32512\tvalid_1's l2: 0.357797\n",
      "[850]\ttraining's l2: 0.323841\tvalid_1's l2: 0.357658\n",
      "[900]\ttraining's l2: 0.322615\tvalid_1's l2: 0.35752\n",
      "[950]\ttraining's l2: 0.321444\tvalid_1's l2: 0.357401\n",
      "[1000]\ttraining's l2: 0.320354\tvalid_1's l2: 0.35733\n",
      "[1050]\ttraining's l2: 0.319264\tvalid_1's l2: 0.357238\n",
      "[1100]\ttraining's l2: 0.318216\tvalid_1's l2: 0.357142\n",
      "[1150]\ttraining's l2: 0.317192\tvalid_1's l2: 0.357085\n",
      "[1200]\ttraining's l2: 0.316214\tvalid_1's l2: 0.357017\n",
      "[1250]\ttraining's l2: 0.315282\tvalid_1's l2: 0.356968\n",
      "[1300]\ttraining's l2: 0.314356\tvalid_1's l2: 0.356904\n",
      "[1350]\ttraining's l2: 0.313441\tvalid_1's l2: 0.356834\n",
      "[1400]\ttraining's l2: 0.312579\tvalid_1's l2: 0.356772\n",
      "[1450]\ttraining's l2: 0.311706\tvalid_1's l2: 0.356702\n",
      "[1500]\ttraining's l2: 0.310866\tvalid_1's l2: 0.356656\n",
      "[1550]\ttraining's l2: 0.309973\tvalid_1's l2: 0.356588\n",
      "[1600]\ttraining's l2: 0.309135\tvalid_1's l2: 0.356562\n",
      "[1650]\ttraining's l2: 0.308338\tvalid_1's l2: 0.356527\n",
      "[1700]\ttraining's l2: 0.307546\tvalid_1's l2: 0.356525\n",
      "[1750]\ttraining's l2: 0.306765\tvalid_1's l2: 0.356452\n",
      "[1800]\ttraining's l2: 0.305999\tvalid_1's l2: 0.356471\n",
      "[1850]\ttraining's l2: 0.305241\tvalid_1's l2: 0.356415\n",
      "[1900]\ttraining's l2: 0.304486\tvalid_1's l2: 0.356427\n",
      "[1950]\ttraining's l2: 0.303702\tvalid_1's l2: 0.356401\n",
      "[2000]\ttraining's l2: 0.302934\tvalid_1's l2: 0.356387\n",
      "[2050]\ttraining's l2: 0.302211\tvalid_1's l2: 0.35642\n",
      "Early stopping, best iteration is:\n",
      "[1964]\ttraining's l2: 0.303491\tvalid_1's l2: 0.35638\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60940\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (241.55 MB) transferred to GPU in 0.339294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.254578\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.515036\tvalid_1's l2: 0.504762\n",
      "[100]\ttraining's l2: 0.397821\tvalid_1's l2: 0.398784\n",
      "[150]\ttraining's l2: 0.373634\tvalid_1's l2: 0.381253\n",
      "[200]\ttraining's l2: 0.363456\tvalid_1's l2: 0.37577\n",
      "[250]\ttraining's l2: 0.356598\tvalid_1's l2: 0.372824\n",
      "[300]\ttraining's l2: 0.351432\tvalid_1's l2: 0.371141\n",
      "[350]\ttraining's l2: 0.347331\tvalid_1's l2: 0.369914\n",
      "[400]\ttraining's l2: 0.344183\tvalid_1's l2: 0.369127\n",
      "[450]\ttraining's l2: 0.341246\tvalid_1's l2: 0.368346\n",
      "[500]\ttraining's l2: 0.338878\tvalid_1's l2: 0.367726\n",
      "[550]\ttraining's l2: 0.336686\tvalid_1's l2: 0.367292\n",
      "[600]\ttraining's l2: 0.334763\tvalid_1's l2: 0.366916\n",
      "[650]\ttraining's l2: 0.332957\tvalid_1's l2: 0.366567\n",
      "[700]\ttraining's l2: 0.33135\tvalid_1's l2: 0.366331\n",
      "[750]\ttraining's l2: 0.329794\tvalid_1's l2: 0.3661\n",
      "[800]\ttraining's l2: 0.328333\tvalid_1's l2: 0.365895\n",
      "[850]\ttraining's l2: 0.326946\tvalid_1's l2: 0.365749\n",
      "[900]\ttraining's l2: 0.325673\tvalid_1's l2: 0.365591\n",
      "[950]\ttraining's l2: 0.324427\tvalid_1's l2: 0.36544\n",
      "[1000]\ttraining's l2: 0.323211\tvalid_1's l2: 0.365324\n",
      "[1050]\ttraining's l2: 0.32206\tvalid_1's l2: 0.365223\n",
      "[1100]\ttraining's l2: 0.320951\tvalid_1's l2: 0.365134\n",
      "[1150]\ttraining's l2: 0.319879\tvalid_1's l2: 0.365035\n",
      "[1200]\ttraining's l2: 0.318872\tvalid_1's l2: 0.364966\n",
      "[1250]\ttraining's l2: 0.317874\tvalid_1's l2: 0.364867\n",
      "[1300]\ttraining's l2: 0.316872\tvalid_1's l2: 0.364815\n",
      "[1350]\ttraining's l2: 0.315906\tvalid_1's l2: 0.364769\n",
      "[1400]\ttraining's l2: 0.31496\tvalid_1's l2: 0.364723\n",
      "[1450]\ttraining's l2: 0.314036\tvalid_1's l2: 0.364678\n",
      "[1500]\ttraining's l2: 0.313122\tvalid_1's l2: 0.364669\n",
      "[1550]\ttraining's l2: 0.312215\tvalid_1's l2: 0.364599\n",
      "[1600]\ttraining's l2: 0.311327\tvalid_1's l2: 0.364594\n",
      "[1650]\ttraining's l2: 0.310476\tvalid_1's l2: 0.364559\n",
      "[1700]\ttraining's l2: 0.309612\tvalid_1's l2: 0.364483\n",
      "[1750]\ttraining's l2: 0.308772\tvalid_1's l2: 0.364448\n",
      "[1800]\ttraining's l2: 0.307945\tvalid_1's l2: 0.364405\n",
      "[1850]\ttraining's l2: 0.307145\tvalid_1's l2: 0.364427\n",
      "Early stopping, best iteration is:\n",
      "[1767]\ttraining's l2: 0.308486\tvalid_1's l2: 0.364392\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62939\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 261 dense feature groups (253.05 MB) transferred to GPU in 0.329194 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.061686\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.474246\tvalid_1's l2: 0.478062\n",
      "[100]\ttraining's l2: 0.380797\tvalid_1's l2: 0.388684\n",
      "[150]\ttraining's l2: 0.362006\tvalid_1's l2: 0.373802\n",
      "[200]\ttraining's l2: 0.3542\tvalid_1's l2: 0.36964\n",
      "[250]\ttraining's l2: 0.349163\tvalid_1's l2: 0.367998\n",
      "[300]\ttraining's l2: 0.345247\tvalid_1's l2: 0.36675\n",
      "[350]\ttraining's l2: 0.342234\tvalid_1's l2: 0.365811\n",
      "[400]\ttraining's l2: 0.339832\tvalid_1's l2: 0.36527\n",
      "[450]\ttraining's l2: 0.337704\tvalid_1's l2: 0.36481\n",
      "[500]\ttraining's l2: 0.335712\tvalid_1's l2: 0.364468\n",
      "[550]\ttraining's l2: 0.333953\tvalid_1's l2: 0.364166\n",
      "[600]\ttraining's l2: 0.33231\tvalid_1's l2: 0.363898\n",
      "[650]\ttraining's l2: 0.330799\tvalid_1's l2: 0.363663\n",
      "[700]\ttraining's l2: 0.329433\tvalid_1's l2: 0.363492\n",
      "[750]\ttraining's l2: 0.328099\tvalid_1's l2: 0.363324\n",
      "[800]\ttraining's l2: 0.326863\tvalid_1's l2: 0.36319\n",
      "[850]\ttraining's l2: 0.325652\tvalid_1's l2: 0.363127\n",
      "[900]\ttraining's l2: 0.324495\tvalid_1's l2: 0.363099\n",
      "[950]\ttraining's l2: 0.323388\tvalid_1's l2: 0.362988\n",
      "[1000]\ttraining's l2: 0.322314\tvalid_1's l2: 0.362979\n",
      "[1050]\ttraining's l2: 0.321263\tvalid_1's l2: 0.362895\n",
      "[1100]\ttraining's l2: 0.320234\tvalid_1's l2: 0.362894\n",
      "[1150]\ttraining's l2: 0.319256\tvalid_1's l2: 0.362885\n",
      "[1200]\ttraining's l2: 0.318327\tvalid_1's l2: 0.36285\n",
      "[1250]\ttraining's l2: 0.317397\tvalid_1's l2: 0.362802\n",
      "[1300]\ttraining's l2: 0.316471\tvalid_1's l2: 0.362791\n",
      "[1350]\ttraining's l2: 0.315589\tvalid_1's l2: 0.362797\n",
      "[1400]\ttraining's l2: 0.314694\tvalid_1's l2: 0.362768\n",
      "[1450]\ttraining's l2: 0.31384\tvalid_1's l2: 0.362775\n",
      "[1500]\ttraining's l2: 0.313009\tvalid_1's l2: 0.362773\n",
      "Early stopping, best iteration is:\n",
      "[1411]\ttraining's l2: 0.314504\tvalid_1's l2: 0.362757\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60681\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (241.55 MB) transferred to GPU in 0.315153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.017916\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.458931\tvalid_1's l2: 0.45591\n",
      "[100]\ttraining's l2: 0.368809\tvalid_1's l2: 0.371906\n",
      "[150]\ttraining's l2: 0.350713\tvalid_1's l2: 0.35848\n",
      "[200]\ttraining's l2: 0.343167\tvalid_1's l2: 0.354876\n",
      "[250]\ttraining's l2: 0.338283\tvalid_1's l2: 0.353464\n",
      "[300]\ttraining's l2: 0.334814\tvalid_1's l2: 0.352495\n",
      "[350]\ttraining's l2: 0.332006\tvalid_1's l2: 0.3519\n",
      "[400]\ttraining's l2: 0.329626\tvalid_1's l2: 0.351364\n",
      "[450]\ttraining's l2: 0.327606\tvalid_1's l2: 0.35108\n",
      "[500]\ttraining's l2: 0.325713\tvalid_1's l2: 0.350784\n",
      "[550]\ttraining's l2: 0.324102\tvalid_1's l2: 0.350595\n",
      "[600]\ttraining's l2: 0.322531\tvalid_1's l2: 0.35038\n",
      "[650]\ttraining's l2: 0.321135\tvalid_1's l2: 0.35033\n",
      "[700]\ttraining's l2: 0.319809\tvalid_1's l2: 0.350164\n",
      "[750]\ttraining's l2: 0.318603\tvalid_1's l2: 0.350099\n",
      "[800]\ttraining's l2: 0.317436\tvalid_1's l2: 0.350013\n",
      "[850]\ttraining's l2: 0.316293\tvalid_1's l2: 0.349887\n",
      "[900]\ttraining's l2: 0.31519\tvalid_1's l2: 0.349833\n",
      "[950]\ttraining's l2: 0.314167\tvalid_1's l2: 0.349781\n",
      "[1000]\ttraining's l2: 0.313152\tvalid_1's l2: 0.349755\n",
      "[1050]\ttraining's l2: 0.312169\tvalid_1's l2: 0.349775\n",
      "[1100]\ttraining's l2: 0.311229\tvalid_1's l2: 0.349713\n",
      "[1150]\ttraining's l2: 0.31028\tvalid_1's l2: 0.349677\n",
      "[1200]\ttraining's l2: 0.309386\tvalid_1's l2: 0.349667\n",
      "[1250]\ttraining's l2: 0.308482\tvalid_1's l2: 0.349673\n",
      "[1300]\ttraining's l2: 0.307628\tvalid_1's l2: 0.349643\n",
      "[1350]\ttraining's l2: 0.306808\tvalid_1's l2: 0.349622\n",
      "[1400]\ttraining's l2: 0.305963\tvalid_1's l2: 0.349608\n",
      "[1450]\ttraining's l2: 0.305137\tvalid_1's l2: 0.349573\n",
      "[1500]\ttraining's l2: 0.304357\tvalid_1's l2: 0.349595\n",
      "[1550]\ttraining's l2: 0.30353\tvalid_1's l2: 0.349604\n",
      "Early stopping, best iteration is:\n",
      "[1452]\ttraining's l2: 0.305104\tvalid_1's l2: 0.349571\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59779\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 247 dense feature groups (237.72 MB) transferred to GPU in 0.310933 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 1.019334\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.453062\tvalid_1's l2: 0.447676\n",
      "[100]\ttraining's l2: 0.357435\tvalid_1's l2: 0.360356\n",
      "[150]\ttraining's l2: 0.338251\tvalid_1's l2: 0.345622\n",
      "[200]\ttraining's l2: 0.330409\tvalid_1's l2: 0.341173\n",
      "[250]\ttraining's l2: 0.325124\tvalid_1's l2: 0.33883\n",
      "[300]\ttraining's l2: 0.321694\tvalid_1's l2: 0.33767\n",
      "[350]\ttraining's l2: 0.318853\tvalid_1's l2: 0.336828\n",
      "[400]\ttraining's l2: 0.316566\tvalid_1's l2: 0.336249\n",
      "[450]\ttraining's l2: 0.314474\tvalid_1's l2: 0.335661\n",
      "[500]\ttraining's l2: 0.312755\tvalid_1's l2: 0.33539\n",
      "[550]\ttraining's l2: 0.311097\tvalid_1's l2: 0.334979\n",
      "[600]\ttraining's l2: 0.309637\tvalid_1's l2: 0.334704\n",
      "[650]\ttraining's l2: 0.30824\tvalid_1's l2: 0.334496\n",
      "[700]\ttraining's l2: 0.306934\tvalid_1's l2: 0.334348\n",
      "[750]\ttraining's l2: 0.305731\tvalid_1's l2: 0.334161\n",
      "[800]\ttraining's l2: 0.304598\tvalid_1's l2: 0.333988\n",
      "[850]\ttraining's l2: 0.303483\tvalid_1's l2: 0.333848\n",
      "[900]\ttraining's l2: 0.302471\tvalid_1's l2: 0.333733\n",
      "[950]\ttraining's l2: 0.301461\tvalid_1's l2: 0.333628\n",
      "[1000]\ttraining's l2: 0.300476\tvalid_1's l2: 0.333545\n",
      "[1050]\ttraining's l2: 0.299519\tvalid_1's l2: 0.333458\n",
      "[1100]\ttraining's l2: 0.298603\tvalid_1's l2: 0.333379\n",
      "[1150]\ttraining's l2: 0.297728\tvalid_1's l2: 0.333325\n",
      "[1200]\ttraining's l2: 0.296878\tvalid_1's l2: 0.333282\n",
      "[1250]\ttraining's l2: 0.29604\tvalid_1's l2: 0.333246\n",
      "[1300]\ttraining's l2: 0.295222\tvalid_1's l2: 0.333245\n",
      "[1350]\ttraining's l2: 0.294447\tvalid_1's l2: 0.333225\n",
      "[1400]\ttraining's l2: 0.29365\tvalid_1's l2: 0.333191\n",
      "[1450]\ttraining's l2: 0.292865\tvalid_1's l2: 0.333154\n",
      "[1500]\ttraining's l2: 0.292109\tvalid_1's l2: 0.333139\n",
      "[1550]\ttraining's l2: 0.291369\tvalid_1's l2: 0.333068\n",
      "[1600]\ttraining's l2: 0.290635\tvalid_1's l2: 0.333037\n",
      "[1650]\ttraining's l2: 0.289905\tvalid_1's l2: 0.333013\n",
      "[1700]\ttraining's l2: 0.289201\tvalid_1's l2: 0.332982\n",
      "[1750]\ttraining's l2: 0.288498\tvalid_1's l2: 0.332976\n",
      "[1800]\ttraining's l2: 0.287786\tvalid_1's l2: 0.332968\n",
      "[1850]\ttraining's l2: 0.287121\tvalid_1's l2: 0.332937\n",
      "[1900]\ttraining's l2: 0.286457\tvalid_1's l2: 0.332931\n",
      "[1950]\ttraining's l2: 0.285799\tvalid_1's l2: 0.332941\n",
      "[2000]\ttraining's l2: 0.28512\tvalid_1's l2: 0.332923\n",
      "Early stopping, best iteration is:\n",
      "[1892]\ttraining's l2: 0.28656\tvalid_1's l2: 0.332914\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61794\n",
      "[LightGBM] [Info] Number of data points in the train set: 1005090, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla K80, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (253.05 MB) transferred to GPU in 0.321000 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.951286\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[50]\ttraining's l2: 0.442481\tvalid_1's l2: 0.456443\n",
      "[100]\ttraining's l2: 0.364242\tvalid_1's l2: 0.381556\n",
      "[150]\ttraining's l2: 0.347912\tvalid_1's l2: 0.36836\n",
      "[200]\ttraining's l2: 0.340866\tvalid_1's l2: 0.364572\n",
      "[250]\ttraining's l2: 0.33606\tvalid_1's l2: 0.362967\n",
      "[300]\ttraining's l2: 0.332146\tvalid_1's l2: 0.361518\n",
      "[350]\ttraining's l2: 0.329379\tvalid_1's l2: 0.360776\n",
      "[400]\ttraining's l2: 0.327098\tvalid_1's l2: 0.360253\n",
      "[450]\ttraining's l2: 0.325114\tvalid_1's l2: 0.359794\n",
      "[500]\ttraining's l2: 0.323331\tvalid_1's l2: 0.359479\n",
      "[550]\ttraining's l2: 0.321757\tvalid_1's l2: 0.35928\n",
      "[600]\ttraining's l2: 0.320283\tvalid_1's l2: 0.359083\n",
      "[650]\ttraining's l2: 0.318943\tvalid_1's l2: 0.35894\n",
      "[700]\ttraining's l2: 0.317673\tvalid_1's l2: 0.358756\n",
      "[750]\ttraining's l2: 0.316484\tvalid_1's l2: 0.358624\n",
      "[800]\ttraining's l2: 0.315336\tvalid_1's l2: 0.358561\n",
      "[850]\ttraining's l2: 0.314261\tvalid_1's l2: 0.358487\n",
      "[900]\ttraining's l2: 0.313175\tvalid_1's l2: 0.358369\n",
      "[950]\ttraining's l2: 0.312141\tvalid_1's l2: 0.358286\n",
      "[1000]\ttraining's l2: 0.311171\tvalid_1's l2: 0.358201\n",
      "[1050]\ttraining's l2: 0.310237\tvalid_1's l2: 0.358165\n",
      "[1100]\ttraining's l2: 0.30932\tvalid_1's l2: 0.358113\n",
      "[1150]\ttraining's l2: 0.308446\tvalid_1's l2: 0.358067\n",
      "[1200]\ttraining's l2: 0.307572\tvalid_1's l2: 0.35806\n",
      "[1250]\ttraining's l2: 0.306724\tvalid_1's l2: 0.358042\n",
      "[1300]\ttraining's l2: 0.305866\tvalid_1's l2: 0.358024\n",
      "[1350]\ttraining's l2: 0.305038\tvalid_1's l2: 0.357997\n",
      "[1400]\ttraining's l2: 0.304235\tvalid_1's l2: 0.357966\n",
      "[1450]\ttraining's l2: 0.303402\tvalid_1's l2: 0.357942\n",
      "[1500]\ttraining's l2: 0.30263\tvalid_1's l2: 0.35793\n",
      "[1550]\ttraining's l2: 0.301867\tvalid_1's l2: 0.35796\n",
      "[1600]\ttraining's l2: 0.301109\tvalid_1's l2: 0.357953\n",
      "Early stopping, best iteration is:\n",
      "[1503]\ttraining's l2: 0.302576\tvalid_1's l2: 0.357918\n",
      "val_mse -->  0.3474470410736301\n",
      "nwrmsle -->  0.5890097981813619\n",
      "CPU times: user 3h 37min 25s, sys: 46min 2s, total: 4h 23min 28s\n",
      "Wall time: 2h 41min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Incresed boost_rounds to 4000 to improve the model performance\n",
    "num_boost_rounds = 4000\n",
    "# Using 6_weeks data\n",
    "n_days=6\n",
    "verbose=50\n",
    "models=[]\n",
    "\n",
    "val_pred,boost_rounds = train_lgb_model(X_train,y_train,X_val,y_val,params,num_boost_rounds,n_days,items,filtered_features,verbose)\n",
    "\n",
    "val_mse = mean_squared_error(y_val, np.array(val_pred).transpose())\n",
    "print(\"val_mse --> \",val_mse)\n",
    "\n",
    "weight = items[\"perishable\"] * 0.25 + 1\n",
    "nwrmsle = calculate_nwrmsle(true,pred,weight)\n",
    "print(\"nwrmsle --> \",nwrmsle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TMuk34bNP22R"
   },
   "outputs": [],
   "source": [
    "#Saving boost_rounds\n",
    "import pickle\n",
    "with open('boost_rounds.pkl','wb') as file:\n",
    "    pickle.dump(boost_rounds,file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4pcBW7DOdqgO"
   },
   "source": [
    "#### Observation\n",
    "* The model performance has been increased by using more previous data and more boosting rounds.\n",
    "* *Score (NWRMSLE)* = **0.5890**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlrMmjf_2xUk"
   },
   "source": [
    "### Final Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maxqz3lBepGy"
   },
   "source": [
    "* Now Training the Final Model on Total Data (i.e. Combined Train Data 6weeks + Validation Data 1week ).\n",
    "* Not using fixed boost rounds = 4000 as there is no validation data for eary stopping.\n",
    "* Using different boost rounds for all 16 models that performed best during the previous training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJP1vytKnizT"
   },
   "source": [
    "#### Creating Features for 7 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757,
     "referenced_widgets": [
      "b67b4a03c52a49b0a8a677def5b0799a",
      "37e4f3bdacbe4ff9a7f26097cb2bd0b7",
      "2556d575b6be47e5aaf3f44cc7fa4fd5",
      "6665220667ea407083de52a9d69b13d8",
      "942af005566c4df2b866df1ed497e5e2",
      "681b5f4fb36b4a34803b7bc2c9ebe159",
      "0e7028f213794e1ea1bba90f84a0ab96",
      "0347fd8847454e6db8ba3da74a7534fc",
      "6e71d83993e74cfb9326ef5c9dd6fbfe",
      "bc3651a8e2ab49c1bc97b112a9089ecb",
      "45f434f043944eb59e18b8987dec540f",
      "91478bb4161541b39719dfb7a79dfc9d",
      "c7925099bad34f2fb5e91bfd634906f6",
      "80a441294bc1420b90b7b0e1f4181456",
      "2f63a90f7a014092923fdee530c447ee",
      "1229dbd91e4a4aa0ad8530407ab43f22",
      "36ebc0dbabfc434e9259773abb046d69",
      "85e28f2eb2e64e6e8cbd1f8daf195290",
      "12ee598bf21c4f7c92907736eef75d6d",
      "24a04579455b42648ecb75e61baeac1b",
      "f1a818dc58904988811294c9171fc538",
      "92b2775bef0949ddac8247348fc86cdb",
      "18daf12ed36440038e7988137d47b328",
      "8617a8d72a324a38bfd597ec26a5b360",
      "05065035d02e4269ab48d1396e43b814",
      "cca5faff73d2416386a16927a09f1953",
      "492f267bd2d54ca393d8acee10d861dc",
      "669be708e9444699b721c903e8577946",
      "79723281fe6746a9ad204b74bc4caa79",
      "51ef784776c14eb9b992e0fa618680b3",
      "632ada0142d642708d23e9e54f5b5e86",
      "fae98f17bcc348ac8e78a753810a5cd6"
     ]
    },
    "colab_type": "code",
    "id": "5jxNrJRCno7D",
    "outputId": "fbfacfd5-6784-4be8-fe55-99e09069877c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Pre-Processing ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67b4a03c52a49b0a8a677def5b0799a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23808261.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the following for Train Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 31/5/2017\n",
      "No. of weeks --> 7\n",
      "\n",
      "Creating Features for data between Dates --> 2017-05-31 - 2017-07-19 (i.e. 7 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e71d83993e74cfb9326ef5c9dd6fbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_train.csv' File ...\n",
      "Saving 'y_train.csv' File ...\n",
      "\n",
      "Enter the following for Validation Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 26/7/2017\n",
      "No. of weeks --> 1\n",
      "\n",
      "Creating Features for data between Dates --> 2017-07-26 - 2017-08-02 (i.e. 1 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ebc0dbabfc434e9259773abb046d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_val.csv' File ...\n",
      "Saving 'y_val.csv' File ...\n",
      "\n",
      "Enter the following for Test Data :\n",
      "\n",
      "Starting Date (Day/Month/Year) --> 16/8/2017\n",
      "No. of weeks --> 1\n",
      "\n",
      "Creating Features for data between Dates --> 2017-08-16 - 2017-08-23 (i.e. 1 weeks) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05065035d02e4269ab48d1396e43b814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving 'X_test.csv' File ...\n",
      "\n",
      "Saving 'sales_2017.csv' File ...\n",
      "Saving 'stores_items.csv' File ...\n"
     ]
    }
   ],
   "source": [
    "#Creating features by excecuting Pre_Processing Feature_engineering.py\n",
    "\n",
    "exec(open('Pre_Processing Feature_engineering.py').read())\n",
    "\n",
    "\n",
    "# Train Dataset Initial Date 31/5/2017\n",
    "# 7 weeks\n",
    "\n",
    "# Validation Dataset Initial Date 26/7/2017\n",
    "# 1 week\n",
    "\n",
    "# Test Dataset Initial Date 16/8/2017\n",
    "# 1 week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FDgHsXPnrBR"
   },
   "source": [
    "#### Training Final Lgbm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JmYZLRmNNnf1",
    "outputId": "87453029-2ac2-4974-dd2e-904f568c60bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 1\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61419\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (295.23 MB) transferred to GPU in 0.413887 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.034830\n",
      "[200]\ttraining's l2: 0.291423\n",
      "[400]\ttraining's l2: 0.283176\n",
      "[600]\ttraining's l2: 0.278751\n",
      "[800]\ttraining's l2: 0.275346\n",
      "[1000]\ttraining's l2: 0.272441\n",
      "[1200]\ttraining's l2: 0.269792\n",
      "[1400]\ttraining's l2: 0.267339\n",
      "[1600]\ttraining's l2: 0.264971\n",
      "[1800]\ttraining's l2: 0.262731\n",
      "[2000]\ttraining's l2: 0.260576\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61203\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 263 dense feature groups (295.23 MB) transferred to GPU in 0.430795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.963074\n",
      "[200]\ttraining's l2: 0.316905\n",
      "[400]\ttraining's l2: 0.30741\n",
      "[600]\ttraining's l2: 0.302287\n",
      "[800]\ttraining's l2: 0.298352\n",
      "[1000]\ttraining's l2: 0.294995\n",
      "[1200]\ttraining's l2: 0.292004\n",
      "[1400]\ttraining's l2: 0.28925\n",
      "[1600]\ttraining's l2: 0.286613\n",
      "[1800]\ttraining's l2: 0.284113\n",
      "[2000]\ttraining's l2: 0.281672\n",
      "[2200]\ttraining's l2: 0.279347\n",
      "[2400]\ttraining's l2: 0.277068\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60320\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 255 dense feature groups (286.28 MB) transferred to GPU in 0.411410 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.051502\n",
      "[200]\ttraining's l2: 0.318432\n",
      "[400]\ttraining's l2: 0.306936\n",
      "[600]\ttraining's l2: 0.30115\n",
      "[800]\ttraining's l2: 0.296947\n",
      "[1000]\ttraining's l2: 0.293491\n",
      "[1200]\ttraining's l2: 0.290413\n",
      "[1400]\ttraining's l2: 0.287536\n",
      "[1600]\ttraining's l2: 0.284901\n",
      "[1800]\ttraining's l2: 0.282391\n",
      "[2000]\ttraining's l2: 0.279927\n",
      "[2200]\ttraining's l2: 0.277624\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60344\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 257 dense feature groups (290.75 MB) transferred to GPU in 0.402178 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.237834\n",
      "[200]\ttraining's l2: 0.338291\n",
      "[400]\ttraining's l2: 0.325279\n",
      "[600]\ttraining's l2: 0.318519\n",
      "[800]\ttraining's l2: 0.313721\n",
      "[1000]\ttraining's l2: 0.309792\n",
      "[1200]\ttraining's l2: 0.306447\n",
      "[1400]\ttraining's l2: 0.303406\n",
      "[1600]\ttraining's l2: 0.300547\n",
      "[1800]\ttraining's l2: 0.297842\n",
      "[2000]\ttraining's l2: 0.295282\n",
      "[2200]\ttraining's l2: 0.292803\n",
      "[2400]\ttraining's l2: 0.290442\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61851\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 256 dense feature groups (286.28 MB) transferred to GPU in 0.406981 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.271817\n",
      "[200]\ttraining's l2: 0.346285\n",
      "[400]\ttraining's l2: 0.330516\n",
      "[600]\ttraining's l2: 0.322874\n",
      "[800]\ttraining's l2: 0.317493\n",
      "[1000]\ttraining's l2: 0.313227\n",
      "[1200]\ttraining's l2: 0.309523\n",
      "[1400]\ttraining's l2: 0.306176\n",
      "[1600]\ttraining's l2: 0.303042\n",
      "[1800]\ttraining's l2: 0.300166\n",
      "[2000]\ttraining's l2: 0.297411\n",
      "[2200]\ttraining's l2: 0.294797\n",
      "[2400]\ttraining's l2: 0.292269\n",
      "[2600]\ttraining's l2: 0.289858\n",
      "[2800]\ttraining's l2: 0.287565\n",
      "[3000]\ttraining's l2: 0.285318\n",
      "[3200]\ttraining's l2: 0.283142\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62418\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 259 dense feature groups (290.75 MB) transferred to GPU in 0.395269 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.067992\n",
      "[200]\ttraining's l2: 0.343256\n",
      "[400]\ttraining's l2: 0.331521\n",
      "[600]\ttraining's l2: 0.325256\n",
      "[800]\ttraining's l2: 0.320621\n",
      "[1000]\ttraining's l2: 0.316814\n",
      "[1200]\ttraining's l2: 0.313397\n",
      "[1400]\ttraining's l2: 0.310316\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61757\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 264 dense feature groups (295.23 MB) transferred to GPU in 0.388251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.022007\n",
      "[200]\ttraining's l2: 0.33307\n",
      "[400]\ttraining's l2: 0.321406\n",
      "[600]\ttraining's l2: 0.315582\n",
      "[800]\ttraining's l2: 0.311264\n",
      "[1000]\ttraining's l2: 0.30766\n",
      "[1200]\ttraining's l2: 0.304441\n",
      "[1400]\ttraining's l2: 0.301426\n",
      "[1600]\ttraining's l2: 0.298607\n",
      "[1800]\ttraining's l2: 0.29593\n",
      "[2000]\ttraining's l2: 0.293421\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 58040\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 252 dense feature groups (281.81 MB) transferred to GPU in 0.379648 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.023325\n",
      "[200]\ttraining's l2: 0.320278\n",
      "[400]\ttraining's l2: 0.308959\n",
      "[600]\ttraining's l2: 0.303064\n",
      "[800]\ttraining's l2: 0.298855\n",
      "[1000]\ttraining's l2: 0.295296\n",
      "[1200]\ttraining's l2: 0.292174\n",
      "[1400]\ttraining's l2: 0.289354\n",
      "[1600]\ttraining's l2: 0.286726\n",
      "[1800]\ttraining's l2: 0.284217\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61063\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 261 dense feature groups (295.23 MB) transferred to GPU in 0.387371 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.949946\n",
      "[200]\ttraining's l2: 0.330938\n",
      "[400]\ttraining's l2: 0.319703\n",
      "[600]\ttraining's l2: 0.31411\n",
      "[800]\ttraining's l2: 0.309858\n",
      "[1000]\ttraining's l2: 0.306289\n",
      "[1200]\ttraining's l2: 0.303101\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59966\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 251 dense feature groups (281.81 MB) transferred to GPU in 0.379889 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.036044\n",
      "[200]\ttraining's l2: 0.332575\n",
      "[400]\ttraining's l2: 0.319036\n",
      "[600]\ttraining's l2: 0.312406\n",
      "[800]\ttraining's l2: 0.307622\n",
      "[1000]\ttraining's l2: 0.303788\n",
      "[1200]\ttraining's l2: 0.300445\n",
      "[1400]\ttraining's l2: 0.29736\n",
      "[1600]\ttraining's l2: 0.294552\n",
      "[1800]\ttraining's l2: 0.291911\n",
      "[2000]\ttraining's l2: 0.289408\n",
      "[2200]\ttraining's l2: 0.28704\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62301\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 266 dense feature groups (299.70 MB) transferred to GPU in 0.380775 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.215889\n",
      "[200]\ttraining's l2: 0.357803\n",
      "[400]\ttraining's l2: 0.341614\n",
      "[600]\ttraining's l2: 0.332994\n",
      "[800]\ttraining's l2: 0.327124\n",
      "[1000]\ttraining's l2: 0.322576\n",
      "[1200]\ttraining's l2: 0.318712\n",
      "[1400]\ttraining's l2: 0.315218\n",
      "[1600]\ttraining's l2: 0.312067\n",
      "[1800]\ttraining's l2: 0.309123\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60952\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (281.81 MB) transferred to GPU in 0.381980 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.245554\n",
      "[200]\ttraining's l2: 0.364019\n",
      "[400]\ttraining's l2: 0.345663\n",
      "[600]\ttraining's l2: 0.336596\n",
      "[800]\ttraining's l2: 0.330454\n",
      "[1000]\ttraining's l2: 0.325467\n",
      "[1200]\ttraining's l2: 0.321308\n",
      "[1400]\ttraining's l2: 0.31763\n",
      "[1600]\ttraining's l2: 0.314248\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 62953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 261 dense feature groups (295.23 MB) transferred to GPU in 0.388018 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.062321\n",
      "[200]\ttraining's l2: 0.356622\n",
      "[400]\ttraining's l2: 0.342848\n",
      "[600]\ttraining's l2: 0.335644\n",
      "[800]\ttraining's l2: 0.33034\n",
      "[1000]\ttraining's l2: 0.326088\n",
      "[1200]\ttraining's l2: 0.322358\n",
      "[1400]\ttraining's l2: 0.318951\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 60688\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 250 dense feature groups (281.81 MB) transferred to GPU in 0.363483 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.014234\n",
      "[200]\ttraining's l2: 0.344654\n",
      "[400]\ttraining's l2: 0.33157\n",
      "[600]\ttraining's l2: 0.324669\n",
      "[800]\ttraining's l2: 0.319836\n",
      "[1000]\ttraining's l2: 0.315828\n",
      "[1200]\ttraining's l2: 0.312285\n",
      "[1400]\ttraining's l2: 0.309065\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 59794\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 247 dense feature groups (277.33 MB) transferred to GPU in 0.367878 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 1.014597\n",
      "[200]\ttraining's l2: 0.331353\n",
      "[400]\ttraining's l2: 0.317693\n",
      "[600]\ttraining's l2: 0.310975\n",
      "[800]\ttraining's l2: 0.306207\n",
      "[1000]\ttraining's l2: 0.302347\n",
      "[1200]\ttraining's l2: 0.299005\n",
      "[1400]\ttraining's l2: 0.295955\n",
      "[1600]\ttraining's l2: 0.293177\n",
      "[1800]\ttraining's l2: 0.290541\n",
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 61806\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172605, number of used features: 300\n",
      "[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 262 dense feature groups (295.23 MB) transferred to GPU in 0.393572 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.946916\n",
      "[200]\ttraining's l2: 0.342564\n",
      "[400]\ttraining's l2: 0.329136\n",
      "[600]\ttraining's l2: 0.322491\n",
      "[800]\ttraining's l2: 0.317666\n",
      "[1000]\ttraining's l2: 0.313802\n",
      "[1200]\ttraining's l2: 0.310304\n",
      "[1400]\ttraining's l2: 0.307159\n",
      "CPU times: user 3h 56min 8s, sys: 28min 49s, total: 4h 24min 58s\n",
      "Wall time: 2h 34min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using 6(train)+1(val) weeks data\n",
    "n_days = 7\n",
    "verbose = 200\n",
    "models=[]\n",
    "\n",
    "test_pred = train_lgb_model(X_train,y_train,None,None,params,boost_rounds,n_days,items,filtered_features,verbose,X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnDwTWTvIvTP"
   },
   "outputs": [],
   "source": [
    "#Saving Models\n",
    "import pickle\n",
    "with open('final_models.pkl','wb') as file:\n",
    "    pickle.dump(models,file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qat_PqlZ6vZA"
   },
   "source": [
    "### Predicting for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFrSRdOQV0Gu"
   },
   "outputs": [],
   "source": [
    "# Reading test.csv\n",
    "df_test = pd.read_csv(\"test.csv\",parse_dates=[\"date\"])\n",
    "\n",
    "# Reading sales_2017.csv\n",
    "sales_2017 = pd.read_csv(\"sales_2017.csv\")\n",
    "\n",
    "# setting index as store_nbr,item_nbr\n",
    "sales_2017 = sales_2017.set_index([\"store_nbr\", \"item_nbr\"])\n",
    "\n",
    "# setting index as store_nbr,item_nbr,date\n",
    "df_test = df_test.set_index([\"store_nbr\", \"item_nbr\",'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B_CSAmvlKfM7",
    "outputId": "23f13d65-e190-4708-862d-10f9a87fc8b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 'final_lgb_predicitons.csv' File ...\n"
     ]
    }
   ],
   "source": [
    "#Converting predicitons on test data to numpy array and taking transpose.\n",
    "y_test = np.array(test_pred).transpose()\n",
    "\n",
    "# Creating Dataframe with test predicitons and setting index same as sales_2017 Dataframe (i.e. str_nbr, item_nbr)\n",
    "df_preds = pd.DataFrame(y_test, index=sales_2017.index,\n",
    "                        columns=pd.date_range(\"2017-08-16\", periods=16) #Column names as Date starting from 16/8/2017 till next 16 days\n",
    "                        ).stack().to_frame(\"unit_sales\")                # Stacking date columns to index\n",
    "\n",
    "# Setting names of the indices\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "\n",
    "# Joining the given test dataset(df_test) for which predictions were to be made\n",
    "# and the dataframe in which predicited values are present\n",
    "final_lgb_predicitons = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0) #The prediciton is only done for Items which were present in train data so the new items sales will be filled with 0\n",
    "\n",
    "# Converting predicted unit_sales back to orginal form by taking exp(unit_sales) - 1 as it was previously converted using log(unit_sales) + 1\n",
    "final_lgb_predicitons[\"unit_sales\"] = np.clip(np.expm1(final_lgb_predicitons[\"unit_sales\"]), 0, 1000)\n",
    "\n",
    "# Saving file for submission.\n",
    "print(\"Saving 'final_lgb_predicitons.csv' File ...\")\n",
    "final_lgb_predicitons.to_csv('final_lgb_predicitons.csv', float_format='%.4f', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31OigxhMK0Ec"
   },
   "source": [
    "### Results (After Submitting):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ik92FExs6FLF"
   },
   "source": [
    "* Model --> **LGBM**\n",
    "* Best Parameters :\n",
    "    * *learning_rate* = **0.020756**\n",
    "    * *num_leaves* = **71**\n",
    "    * *min_data_in_leaf* = **180**\n",
    "    * *feature_fraction* = **0.614000**\n",
    "    * *bagging_fraction* = **0.792127**\n",
    "    * *bagging_freq* = **1** \n",
    "* Private Score (NWRMSLE) = **0.51241** (***Rank-2***)\n",
    "* Public Score (NWRMSLE) = **0.50822**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "gNVpaWaSi_dC",
    "edpKYGBbjG50",
    "PAYxORCE5tBg",
    "JYs6IsHakahn",
    "yGHCj5TN6MV1",
    "cGg0O77VR1_U",
    "vF4KojL_cAa7",
    "KOGcPWZW6nwj",
    "8TWHI04p2BIs",
    "GlrMmjf_2xUk",
    "jJP1vytKnizT",
    "_FDgHsXPnrBR",
    "Qat_PqlZ6vZA",
    "31OigxhMK0Ec"
   ],
   "name": "Final_LGBM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0347fd8847454e6db8ba3da74a7534fc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03627738e52340aabd715f02ee73d4ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2804f23dc2874f71a2655dcba9ae7649",
       "IPY_MODEL_c45b1d5db9a549e1b094aa986654f205"
      ],
      "layout": "IPY_MODEL_411226fa036c48f3bc7049f7d8b76c4c"
     }
    },
    "03772aa258cf4be591d212abcc9d8aab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25c5fd2969b24e2eb421a4e8ceddd945",
       "IPY_MODEL_7fd483d30177402ab4ac99adc4b8f0f7"
      ],
      "layout": "IPY_MODEL_2dc5aa5e515343a9bafd3a9a9d31b31e"
     }
    },
    "03fbeb6469454a319e97bf111c5900e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05065035d02e4269ab48d1396e43b814": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_492f267bd2d54ca393d8acee10d861dc",
       "IPY_MODEL_669be708e9444699b721c903e8577946"
      ],
      "layout": "IPY_MODEL_cca5faff73d2416386a16927a09f1953"
     }
    },
    "0e7028f213794e1ea1bba90f84a0ab96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11b30308521b463597c88c64f84e0887": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1229dbd91e4a4aa0ad8530407ab43f22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12ee598bf21c4f7c92907736eef75d6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92b2775bef0949ddac8247348fc86cdb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1a818dc58904988811294c9171fc538",
      "value": 1
     }
    },
    "1324f19f71f6421a9aaababad060e076": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "181061f7c9474cf98d97b9eea9a91b4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ef0bbbe48d1f4b39b1143cf7bebca019",
      "placeholder": "​",
      "style": "IPY_MODEL_1324f19f71f6421a9aaababad060e076",
      "value": " 23808261/23808261 [01:08&lt;00:00, 346933.04it/s]"
     }
    },
    "18daf12ed36440038e7988137d47b328": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a079d52f9354ec39c3f8de76e673ecb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21f2f1812d7e454b98f6f01fc8872327": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24a04579455b42648ecb75e61baeac1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8617a8d72a324a38bfd597ec26a5b360",
      "placeholder": "​",
      "style": "IPY_MODEL_18daf12ed36440038e7988137d47b328",
      "value": " 1/1 [02:28&lt;00:00, 148.97s/it]"
     }
    },
    "2556d575b6be47e5aaf3f44cc7fa4fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_681b5f4fb36b4a34803b7bc2c9ebe159",
      "max": 23808261,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_942af005566c4df2b866df1ed497e5e2",
      "value": 23808261
     }
    },
    "25c5fd2969b24e2eb421a4e8ceddd945": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3499603b01014c14987a8f56cb8dee52",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5dc2349f861546e880ca84d1db9c686a",
      "value": 1
     }
    },
    "25e04ea4e04d43f7909923c190f9d6fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2804f23dc2874f71a2655dcba9ae7649": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36a266d9fed14ecf8abdc5daf162d155",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c14ac1246a17454bb973356897c84a1d",
      "value": 6
     }
    },
    "2dc5aa5e515343a9bafd3a9a9d31b31e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f63a90f7a014092923fdee530c447ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3499603b01014c14987a8f56cb8dee52": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36a266d9fed14ecf8abdc5daf162d155": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36ebc0dbabfc434e9259773abb046d69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12ee598bf21c4f7c92907736eef75d6d",
       "IPY_MODEL_24a04579455b42648ecb75e61baeac1b"
      ],
      "layout": "IPY_MODEL_85e28f2eb2e64e6e8cbd1f8daf195290"
     }
    },
    "37e4f3bdacbe4ff9a7f26097cb2bd0b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "411226fa036c48f3bc7049f7d8b76c4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41648c09cd7b4d919e7410452e2e0a30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "417c09e0afb14d979ecb3021100c2393": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6b523cf2ae2461cb49961d55ad76296",
       "IPY_MODEL_bc22aca106674e9c824708a4c9e31fa2"
      ],
      "layout": "IPY_MODEL_f5de498a722046a3bb0bbe834e5cd23b"
     }
    },
    "45f434f043944eb59e18b8987dec540f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80a441294bc1420b90b7b0e1f4181456",
      "max": 7,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7925099bad34f2fb5e91bfd634906f6",
      "value": 7
     }
    },
    "492f267bd2d54ca393d8acee10d861dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51ef784776c14eb9b992e0fa618680b3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79723281fe6746a9ad204b74bc4caa79",
      "value": 1
     }
    },
    "4a48fa242d284b3c9483862ff711f44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_712acd616c954244802e252377e7bb79",
       "IPY_MODEL_fd07bdebd10046b394e08bf6eccde2a2"
      ],
      "layout": "IPY_MODEL_8d387c52c729472c8f416c4793e04790"
     }
    },
    "4a6c4f9a68e9499f8e0665348dd2a4bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d6f5831c9e14a468b308d629aa258ef",
      "max": 23808261,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aece3190486745a9b65e8f149c109399",
      "value": 23808261
     }
    },
    "51ef784776c14eb9b992e0fa618680b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5759388fb12b4189a105c68a21d27805": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5b118e2a48ba421c97673296c7f36cb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6182ad151f3341ef844ab423b18f2dfa",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41648c09cd7b4d919e7410452e2e0a30",
      "value": 1
     }
    },
    "5dc2349f861546e880ca84d1db9c686a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6182ad151f3341ef844ab423b18f2dfa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "632ada0142d642708d23e9e54f5b5e86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6665220667ea407083de52a9d69b13d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0347fd8847454e6db8ba3da74a7534fc",
      "placeholder": "​",
      "style": "IPY_MODEL_0e7028f213794e1ea1bba90f84a0ab96",
      "value": " 23808261/23808261 [00:45&lt;00:00, 520864.99it/s]"
     }
    },
    "669be708e9444699b721c903e8577946": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fae98f17bcc348ac8e78a753810a5cd6",
      "placeholder": "​",
      "style": "IPY_MODEL_632ada0142d642708d23e9e54f5b5e86",
      "value": " 1/1 [03:03&lt;00:00, 183.88s/it]"
     }
    },
    "681b5f4fb36b4a34803b7bc2c9ebe159": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e5577953e7a414a9758725241445970": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e71d83993e74cfb9326ef5c9dd6fbfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45f434f043944eb59e18b8987dec540f",
       "IPY_MODEL_91478bb4161541b39719dfb7a79dfc9d"
      ],
      "layout": "IPY_MODEL_bc3651a8e2ab49c1bc97b112a9089ecb"
     }
    },
    "6f606c7dc1054a8b91d7bbe5709fdba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "712acd616c954244802e252377e7bb79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5409acbb7324b40b4cd2e4e50ab0db1",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de9581fff5814dd99dc9149b63d30f64",
      "value": 3
     }
    },
    "78bfc6454fbe42b389c185cfac704ca2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79723281fe6746a9ad204b74bc4caa79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7b99a7de81e94732888fdaa5dc9585f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7fd483d30177402ab4ac99adc4b8f0f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21f2f1812d7e454b98f6f01fc8872327",
      "placeholder": "​",
      "style": "IPY_MODEL_90150e4582ed454d911c26515c71f8c7",
      "value": " 1/1 [03:37&lt;00:00, 217.70s/it]"
     }
    },
    "7feec5900101408da50dffba13863c06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80a441294bc1420b90b7b0e1f4181456": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85e28f2eb2e64e6e8cbd1f8daf195290": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8617a8d72a324a38bfd597ec26a5b360": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d387c52c729472c8f416c4793e04790": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d6f5831c9e14a468b308d629aa258ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8eca55bb8cc84f92b074a791f526b871": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90150e4582ed454d911c26515c71f8c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91478bb4161541b39719dfb7a79dfc9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1229dbd91e4a4aa0ad8530407ab43f22",
      "placeholder": "​",
      "style": "IPY_MODEL_2f63a90f7a014092923fdee530c447ee",
      "value": " 7/7 [19:00&lt;00:00, 162.97s/it]"
     }
    },
    "91a12ec0de7b42aaab050e26001d6005": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92b2775bef0949ddac8247348fc86cdb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "942af005566c4df2b866df1ed497e5e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a5409acbb7324b40b4cd2e4e50ab0db1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a919e10078684258821db5608b8b2c2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb447b61bc20479d8487dd621a28ee08",
      "placeholder": "​",
      "style": "IPY_MODEL_cb9a96461b6145049b4aeaaf72e6c959",
      "value": " 1/1 [04:34&lt;00:00, 274.82s/it]"
     }
    },
    "aece3190486745a9b65e8f149c109399": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b67b4a03c52a49b0a8a677def5b0799a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2556d575b6be47e5aaf3f44cc7fa4fd5",
       "IPY_MODEL_6665220667ea407083de52a9d69b13d8"
      ],
      "layout": "IPY_MODEL_37e4f3bdacbe4ff9a7f26097cb2bd0b7"
     }
    },
    "bb447b61bc20479d8487dd621a28ee08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc22aca106674e9c824708a4c9e31fa2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91a12ec0de7b42aaab050e26001d6005",
      "placeholder": "​",
      "style": "IPY_MODEL_11b30308521b463597c88c64f84e0887",
      "value": " 633/633 [2:46:09&lt;00:00, 15.75s/it]"
     }
    },
    "bc3651a8e2ab49c1bc97b112a9089ecb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf4983d9aa894a3cab7bb604d1d6612a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c077db0b048f4460a5bfdfc650587e4c",
       "IPY_MODEL_f10211f0b4a94605b272f439fc2c8e0a"
      ],
      "layout": "IPY_MODEL_d5d18016a0c74e54a7b96e6c428130c8"
     }
    },
    "c077db0b048f4460a5bfdfc650587e4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7868103552c4d2bbbb32a990e34904c",
      "max": 633,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b99a7de81e94732888fdaa5dc9585f6",
      "value": 633
     }
    },
    "c14ac1246a17454bb973356897c84a1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c45b1d5db9a549e1b094aa986654f205": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03fbeb6469454a319e97bf111c5900e3",
      "placeholder": "​",
      "style": "IPY_MODEL_25e04ea4e04d43f7909923c190f9d6fd",
      "value": " 6/6 [17:06&lt;00:00, 171.04s/it]"
     }
    },
    "c7925099bad34f2fb5e91bfd634906f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cb9a96461b6145049b4aeaaf72e6c959": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cca5faff73d2416386a16927a09f1953": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5d18016a0c74e54a7b96e6c428130c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7868103552c4d2bbbb32a990e34904c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbe4c42659f6494bba5a3942c6a2036e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4a6c4f9a68e9499f8e0665348dd2a4bc",
       "IPY_MODEL_181061f7c9474cf98d97b9eea9a91b4a"
      ],
      "layout": "IPY_MODEL_f1f3f0a5e7c0413e9d68edde10d5211a"
     }
    },
    "de9581fff5814dd99dc9149b63d30f64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e120464726c54dab87cbda59abf98831": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b118e2a48ba421c97673296c7f36cb5",
       "IPY_MODEL_a919e10078684258821db5608b8b2c2a"
      ],
      "layout": "IPY_MODEL_1a079d52f9354ec39c3f8de76e673ecb"
     }
    },
    "ef0bbbe48d1f4b39b1143cf7bebca019": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f10211f0b4a94605b272f439fc2c8e0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7feec5900101408da50dffba13863c06",
      "placeholder": "​",
      "style": "IPY_MODEL_6f606c7dc1054a8b91d7bbe5709fdba9",
      "value": " 633/633 [06:44&lt;00:00,  1.56it/s]"
     }
    },
    "f1a818dc58904988811294c9171fc538": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1f3f0a5e7c0413e9d68edde10d5211a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5de498a722046a3bb0bbe834e5cd23b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6b523cf2ae2461cb49961d55ad76296": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78bfc6454fbe42b389c185cfac704ca2",
      "max": 633,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5759388fb12b4189a105c68a21d27805",
      "value": 633
     }
    },
    "fae98f17bcc348ac8e78a753810a5cd6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd07bdebd10046b394e08bf6eccde2a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e5577953e7a414a9758725241445970",
      "placeholder": "​",
      "style": "IPY_MODEL_8eca55bb8cc84f92b074a791f526b871",
      "value": " 3/3 [00:00&lt;00:00, 22.68it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
